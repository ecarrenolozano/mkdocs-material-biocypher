{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#overview","title":"Overview","text":""},{"location":"#mission-statement","title":"Mission Statement","text":"<p>We aim to enable access to versatile and powerful knowledge graphs for as many researchers as possible. Making biomedical knowledge \u201ctheir own\u201d is often a privilege of the companies and groups that can afford individuals or teams working on knowledge representation in a dedicated manner. With BioCypher, we aim to change that. Creating a knowledge graph should be \u201cas simple as possible, but not any simpler.\u201d To achieve this, we have developed a framework that facilitates the creation of knowledge graphs that are informed by the latest developments in the field of biomedical knowledge representation. However, to make this framework truly accessible and comprehensive, we need the input of the biomedical community. We are therefore inviting you to join us in this endeavour!</p>"},{"location":"#vision-statement","title":"Vision Statement","text":"<p>The machine learning models we train are only as good as the data they are trained on. However, most developments today still rely on manually engineered and non-reproducible data processing. We envision a future where the creation of knowledge graphs is as easy as running a script, enabling researchers to build reliable knowledge representations with up-to-date information. We believe that making the knowledge representation process more agile and lifting it to the same level of attention as the process of algorithm development will lead to more robust and reliable machine learning models. We are convinced that this will be a crucial step towards the democratization of AI in biomedicine and beyond.</p>"},{"location":"#project-timeline","title":"Project Timeline","text":"January 2024 <p>Project Kickoff: Defined project goals and gathered the team.</p> February 2024 <p>Design Phase: Initial design prototypes were created.</p> March 2024 <p>Development Begins: Core development started, focusing on main features.</p> January 2025 <p>Beta Testing: Released the first beta version to select users.</p> March 2025 <p>Official Launch: Publicly launched the final version.</p>"},{"location":"installation/","title":"Install BioCypher","text":""},{"location":"installation/#system-requirements","title":"System Requirements","text":"<p>python &gt;=3.10</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<ol> <li>Ensure that your Python version is 3.10 or higher. To check your current Python version, run the following command in your terminal, Command Prompt, or PowerShell:    <pre><code>python --version\n</code></pre></li> <li>Ensure you have <code>git</code> installed in your machine:    <pre><code>git --version\n</code></pre></li> </ol>"},{"location":"installation/#option-1-use-a-pre-configured-project-with-biocypher","title":"Option 1. Use a pre-configured project with BioCypher","text":"localDocker <p>Note:</p> <p>These are manual installation instructions. If you created the repository using the above GitHub template  functionality, you don't need to do the first two steps. Instead, just clone the repository you have created.</p> <pre><code># Clone this repository and rename to your project name.\ngit clone https://github.com/biocypher/project-template.git\nmv project-template my-project\ncd my-project\n\n# Make the repository your own.\nrm -rf .git\ngit init\ngit add .\ngit commit -m \"Initial commit\"\n# (you can add your remote repository here)\n\n# Install the dependencies using Poetry. \n# Or feel free to use your own dependency management system. \n# We provide a pyproject.toml to define dependencies.)\npoetry install\n\n#You are ready to go!\npoetry shell\npython create_knowledge_graph.py\n</code></pre> <p>This repo also contains a docker compose workflow to create the example database using BioCypher and load it into a  dockerised Neo4j instance automatically. </p> <p>Start up a single (detached) docker container with a Neo4j instance that contains the knowledge  graph built by BioCypher as the DB neo4j (the default DB),</p> <p><pre><code>docker compose up -d \n</code></pre> which you can connect to and browse at localhost:7474. </p> <p>Authentication is deactivated by default and can be modified in the docker_variables.env file (in which case you  need to provide the .env file to the deploy stage of the docker-compose.yml).</p> <p>Regarding the BioCypher build procedure, the biocypher_docker_config.yaml file is used instead of the  biocypher_config.yaml (configured in scripts/build.sh). Everything else is the same as in the local setup. The first container (build) installs and runs the BioCypher pipeline, the second container (import) installs Neo4j and runs  the import, and the third container (deploy) deploys the Neo4j instance on localhost. The files are shared using a  Docker Volume. This three-stage setup strictly is not necessary for the mounting of a read-write instance of Neo4j,  but is required if the purpose is to provide a read-only instance (e.g. for a web app) that is updated regularly;  for an example, see the meta graph repository. The read-only setting is configured in the docker-compose.yml file  (NEO4J_dbms_databases_default__to__read__only: \"false\") and is deactivated by default.</p>"},{"location":"installation/#option-2-download-a-package","title":"Option 2. Download a Package","text":"poetry(recommended)pip <p>Note: About Poetry</p> <p>Poetry is a tool for dependency management and packaging in Python. It allows you to declare the  libraries your project depends on and it will manage (install/update) them for you. Poetry offers a lockfile to  ensure repeatable installs, and can build your project for distribution. For information about the installation  process, you can consult here.</p> <pre><code># Create a new Poetry project, i.e. my-awesome-kg-project.\npoetry new &lt;name-of-the-project&gt;\n\n# Navigate into the recently created folder's project\ncd &lt;name-of-the-project&gt;\n\n# Install the BioCypher package with all the dependencies\npoetry add biocypher\n</code></pre> <p>Note: Virtual environment and best practices</p> <p>To follow best practices in software engineering and prevent issues with your Python installation, we highly recommend installing packages in a separate virtual environment instead of directly in the base Python installation.</p> <ol> <li> <p>Create and activate a virtual environment. Replace <code>&lt;name-of-environment&gt;</code> with the name of the environment you desire, i.e. <code>biocypher_env</code> </p> condavenv <pre><code># Create a conda environment with Python 3.10\nconda create --name &lt;name-of-environment&gt; python=3.10\n\n# Activate the new created environment\nconda activate &lt;name-of-environment&gt;\n</code></pre> <pre><code># Create a virtualenv environment\npython3 -m venv &lt;name-of-environment&gt;\n\n# Activate the new created environment\nsource ./&lt;name-of-environment&gt;/bin/activate\n</code></pre> </li> <li> <p>Install BioCypher package from <code>pip</code>. Type the following command to install BioCypher package. Note: do not forget to activate a virtual environment before do it.</p> <pre><code>pip install biocypher        \n</code></pre> </li> </ol>"},{"location":"biocypher-project/biochatter-integration/","title":"BioChatter (LLM on Knowledge Graphs)","text":""},{"location":"biocypher-project/biochatter-integration/#connect-your-knowledge-graph-to-large-language-models","title":"Connect your Knowledge Graph to Large Language Models","text":"<p>To facilitate the use of knowledge graphs in downstream tasks, we have developed a framework to connect knowledge graphs to large language models, this framework is called BioChatter</p> <p>biochatter is a Python package implementing a generic backend library for the connection of biomedical applications to conversational AI. We describe the framework in this preprint. BioChatter is part of the BioCypher ecosystem, connecting natively to BioCypher knowledge graphs.</p>"},{"location":"biocypher-project/biochatter-integration/#biocypher-ecosystem-biocypher-biochatter","title":"BioCypher Ecosystem (BioCypher + BioChatter)","text":""},{"location":"biocypher-project/design-philosophy/","title":"BioCypher design philosophy","text":""},{"location":"biocypher-project/design-philosophy/#biocypher-design-philosophy","title":"BioCypher design philosophy","text":"<p>BioCypher uses a collection of reusable \u201cadapters\u201d for the different sources of biomedical knowledge, which can be  flexibly recombined to fit various demands, thus reducing redundant maintenance work through quasi-standardisation.  Integrating the controlled vocabularies of ontologies into the process helps to harmonise the data from individual  resources and yields a consistent semantic basis for downstream analyses. Through unambiguous and simple \u201clow-code\u201d  configuration, a reproducible knowledge graph can be created and shared for every specific task.</p> <p></p>"},{"location":"biocypher-project/design-philosophy/#design-principles","title":"Design Principles","text":""},{"location":"biocypher-project/design-philosophy/#resources","title":"Resources","text":"<p>Resources are diverse data inputs and sources that feed into the knowledge graph through \"adaptors\". A Resource could be a file, a list of files, an API request, or a list of API requests. Biocypher can download resources from a given URL,  cache them, and manage their lifecycle.</p>"},{"location":"biocypher-project/design-philosophy/#adaptors","title":"Adaptors","text":"<p>BioCypher is a modular framework, with the main purpose of avoiding redundant maintenance work for maintainers of  secondary resources and end users alike. To achieve this, we use a collection of reusable \"adapters\" for the different  sources of biomedical knowledge as well as for different ontologies.</p>"},{"location":"biocypher-project/design-philosophy/#ontologies","title":"Ontologies","text":"<p>An ontology is a formal, hierarchical representation of knowledge within a specific domain, organizing concepts and  their relationships. It structures concepts into subclasses of more general categories, such as a wardrobe being a  subclass of furniture. BioCypher requires a certain amount of knowledge about ontologies and how to use them. We try to  make dealing with ontologies as easy as possible, but some basic understanding is required.</p>"},{"location":"biocypher-project/design-philosophy/#configuration","title":"Configuration","text":"<p>Configuration in BioCypher involves setting up and customizing the system to meet specific needs. BioCypher provides  default configuration parameters, which can be overridden by creating a <code>biocypher_config.yaml</code> file in your project's  root or config directory,specifying the parameters you wish to change.</p>"},{"location":"biocypher-project/design-philosophy/#outputs","title":"Outputs","text":"<p>Initially focused on Neo4j due to OmniPath's migration, BioCypher now supports multiple output formats, including RDF,  SQL, ArangoDB, CSV, PostgreSQL, SQLite, and NetworkX, specified via the dbms parameter in the <code>biocypher_config.yaml</code>  file. Users can choose between online mode or offline mode.</p>"},{"location":"explanation/","title":"Explanation:","text":""},{"location":"explanation/#purpose","title":"Purpose","text":"<p>The purpose of this documentation is to provide a comprehensive guide to understanding and working with knowledge graphs  within the context of BioCypher.  It aims to explain the fundamental concepts of knowledge graphs and how they are  represented in BioCypher.</p>"},{"location":"explanation/#catalog","title":"Catalog","text":""},{"location":"explanation/#basics-of-knowledge-graphs","title":"Basics of Knowledge Graphs.","text":"<ul> <li>Here goes a simple explanation about edges, nodes, and graphs.</li> </ul>"},{"location":"explanation/#how-a-graph-is-represented-in-biocypher","title":"How a graph is represented in BioCypher?","text":"<ul> <li>Here goes a simple explanation about how the graphs are represented in BioCypher.</li> </ul>"},{"location":"explanation/#about-this-documentation","title":"About this documentation","text":"<p>TO DO: delete once the webpage is live in production.</p>"},{"location":"explanation/about-documentation/","title":"About the structure: tutorials, how-to guides, technical reference and explanations","text":"<p>Our documentation follows the \"Diataxis documentation framework\" proposed by Daniel Procida. This framework divide the documentation universe in four parts that represent different purposes or functions. They are: Tutorials, How-to guides, Technical Reference and Explanations.</p>"},{"location":"explanation/about-documentation/#brief-summary","title":"Brief Summary:","text":"<p>Table 1. Diataxis documentation framework (extracted from link)</p> Tutorials How-to Guides Reference Explanation what they do introduce, educate, lead guide state, describe, inform explain, clarify, discuss answers the question Can you teach me to...? How do I...? \"What is...?\" \"Why...?\" oriented to learning a goal information understanding purpose to provide a learning experience to help achieve a particular goal to describe the machinery to illuminate a topic form a lesson a series of steps dry description discursive explanation analogy teaching a small child how to cook a recipe in a cookery book a reference encyclopedia article an article on culinary social history"},{"location":"explanation/exp001_basics_knowledge_graphs/","title":"Basics of Knowledge Graphs","text":"<ul> <li> <p>Nodes</p> </li> <li> <p>Edges</p> </li> <li> <p>Operations</p> </li> </ul>"},{"location":"how-to-guides/","title":"Index","text":""},{"location":"how-to-guides/#how-to-guides","title":"How-to Guides:","text":"<ol> <li> <p>How-to create a standalone Docker image for a BioCypher KG?</p> </li> <li> <p>How-to use or create an Adapter to read data?</p> </li> <li>How-to combine data from different Adapters?</li> <li>How-to create a graph from a CSV file</li> <li>How-to create convert a graph to Pandas Dataframe.</li> <li>How-to create a complete pipeline (from CSV file to Neo4j)</li> <li>How to configure BioCypher</li> <li>How to define an Schema for your Graph</li> </ol>"},{"location":"how-to-guides/htg001_standalone_docker_biocypher/","title":"Standalone Docker Image","text":"<p>In order to build a standalone Docker image for a BioCypher KG, you only need small modifications to the Docker image of the template. We will render the data that ususally is stored in the <code>biocypher_neo4j_volume</code> to our local disk by exchanging <code>biocypher_neo4j_volume</code> with a local directory, <code>./biocypher_neo4j_volume</code>. Then, we use a Dockerfile to build an image that contains the final database. This image can be used to deploy the database anywhere, without the need to run the BioCypher code. This process is demonstrated in the drug-interactions example repository.</p> <ol> <li> <p>Clone the example repository</p> <pre><code>git clone https://github.com/biocypher/drug-interactions.git\ncd drug-interactions\n</code></pre> </li> <li> <p>Attach volumes to disk by modifying the docker-compose.yml. In the example repository, we have created a dedicated compose file for the standalone image. You can see the differences between the standard and standalone compose files here. IMPORTANT: only run the standalone compose file once, as the data in the <code>./biocypher_neo4j_volume</code> directory is persistent and interferes with subsequent runs. If you want to run it again, you need to delete the <code>./biocypher_neo4j_volume</code> directory.</p> </li> <li> <p>Run the standalone compose file. This will create the <code>./biocypher_neo4j_volume</code> directory and store the data in it. You can stop the container after the database has been created.</p> <pre><code>docker compose -f docker-compose-local-disk.yml up -d\ndocker compose -f docker-compose-local-disk.yml down\n</code></pre> </li> <li> <p>Create standalone <code>Dockerfile</code> (example here):</p> <pre><code># Dockerfile\nFROM neo4j:4.4-enterprise\nCOPY ./biocypher_neo4j_volume /data\nRUN chown -R 7474:7474 /data\nEXPOSE 7474\nEXPOSE 7687\n</code></pre> </li> <li> <p>Build the standalone image.</p> <pre><code>docker build -t drug-interactions:latest .\n</code></pre> <p>This image can be deployed anywhere, without the need to run the BioCypher code. For example, you can add it to a Docker Compose file (example here):</p> <pre><code># docker-compose.yml\nversion: '3.9'\nservices:\n[other services ...]\n\nbiocypher:\n    container_name: biocypher\n    image: biocypher/drug-interactions:latest\n    environment:\n    NEO4J_dbms_security_auth__enabled: \"false\"\n    NEO4J_dbms_databases_default__to__read__only: \"false\"\n    NEO4J_ACCEPT_LICENSE_AGREEMENT: \"yes\"\n    ports:\n    - \"0.0.0.0:7474:7474\"\n    - \"0.0.0.0:7687:7687\"\n</code></pre> </li> </ol>"},{"location":"reference/","title":"Index","text":"<ul> <li> <p> API Documentation</p> <p>Install <code>mkdocs-material</code> with <code>pip</code> and get up and running in minutes</p> <p> Getting started</p> </li> <li> <p> BioCypher Configuration Reference</p> <p>Focus on your content and generate a responsive and searchable static site</p> <p> Reference</p> </li> <li> <p> Schema Configuration Reference</p> <p>Change the colors, fonts, language, icons, logo and more with a few lines</p> <p> Customization</p> </li> <li> <p> Open Source, MIT</p> <p>Material for MkDocs is licensed under MIT and available on [GitHub]</p> <p> License</p> </li> </ul>"},{"location":"reference/api-reference/","title":"Api reference","text":"<ul> <li> <p> Set up in 5 minutes</p> <p>Install <code>mkdocs-material</code> with <code>pip</code> and get up and running in minutes</p> <p> Getting started</p> </li> <li> <p> It's just Markdown</p> <p>Focus on your content and generate a responsive and searchable static site</p> <p> Reference</p> </li> <li> <p> Made to measure</p> <p>Change the colors, fonts, language, icons, logo and more with a few lines</p> <p> Customization</p> </li> <li> <p> Open Source, MIT</p> <p>Material for MkDocs is licensed under MIT and available on [GitHub]</p> <p> License</p> </li> </ul>"},{"location":"reference/biocypher-config-guide/","title":"BioCypher Configuration Reference","text":""},{"location":"reference/biocypher-config-guide/#purpose","title":"Purpose","text":"<p>The configuration in BioCypher customizes its behavior by overriding default settings through a <code>biocypher_config.yaml</code>  file. It ensures flexibility for different use cases by allowing you to define data sources, database connections, and  output formats.</p>"},{"location":"reference/biocypher-config-guide/#convention-for-naming","title":"Convention for naming","text":"<p>It is important to follow the rules of indentation in the YAML file. BioCypher module configuration is found under the  top-level keyword <code>biocypher</code>, while the settings for DBMS systems (e.g., Neo4j) are found under their respective  keywords (e.g., <code>neo4j</code>).</p> <p>If possible, avoid using quote characters in your YAML files. If you need to quote, for instance a tab delimiter (<code>\\t</code>), use single quotes (<code>'</code>), since double quotes (<code>\"</code>) allow parsing of escape characters in YAML, which can cause issues  downstream. It is safe to use double quotes to quote a single quote character (<code>\"'\"</code>).</p>"},{"location":"reference/biocypher-config-guide/#skeleton","title":"Skeleton","text":"<pre><code>biocypher:\n  #---- REQUIRED PARAMETERS\n\n  dbms: neo4j\n  schema_config_path: config/schema_config.yaml\n  offline: true\n  strict_mode: false\n  head_ontology:\n    url: https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl\n    root_node: entity\n    switch_label_and_id: true\n\n  #---- OPTIONAL PARAMETERS\n  log_to_disk: true\n\n  debug: true\n\n  log_directory: biocypher-log\n\n  output_directory: biocypher-out\n\n  cache_directory: .cache\n\n  #---- OPTIONAL TAIL ONTOLOGIES\n\n  # tail_ontologies:\n  #   so:\n  #     url: test/ontologies/so.owl\n  #     head_join_node: sequence variant\n  #     tail_join_node: sequence_variant\n  #     switch_label_and_id: true\n  #   mondo:\n  #     url: test/ontologies/mondo.owl\n  #     head_join_node: disease\n  #     tail_join_node: disease\n  #     switch_label_and_id: true\n\n#-------------------------------------------------------------------\n#-----------------       OUTPUT Configuration      -----------------\n#-------------------------------------------------------------------\n#---- NEO4J database management system\nneo4j:\n  database_name: neo4j\n  wipe: true\n\n  uri: neo4j://localhost:7687\n  user: neo4j\n  password: neo4j\n\n  delimiter: \";\"\n  array_delimiter: \"|\"\n  quote_character: \"'\"\n\n  multi_db: true\n\n  skip_duplicate_nodes: false\n  skip_bad_relationships: false\n\n  # import_call_bin_prefix: bin/\n  # import_call_file_prefix: path/to/files/\n\n#---- PostgreSQL database management system\npostgresql:\n  database_name: postgres\n\n  host: localhost # host\n  port: 5432 # port\n\n  user: postgres\n  password: postgres # password\n\n  quote_character: '\"'\n  delimiter: '\\t'\n  # import_call_bin_prefix: '' # path to \"psql\"\n  # import_call_file_prefix: '/path/to/files'\n\n#---- SQLite database management system\nsqlite:\n  ### SQLite configuration ###\n\n  # SQLite connection credentials\n  database_name: sqlite.db # DB name\n\n  # SQLite import batch writer settings\n  quote_character: '\"'\n  delimiter: '\\t'\n  # import_call_bin_prefix: '' # path to \"sqlite3\"\n  # import_call_file_prefix: '/path/to/files'\n\n#---- RDF (Resource Description Framework) data model\nrdf:\n  ### RDF configuration ###\n  rdf_format: turtle\n\n#---- NetworkX graph data model\nnetworkx:\n  ### NetworkX configuration ###\n  some_config: some_value # placeholder for technical reasons TODO\n\n#---- CSV (Comma-Separated Values) text file format\ncsv:\n  ### CSV/Pandas configuration ###\n  delimiter: \",\"\n</code></pre>"},{"location":"reference/biocypher-config-guide/#fields-reference","title":"Fields reference:","text":""},{"location":"reference/biocypher-config-guide/#biocypher-section-parameters","title":"Biocypher section parameters","text":""},{"location":"reference/biocypher-config-guide/#required-parameters","title":"Required parameters","text":""},{"location":"reference/biocypher-config-guide/#dbms","title":"<code>dbms</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#head_ontology","title":"<code>head_ontology</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#offline","title":"<code>offline</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#root_node","title":"<code>root_node</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#schema_config_path","title":"<code>schema_config_path</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#strict_mode","title":"<code>strict_mode</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#switch_label_and_id","title":"<code>switch_label_and_id</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#url","title":"<code>url</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#optional-parameters","title":"Optional parameters","text":""},{"location":"reference/biocypher-config-guide/#cache_directory","title":"<code>cache_directory</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#debug","title":"<code>debug</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#log_directory","title":"<code>log_directory</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#log_to_disk","title":"<code>log_to_disk</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#output_directory","title":"<code>output_directory</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#switch_label_and_id_1","title":"<code>switch_label_and_id</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#tail_join_node","title":"<code>tail_join_node</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#tail_ontologies","title":"<code>tail_ontologies</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#url_1","title":"<code>url</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#output-configuration-parameters","title":"Output configuration parameters","text":""},{"location":"reference/biocypher-config-guide/#neo4j-dbms","title":"NEO4j DBMS","text":""},{"location":"reference/biocypher-config-guide/#array_delimiter","title":"<code>array_delimiter</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#database_name","title":"<code>database_name</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#delimiter","title":"<code>delimiter</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#import_call_bin_prefix","title":"<code>import_call_bin_prefix</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#import_call_file_prefix","title":"<code>import_call_file_prefix</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#multi_db","title":"<code>multi_db</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#password","title":"<code>password</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#quote_character","title":"<code>quote_character</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#skip_duplicate_nodes","title":"<code>skip_duplicate_nodes</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#skip_bad_relationships","title":"<code>skip_bad_relationships</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#uri","title":"<code>uri</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#user","title":"<code>user</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#wipe","title":"<code>wipe</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#postgresql-dbms","title":"PostgreSQL DBMS","text":""},{"location":"reference/biocypher-config-guide/#database_name_1","title":"<code>database_name</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#delimiter_1","title":"<code>delimiter</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#host","title":"<code>host</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#import_call_bin_prefix_1","title":"<code>import_call_bin_prefix</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#import_call_file_prefix_1","title":"<code>import_call_file_prefix</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#password_1","title":"<code>password</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#port","title":"<code>port</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#quote_character_1","title":"<code>quote_character</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#user_1","title":"<code>user</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#sqlite-dbms","title":"SQLite DBMS","text":""},{"location":"reference/biocypher-config-guide/#database_name_2","title":"<code>database_name</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#delimiter_2","title":"<code>delimiter</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#import_call_bin_prefix_2","title":"<code>import_call_bin_prefix</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#import_call_file_prefix_2","title":"<code>import_call_file_prefix</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#quote_character_2","title":"<code>quote_character</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#rdf-data-model","title":"RDF data model","text":""},{"location":"reference/biocypher-config-guide/#rdf_format","title":"<code>rdf_format</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#networkx-graph-data-model","title":"NetworkX graph data model","text":""},{"location":"reference/biocypher-config-guide/#some_config","title":"<code>some_config</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#networkx-graph-data-model_1","title":"NetworkX graph data model","text":""},{"location":"reference/biocypher-config-guide/#some_config_1","title":"<code>some_config</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/biocypher-config-guide/#csv-file-format","title":"CSV file format","text":""},{"location":"reference/biocypher-config-guide/#delimiter_3","title":"<code>delimiter</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/schema-config-guide/","title":"Schema Configuration Reference","text":""},{"location":"reference/schema-config-guide/#purpose","title":"Purpose:","text":""},{"location":"reference/schema-config-guide/#convention-for-naming","title":"Convention for naming:","text":""},{"location":"reference/schema-config-guide/#skeleton","title":"Skeleton:","text":"<pre><code>#-------------------------------------------------------------------\n#---- Title: Schema Configuration file example\n#---- Authors: &lt;author 1&gt;, &lt;author 2&gt;\n#---- Description: Schema to load information related to proteins, and \n#                  and their interactions.\n#\n#-------------------------------------------------------------------\n\n#-------------------------------------------------------------------\n#-------------------------      NODES      -------------------------\n#-------------------------------------------------------------------\n#=========    PARENT NODES\nprotein:\n  represented_as: node\n  preferred_id: [uniprot, entrez]\n  input_label: [uniprot_protein, entrez_protein]\n  properties:\n    sequence: str\n    description: str\n    taxon: str\n    mass: int\n\n#=========    INHERITED NODES\nprotein isoform:\n  is_a: protein\n  inherit_properties: true\n  represented_as: node\n  preferred_id: uniprot\n  input_label: uniprot_isoform\n\n#-------------------------------------------------------------------\n#------------------      RELATIONSHIPS (EDGES)     -----------------\n#-------------------------------------------------------------------\n#=========    PARENT EDGES\nprotein protein interaction:\n  is_a: pairwise molecular interaction\n  represented_as: edge\n  preferred_id: intact\n  input_label: interacts_with\n  properties:\n      method: str\n      source: str\n\n#=========    INHERITED EDGES\n\n#=========    EDGES AS NODES\n\n\n#--------------------------------------------------------------------\n#---- Dictionary of custom keywords: add additional keywords if you\n#     need it. Please document each new keyword as in the following \n#     template. DO NOT DELETE the hash symbol (#) in each line.\n\n# &lt;keyword's name&gt;\n#    Description:\n#    Possible values:\n#        - possible value 1 [*datatype*]\n#        - possible value 2 [*datatype*]\n#\n</code></pre>"},{"location":"reference/schema-config-guide/#fields-reference","title":"Fields reference:","text":""},{"location":"reference/schema-config-guide/#exclude_properties","title":"<code>exclude_properties</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/schema-config-guide/#inherit_properties","title":"<code>inherit_properties</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/schema-config-guide/#input_label","title":"<code>input_label</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/schema-config-guide/#is_a","title":"<code>is_a</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/schema-config-guide/#label_as_edge","title":"<code>label_as_edge</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/schema-config-guide/#preferred_id","title":"<code>preferred_id</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/schema-config-guide/#properties","title":"<code>properties</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/schema-config-guide/#represented_as","title":"<code>represented_as</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/schema-config-guide/#source","title":"<code>source</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/schema-config-guide/#synonym_for","title":"<code>synonym_for</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/schema-config-guide/#target","title":"<code>target</code>","text":"<ul> <li>Description: describe briefly the purpose of this property.</li> <li>Possible values:</li> <li>possible value 1 [datatype]</li> <li>possible value 2 [datatype]</li> </ul>"},{"location":"reference/schema-config-guide/#add-custom-fields","title":"Add custom fields","text":"<p>Tip</p> <p>Do not forget to document your custom keywords at the end of the schema config file, this is especially useful if you share your schema configuration file with others. They will understand what is the purpose of those new keywords.</p> <p>You can use other keywords for local functionalities without interfering with the default ones. For instance, a particular user has added the <code>db_collection_name</code> field for its own purposes. </p> Example: schema configuration with a custom keyword<pre><code>#...\nprotein:\n  represented_as: node\n  preferred_id: uniprot\n  input_label: protein\n  db_collection_name: proteins\n  properties:\n    name: str\n    score: float\n    taxon: int\n    genes: str[]\n#...\n</code></pre>"},{"location":"reference/source/","title":"BioCypher","text":""},{"location":"reference/source/#modules","title":"Modules","text":""},{"location":"reference/source/#_corepy","title":"_core.py","text":"<p>BioCypher core module. Interfaces with the user and distributes tasks to submodules.</p>"},{"location":"reference/source/#biocypher._core.BioCypher","title":"<code>BioCypher</code>","text":"<p>Orchestration of BioCypher operations. Instantiate this class to interact with BioCypher.</p> <p>Args:</p> <pre><code>dbms (str): The database management system to use. For supported\n    systems see SUPPORTED_DBMS.\n\noffline (bool): Whether to run in offline mode. If True, no\n    connection to the database will be made.\n\nstrict_mode (bool): Whether to run in strict mode. If True, the\n    translator will raise an error if a node or edge does not\n    provide source, version, and licence information.\n\nbiocypher_config_path (str): Path to the BioCypher config file.\n\nschema_config_path (str): Path to the user schema config\n    file.\n\nhead_ontology (dict): The head ontology defined by URL ('url') and root\n    node ('root_node').\n\ntail_ontologies (dict): The tail ontologies defined by URL and\n    join nodes for both head and tail ontology.\n\noutput_directory (str): Path to the output directory. If not\n    provided, the default value 'biocypher-out' will be used.\n</code></pre> Source code in <code>biocypher/_core.py</code> <pre><code>class BioCypher:\n    \"\"\"\n    Orchestration of BioCypher operations. Instantiate this class to interact\n    with BioCypher.\n\n    Args:\n\n        dbms (str): The database management system to use. For supported\n            systems see SUPPORTED_DBMS.\n\n        offline (bool): Whether to run in offline mode. If True, no\n            connection to the database will be made.\n\n        strict_mode (bool): Whether to run in strict mode. If True, the\n            translator will raise an error if a node or edge does not\n            provide source, version, and licence information.\n\n        biocypher_config_path (str): Path to the BioCypher config file.\n\n        schema_config_path (str): Path to the user schema config\n            file.\n\n        head_ontology (dict): The head ontology defined by URL ('url') and root\n            node ('root_node').\n\n        tail_ontologies (dict): The tail ontologies defined by URL and\n            join nodes for both head and tail ontology.\n\n        output_directory (str): Path to the output directory. If not\n            provided, the default value 'biocypher-out' will be used.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        dbms: str = None,\n        offline: bool = None,\n        strict_mode: bool = None,\n        biocypher_config_path: str = None,\n        schema_config_path: str = None,\n        head_ontology: dict = None,\n        tail_ontologies: dict = None,\n        output_directory: str = None,\n        cache_directory: str = None,\n        # legacy params\n        db_name: str = None,\n    ):\n        # Update configuration if custom path is provided\n        if biocypher_config_path:\n            _file_update(biocypher_config_path)\n\n        if db_name:\n            logger.warning(\n                \"The parameter `db_name` is deprecated. Please set the \"\n                \"`database_name` setting in the `biocypher_config.yaml` file \"\n                \"instead.\"\n            )\n            _config(**{db_name: {\"database_name\": db_name}})\n\n        # Load configuration\n        self.base_config = _config(\"biocypher\")\n\n        # Check for required configuration\n        for key in REQUIRED_CONFIG:\n            if key not in self.base_config:\n                raise ValueError(f\"Configuration key {key} is required.\")\n\n        # Set configuration - mandatory\n        self._dbms = dbms or self.base_config[\"dbms\"]\n\n        if offline is None:\n            self._offline = self.base_config[\"offline\"]\n        else:\n            self._offline = offline\n\n        if strict_mode is None:\n            self._strict_mode = self.base_config[\"strict_mode\"]\n        else:\n            self._strict_mode = strict_mode\n\n        self._schema_config_path = schema_config_path or self.base_config.get(\n            \"schema_config_path\"\n        )\n\n        if not self._schema_config_path:\n            logger.warning(\"Running BioCypher without schema configuration.\")\n        else:\n            logger.info(\n                f\"Running BioCypher with schema configuration from {self._schema_config_path}.\"\n            )\n\n        self._head_ontology = head_ontology or self.base_config[\"head_ontology\"]\n\n        # Set configuration - optional\n        self._output_directory = output_directory or self.base_config.get(\n            \"output_directory\"\n        )\n        self._cache_directory = cache_directory or self.base_config.get(\n            \"cache_directory\"\n        )\n        self._tail_ontologies = tail_ontologies or self.base_config.get(\n            \"tail_ontologies\"\n        )\n\n        if self._dbms not in SUPPORTED_DBMS:\n            raise ValueError(\n                f\"DBMS {self._dbms} not supported. \"\n                f\"Please select from {SUPPORTED_DBMS}.\"\n            )\n\n        # Initialize\n        self._ontology_mapping = None\n        self._deduplicator = None\n        self._translator = None\n        self._downloader = None\n        self._ontology = None\n        self._writer = None\n        self._pd = None\n\n    def _get_deduplicator(self) -&gt; Deduplicator:\n        \"\"\"\n        Create deduplicator if not exists and return.\n        \"\"\"\n\n        if not self._deduplicator:\n            self._deduplicator = Deduplicator()\n\n        return self._deduplicator\n\n    def _get_ontology_mapping(self) -&gt; OntologyMapping:\n        \"\"\"\n        Create ontology mapping if not exists and return.\n        \"\"\"\n\n        if not self._schema_config_path:\n            self._ontology_mapping = OntologyMapping()\n\n        if not self._ontology_mapping:\n            self._ontology_mapping = OntologyMapping(\n                config_file=self._schema_config_path,\n            )\n\n        return self._ontology_mapping\n\n    def _get_ontology(self) -&gt; Ontology:\n        \"\"\"\n        Create ontology if not exists and return.\n        \"\"\"\n\n        if not self._ontology:\n            self._ontology = Ontology(\n                ontology_mapping=self._get_ontology_mapping(),\n                head_ontology=self._head_ontology,\n                tail_ontologies=self._tail_ontologies,\n            )\n\n        return self._ontology\n\n    def _get_translator(self) -&gt; Translator:\n        \"\"\"\n        Create translator if not exists and return.\n        \"\"\"\n\n        if not self._translator:\n            self._translator = Translator(\n                ontology=self._get_ontology(),\n                strict_mode=self._strict_mode,\n            )\n\n        return self._translator\n\n    def _get_writer(self):\n        \"\"\"\n        Create writer if not online. Set as instance variable `self._writer`.\n        \"\"\"\n\n        if self._offline:\n            timestamp = lambda: datetime.now().strftime(\"%Y%m%d%H%M%S\")\n            outdir = self._output_directory or os.path.join(\n                \"biocypher-out\", timestamp()\n            )\n            self._output_directory = os.path.abspath(outdir)\n\n            self._writer = get_writer(\n                dbms=self._dbms,\n                translator=self._get_translator(),\n                deduplicator=self._get_deduplicator(),\n                output_directory=self._output_directory,\n                strict_mode=self._strict_mode,\n            )\n        else:\n            raise NotImplementedError(\"Cannot get writer in online mode.\")\n\n    def _get_driver(self):\n        \"\"\"\n        Create driver if not exists. Set as instance variable `self._driver`.\n        \"\"\"\n\n        if not self._offline:\n            self._driver = get_driver(\n                dbms=self._dbms,\n                translator=self._get_translator(),\n                deduplicator=self._get_deduplicator(),\n            )\n        else:\n            raise NotImplementedError(\"Cannot get driver in offline mode.\")\n\n    def write_nodes(\n        self, nodes, batch_size: int = int(1e6), force: bool = False\n    ) -&gt; bool:\n        \"\"\"\n        Write nodes to database. Either takes an iterable of tuples (if given,\n        translates to ``BioCypherNode`` objects) or an iterable of\n        ``BioCypherNode`` objects.\n\n        Args:\n            nodes (iterable): An iterable of nodes to write to the database.\n\n            batch_size (int): The batch size to use when writing to disk.\n\n            force (bool): Whether to force writing to the output directory even\n                if the node type is not present in the schema config file.\n\n        Returns:\n            bool: True if successful.\n        \"\"\"\n\n        if not self._writer:\n            self._get_writer()\n\n        nodes = peekable(nodes)\n        if not isinstance(nodes.peek(), BioCypherNode):\n            tnodes = self._translator.translate_nodes(nodes)\n        else:\n            tnodes = nodes\n        # write node files\n        return self._writer.write_nodes(\n            tnodes, batch_size=batch_size, force=force\n        )\n\n    def write_edges(self, edges, batch_size: int = int(1e6)) -&gt; bool:\n        \"\"\"\n        Write edges to database. Either takes an iterable of tuples (if given,\n        translates to ``BioCypherEdge`` objects) or an iterable of\n        ``BioCypherEdge`` objects.\n\n        Args:\n            edges (iterable): An iterable of edges to write to the database.\n\n        Returns:\n            bool: True if successful.\n        \"\"\"\n\n        if not self._writer:\n            self._get_writer()\n\n        edges = peekable(edges)\n        if not isinstance(edges.peek(), BioCypherEdge):\n            tedges = self._translator.translate_edges(edges)\n        else:\n            tedges = edges\n        # write edge files\n        return self._writer.write_edges(tedges, batch_size=batch_size)\n\n    def to_df(self) -&gt; list[pd.DataFrame]:\n        \"\"\"\n        Convert entities to a pandas DataFrame for each entity type and return\n        a list.\n\n        Args:\n            entities (iterable): An iterable of entities to convert to a\n                DataFrame.\n\n        Returns:\n            pd.DataFrame: A pandas DataFrame.\n        \"\"\"\n        if not self._pd:\n            raise ValueError(\n                \"No pandas instance found. Please call `add()` first.\"\n            )\n\n        return self._pd.dfs\n\n    def add(self, entities) -&gt; None:\n        \"\"\"\n        Function to add entities to the in-memory database. Accepts an iterable\n        of tuples (if given, translates to ``BioCypherNode`` or\n        ``BioCypherEdge`` objects) or an iterable of ``BioCypherNode`` or\n        ``BioCypherEdge`` objects.\n\n        Args:\n            entities (iterable): An iterable of entities to add to the database.\n                Can be 3-tuples (nodes) or 5-tuples (edges); also accepts\n                4-tuples for edges (deprecated).\n\n        Returns:\n            None\n        \"\"\"\n        if not self._pd:\n            self._pd = Pandas(\n                translator=self._get_translator(),\n                deduplicator=self._get_deduplicator(),\n            )\n\n        entities = peekable(entities)\n\n        if (\n            isinstance(entities.peek(), BioCypherNode)\n            or isinstance(entities.peek(), BioCypherEdge)\n            or isinstance(entities.peek(), BioCypherRelAsNode)\n        ):\n            tentities = entities\n        elif len(entities.peek()) &lt; 4:\n            tentities = self._translator.translate_nodes(entities)\n        else:\n            tentities = self._translator.translate_edges(entities)\n\n        self._pd.add_tables(tentities)\n\n    def add_nodes(self, nodes) -&gt; None:\n        \"\"\"\n        Wrapper for ``add()`` to add nodes to the in-memory database.\n\n        Args:\n            nodes (iterable): An iterable of node tuples to add to the database.\n\n        Returns:\n            None\n        \"\"\"\n        self.add(nodes)\n\n    def add_edges(self, edges) -&gt; None:\n        \"\"\"\n        Wrapper for ``add()`` to add edges to the in-memory database.\n\n        Args:\n            edges (iterable): An iterable of edge tuples to add to the database.\n\n        Returns:\n            None\n        \"\"\"\n        self.add(edges)\n\n    def merge_nodes(self, nodes) -&gt; bool:\n        \"\"\"\n        Merge nodes into database. Either takes an iterable of tuples (if given,\n        translates to ``BioCypherNode`` objects) or an iterable of\n        ``BioCypherNode`` objects.\n\n        Args:\n            nodes (iterable): An iterable of nodes to merge into the database.\n\n        Returns:\n            bool: True if successful.\n        \"\"\"\n\n        if not self._driver:\n            self._get_driver()\n\n        nodes = peekable(nodes)\n        if not isinstance(nodes.peek(), BioCypherNode):\n            tnodes = self._translator.translate_nodes(nodes)\n        else:\n            tnodes = nodes\n        # write node files\n        return self._driver.add_biocypher_nodes(tnodes)\n\n    def merge_edges(self, edges) -&gt; bool:\n        \"\"\"\n        Merge edges into database. Either takes an iterable of tuples (if given,\n        translates to ``BioCypherEdge`` objects) or an iterable of\n        ``BioCypherEdge`` objects.\n\n        Args:\n            edges (iterable): An iterable of edges to merge into the database.\n\n        Returns:\n            bool: True if successful.\n        \"\"\"\n\n        if not self._driver:\n            self._get_driver()\n\n        edges = peekable(edges)\n        if not isinstance(edges.peek(), BioCypherEdge):\n            tedges = self._translator.translate_edges(edges)\n        else:\n            tedges = edges\n        # write edge files\n        return self._driver.add_biocypher_edges(tedges)\n\n    # DOWNLOAD AND CACHE MANAGEMENT METHODS ###\n\n    def _get_downloader(self, cache_dir: Optional[str] = None):\n        \"\"\"\n        Create downloader if not exists.\n        \"\"\"\n\n        if not self._downloader:\n            self._downloader = Downloader(self._cache_directory)\n\n    def download(self, *resources) -&gt; None:\n        \"\"\"\n        Use the :class:`Downloader` class to download or load from cache the\n        resources given by the adapter.\n        \"\"\"\n\n        self._get_downloader()\n        return self._downloader.download(*resources)\n\n    # OVERVIEW AND CONVENIENCE METHODS ###\n\n    def log_missing_input_labels(self) -&gt; Optional[dict[str, list[str]]]:\n        \"\"\"\n\n        Get the set of input labels encountered without an entry in the\n        `schema_config.yaml` and print them to the logger.\n\n        Returns:\n\n            Optional[Dict[str, List[str]]]: A dictionary of Biolink types\n            encountered without an entry in the `schema_config.yaml` file.\n\n        \"\"\"\n\n        mt = self._translator.get_missing_biolink_types()\n\n        if mt:\n            msg = (\n                \"Input entities not accounted for due to them not being \"\n                f\"present in the schema configuration file {self._schema_config_path} \"\n                \"(this is not necessarily a problem, if you did not intend \"\n                \"to include them in the database; see the log for details): \\n\"\n            )\n            for k, v in mt.items():\n                msg += f\"    {k}: {v} \\n\"\n\n            logger.info(msg)\n            return mt\n\n        else:\n            logger.info(\"No missing labels in input.\")\n            return None\n\n    def log_duplicates(self) -&gt; None:\n        \"\"\"\n        Get the set of duplicate nodes and edges encountered and print them to\n        the logger.\n        \"\"\"\n\n        dn = self._deduplicator.get_duplicate_nodes()\n\n        if dn:\n            ntypes = dn[0]\n            nids = dn[1]\n\n            msg = \"Duplicate node types encountered (IDs in log): \\n\"\n            for typ in ntypes:\n                msg += f\"    {typ}\\n\"\n\n            logger.info(msg)\n\n            idmsg = \"Duplicate node IDs encountered: \\n\"\n            for _id in nids:\n                idmsg += f\"    {_id}\\n\"\n\n            logger.debug(idmsg)\n\n        else:\n            logger.info(\"No duplicate nodes in input.\")\n\n        de = self._deduplicator.get_duplicate_edges()\n\n        if de:\n            etypes = de[0]\n            eids = de[1]\n\n            msg = \"Duplicate edge types encountered (IDs in log): \\n\"\n            for typ in etypes:\n                msg += f\"    {typ}\\n\"\n\n            logger.info(msg)\n\n            idmsg = \"Duplicate edge IDs encountered: \\n\"\n            for _id in eids:\n                idmsg += f\"    {_id}\\n\"\n\n            logger.debug(idmsg)\n\n        else:\n            logger.info(\"No duplicate edges in input.\")\n\n    def show_ontology_structure(self, **kwargs) -&gt; None:\n        \"\"\"\n        Show the ontology structure using treelib or write to GRAPHML file.\n\n        Args:\n\n            to_disk (str): If specified, the ontology structure will be saved\n                to disk as a GRAPHML file, to be opened in your favourite\n                graph visualisation tool.\n\n            full (bool): If True, the full ontology structure will be shown,\n                including all nodes and edges. If False, only the nodes and\n                edges that are relevant to the extended schema will be shown.\n        \"\"\"\n\n        if not self._ontology:\n            self._get_ontology()\n\n        return self._ontology.show_ontology_structure(**kwargs)\n\n    def write_import_call(self) -&gt; str:\n        \"\"\"\n        Write a shell script to import the database depending on the chosen\n        DBMS.\n\n        Returns:\n            str: path toward the file holding the import call.\n        \"\"\"\n\n        if not self._offline:\n            raise NotImplementedError(\n                \"Cannot write import call in online mode.\"\n            )\n\n        return self._writer.write_import_call()\n\n    def write_schema_info(self, as_node: bool = False) -&gt; None:\n        \"\"\"\n        Write an extended schema info YAML file that extends the\n        `schema_config.yaml` with run-time information of the built KG. For\n        instance, include information on whether something present in the actual\n        knowledge graph, whether it is a relationship (which is important in the\n        case of representing relationships as nodes) and the actual sources and\n        targets of edges. Since this file can be used in place of the original\n        `schema_config.yaml` file, it indicates that it is the extended schema\n        by setting `is_schema_info` to `true`.\n\n        We start by using the `extended_schema` dictionary from the ontology\n        class instance, which contains all expanded entities and relationships.\n        The information of whether something is a relationship can be gathered\n        from the deduplicator instance, which keeps track of all entities that\n        have been seen.\n        \"\"\"\n\n        if not self._offline:\n            raise NotImplementedError(\n                \"Cannot write schema info in online mode.\"\n            )\n\n        ontology = self._get_ontology()\n        schema = ontology.mapping.extended_schema.copy()\n        schema[\"is_schema_info\"] = True\n\n        deduplicator = self._get_deduplicator()\n        for node in deduplicator.entity_types:\n            if node in schema.keys():\n                schema[node][\"present_in_knowledge_graph\"] = True\n                schema[node][\"is_relationship\"] = False\n            else:\n                logger.info(\n                    f\"Node {node} not present in extended schema. \"\n                    \"Skipping schema info.\"\n                )\n\n        # find 'label_as_edge' cases in schema entries\n        changed_labels = {}\n        for k, v in schema.items():\n            if not isinstance(v, dict):\n                continue\n            if \"label_as_edge\" in v.keys():\n                if v[\"label_as_edge\"] in deduplicator.seen_relationships.keys():\n                    changed_labels[v[\"label_as_edge\"]] = k\n\n        for edge in deduplicator.seen_relationships.keys():\n            if edge in changed_labels.keys():\n                edge = changed_labels[edge]\n            if edge in schema.keys():\n                schema[edge][\"present_in_knowledge_graph\"] = True\n                schema[edge][\"is_relationship\"] = True\n                # TODO information about source and target nodes\n            else:\n                logger.info(\n                    f\"Edge {edge} not present in extended schema. \"\n                    \"Skipping schema info.\"\n                )\n\n        # write to output directory as YAML file\n        path = os.path.join(self._output_directory, \"schema_info.yaml\")\n        with open(path, \"w\") as f:\n            f.write(yaml.dump(schema))\n\n        if as_node:\n            # write as node\n            node = BioCypherNode(\n                node_id=\"schema_info\",\n                node_label=\"schema_info\",\n                properties={\"schema_info\": json.dumps(schema)},\n            )\n            self.write_nodes([node], force=True)\n\n            # override import call with added schema info node\n            self.write_import_call()\n\n        return schema\n\n    # TRANSLATION METHODS ###\n\n    def translate_term(self, term: str) -&gt; str:\n        \"\"\"\n        Translate a term to its BioCypher equivalent.\n\n        Args:\n            term (str): The term to translate.\n\n        Returns:\n            str: The BioCypher equivalent of the term.\n        \"\"\"\n\n        # instantiate adapter if not exists\n        self.start_ontology()\n\n        return self._translator.translate_term(term)\n\n    def summary(self) -&gt; None:\n        \"\"\"\n        Wrapper for showing ontology structure and logging duplicates and\n        missing input types.\n        \"\"\"\n\n        self.show_ontology_structure()\n        self.log_duplicates()\n        self.log_missing_input_labels()\n\n    def reverse_translate_term(self, term: str) -&gt; str:\n        \"\"\"\n        Reverse translate a term from its BioCypher equivalent.\n\n        Args:\n            term (str): The BioCypher term to reverse translate.\n\n        Returns:\n            str: The original term.\n        \"\"\"\n\n        # instantiate adapter if not exists\n        self.start_ontology()\n\n        return self._translator.reverse_translate_term(term)\n\n    def translate_query(self, query: str) -&gt; str:\n        \"\"\"\n        Translate a query to its BioCypher equivalent.\n\n        Args:\n            query (str): The query to translate.\n\n        Returns:\n            str: The BioCypher equivalent of the query.\n        \"\"\"\n\n        # instantiate adapter if not exists\n        self.start_ontology()\n\n        return self._translator.translate(query)\n\n    def reverse_translate_query(self, query: str) -&gt; str:\n        \"\"\"\n        Reverse translate a query from its BioCypher equivalent.\n\n        Args:\n            query (str): The BioCypher query to reverse translate.\n\n        Returns:\n            str: The original query.\n        \"\"\"\n\n        # instantiate adapter if not exists\n        self.start_ontology()\n\n        return self._translator.reverse_translate(query)\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher._get_deduplicator","title":"<code>_get_deduplicator()</code>","text":"<p>Create deduplicator if not exists and return.</p> Source code in <code>biocypher/_core.py</code> <pre><code>def _get_deduplicator(self) -&gt; Deduplicator:\n    \"\"\"\n    Create deduplicator if not exists and return.\n    \"\"\"\n\n    if not self._deduplicator:\n        self._deduplicator = Deduplicator()\n\n    return self._deduplicator\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher._get_downloader","title":"<code>_get_downloader(cache_dir=None)</code>","text":"<p>Create downloader if not exists.</p> Source code in <code>biocypher/_core.py</code> <pre><code>def _get_downloader(self, cache_dir: Optional[str] = None):\n    \"\"\"\n    Create downloader if not exists.\n    \"\"\"\n\n    if not self._downloader:\n        self._downloader = Downloader(self._cache_directory)\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher._get_driver","title":"<code>_get_driver()</code>","text":"<p>Create driver if not exists. Set as instance variable <code>self._driver</code>.</p> Source code in <code>biocypher/_core.py</code> <pre><code>def _get_driver(self):\n    \"\"\"\n    Create driver if not exists. Set as instance variable `self._driver`.\n    \"\"\"\n\n    if not self._offline:\n        self._driver = get_driver(\n            dbms=self._dbms,\n            translator=self._get_translator(),\n            deduplicator=self._get_deduplicator(),\n        )\n    else:\n        raise NotImplementedError(\"Cannot get driver in offline mode.\")\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher._get_ontology","title":"<code>_get_ontology()</code>","text":"<p>Create ontology if not exists and return.</p> Source code in <code>biocypher/_core.py</code> <pre><code>def _get_ontology(self) -&gt; Ontology:\n    \"\"\"\n    Create ontology if not exists and return.\n    \"\"\"\n\n    if not self._ontology:\n        self._ontology = Ontology(\n            ontology_mapping=self._get_ontology_mapping(),\n            head_ontology=self._head_ontology,\n            tail_ontologies=self._tail_ontologies,\n        )\n\n    return self._ontology\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher._get_ontology_mapping","title":"<code>_get_ontology_mapping()</code>","text":"<p>Create ontology mapping if not exists and return.</p> Source code in <code>biocypher/_core.py</code> <pre><code>def _get_ontology_mapping(self) -&gt; OntologyMapping:\n    \"\"\"\n    Create ontology mapping if not exists and return.\n    \"\"\"\n\n    if not self._schema_config_path:\n        self._ontology_mapping = OntologyMapping()\n\n    if not self._ontology_mapping:\n        self._ontology_mapping = OntologyMapping(\n            config_file=self._schema_config_path,\n        )\n\n    return self._ontology_mapping\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher._get_translator","title":"<code>_get_translator()</code>","text":"<p>Create translator if not exists and return.</p> Source code in <code>biocypher/_core.py</code> <pre><code>def _get_translator(self) -&gt; Translator:\n    \"\"\"\n    Create translator if not exists and return.\n    \"\"\"\n\n    if not self._translator:\n        self._translator = Translator(\n            ontology=self._get_ontology(),\n            strict_mode=self._strict_mode,\n        )\n\n    return self._translator\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher._get_writer","title":"<code>_get_writer()</code>","text":"<p>Create writer if not online. Set as instance variable <code>self._writer</code>.</p> Source code in <code>biocypher/_core.py</code> <pre><code>def _get_writer(self):\n    \"\"\"\n    Create writer if not online. Set as instance variable `self._writer`.\n    \"\"\"\n\n    if self._offline:\n        timestamp = lambda: datetime.now().strftime(\"%Y%m%d%H%M%S\")\n        outdir = self._output_directory or os.path.join(\n            \"biocypher-out\", timestamp()\n        )\n        self._output_directory = os.path.abspath(outdir)\n\n        self._writer = get_writer(\n            dbms=self._dbms,\n            translator=self._get_translator(),\n            deduplicator=self._get_deduplicator(),\n            output_directory=self._output_directory,\n            strict_mode=self._strict_mode,\n        )\n    else:\n        raise NotImplementedError(\"Cannot get writer in online mode.\")\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher.add","title":"<code>add(entities)</code>","text":"<p>Function to add entities to the in-memory database. Accepts an iterable of tuples (if given, translates to <code>BioCypherNode</code> or <code>BioCypherEdge</code> objects) or an iterable of <code>BioCypherNode</code> or <code>BioCypherEdge</code> objects.</p> <p>Parameters:</p> Name Type Description Default <code>entities</code> <code>iterable</code> <p>An iterable of entities to add to the database. Can be 3-tuples (nodes) or 5-tuples (edges); also accepts 4-tuples for edges (deprecated).</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>biocypher/_core.py</code> <pre><code>def add(self, entities) -&gt; None:\n    \"\"\"\n    Function to add entities to the in-memory database. Accepts an iterable\n    of tuples (if given, translates to ``BioCypherNode`` or\n    ``BioCypherEdge`` objects) or an iterable of ``BioCypherNode`` or\n    ``BioCypherEdge`` objects.\n\n    Args:\n        entities (iterable): An iterable of entities to add to the database.\n            Can be 3-tuples (nodes) or 5-tuples (edges); also accepts\n            4-tuples for edges (deprecated).\n\n    Returns:\n        None\n    \"\"\"\n    if not self._pd:\n        self._pd = Pandas(\n            translator=self._get_translator(),\n            deduplicator=self._get_deduplicator(),\n        )\n\n    entities = peekable(entities)\n\n    if (\n        isinstance(entities.peek(), BioCypherNode)\n        or isinstance(entities.peek(), BioCypherEdge)\n        or isinstance(entities.peek(), BioCypherRelAsNode)\n    ):\n        tentities = entities\n    elif len(entities.peek()) &lt; 4:\n        tentities = self._translator.translate_nodes(entities)\n    else:\n        tentities = self._translator.translate_edges(entities)\n\n    self._pd.add_tables(tentities)\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher.add_edges","title":"<code>add_edges(edges)</code>","text":"<p>Wrapper for <code>add()</code> to add edges to the in-memory database.</p> <p>Parameters:</p> Name Type Description Default <code>edges</code> <code>iterable</code> <p>An iterable of edge tuples to add to the database.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>biocypher/_core.py</code> <pre><code>def add_edges(self, edges) -&gt; None:\n    \"\"\"\n    Wrapper for ``add()`` to add edges to the in-memory database.\n\n    Args:\n        edges (iterable): An iterable of edge tuples to add to the database.\n\n    Returns:\n        None\n    \"\"\"\n    self.add(edges)\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher.add_nodes","title":"<code>add_nodes(nodes)</code>","text":"<p>Wrapper for <code>add()</code> to add nodes to the in-memory database.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>iterable</code> <p>An iterable of node tuples to add to the database.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>biocypher/_core.py</code> <pre><code>def add_nodes(self, nodes) -&gt; None:\n    \"\"\"\n    Wrapper for ``add()`` to add nodes to the in-memory database.\n\n    Args:\n        nodes (iterable): An iterable of node tuples to add to the database.\n\n    Returns:\n        None\n    \"\"\"\n    self.add(nodes)\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher.download","title":"<code>download(*resources)</code>","text":"<p>Use the :class:<code>Downloader</code> class to download or load from cache the resources given by the adapter.</p> Source code in <code>biocypher/_core.py</code> <pre><code>def download(self, *resources) -&gt; None:\n    \"\"\"\n    Use the :class:`Downloader` class to download or load from cache the\n    resources given by the adapter.\n    \"\"\"\n\n    self._get_downloader()\n    return self._downloader.download(*resources)\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher.log_duplicates","title":"<code>log_duplicates()</code>","text":"<p>Get the set of duplicate nodes and edges encountered and print them to the logger.</p> Source code in <code>biocypher/_core.py</code> <pre><code>def log_duplicates(self) -&gt; None:\n    \"\"\"\n    Get the set of duplicate nodes and edges encountered and print them to\n    the logger.\n    \"\"\"\n\n    dn = self._deduplicator.get_duplicate_nodes()\n\n    if dn:\n        ntypes = dn[0]\n        nids = dn[1]\n\n        msg = \"Duplicate node types encountered (IDs in log): \\n\"\n        for typ in ntypes:\n            msg += f\"    {typ}\\n\"\n\n        logger.info(msg)\n\n        idmsg = \"Duplicate node IDs encountered: \\n\"\n        for _id in nids:\n            idmsg += f\"    {_id}\\n\"\n\n        logger.debug(idmsg)\n\n    else:\n        logger.info(\"No duplicate nodes in input.\")\n\n    de = self._deduplicator.get_duplicate_edges()\n\n    if de:\n        etypes = de[0]\n        eids = de[1]\n\n        msg = \"Duplicate edge types encountered (IDs in log): \\n\"\n        for typ in etypes:\n            msg += f\"    {typ}\\n\"\n\n        logger.info(msg)\n\n        idmsg = \"Duplicate edge IDs encountered: \\n\"\n        for _id in eids:\n            idmsg += f\"    {_id}\\n\"\n\n        logger.debug(idmsg)\n\n    else:\n        logger.info(\"No duplicate edges in input.\")\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher.log_missing_input_labels","title":"<code>log_missing_input_labels()</code>","text":"<p>Get the set of input labels encountered without an entry in the <code>schema_config.yaml</code> and print them to the logger.</p> <p>Returns:</p> <pre><code>Optional[Dict[str, List[str]]]: A dictionary of Biolink types\nencountered without an entry in the `schema_config.yaml` file.\n</code></pre> Source code in <code>biocypher/_core.py</code> <pre><code>def log_missing_input_labels(self) -&gt; Optional[dict[str, list[str]]]:\n    \"\"\"\n\n    Get the set of input labels encountered without an entry in the\n    `schema_config.yaml` and print them to the logger.\n\n    Returns:\n\n        Optional[Dict[str, List[str]]]: A dictionary of Biolink types\n        encountered without an entry in the `schema_config.yaml` file.\n\n    \"\"\"\n\n    mt = self._translator.get_missing_biolink_types()\n\n    if mt:\n        msg = (\n            \"Input entities not accounted for due to them not being \"\n            f\"present in the schema configuration file {self._schema_config_path} \"\n            \"(this is not necessarily a problem, if you did not intend \"\n            \"to include them in the database; see the log for details): \\n\"\n        )\n        for k, v in mt.items():\n            msg += f\"    {k}: {v} \\n\"\n\n        logger.info(msg)\n        return mt\n\n    else:\n        logger.info(\"No missing labels in input.\")\n        return None\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher.merge_edges","title":"<code>merge_edges(edges)</code>","text":"<p>Merge edges into database. Either takes an iterable of tuples (if given, translates to <code>BioCypherEdge</code> objects) or an iterable of <code>BioCypherEdge</code> objects.</p> <p>Parameters:</p> Name Type Description Default <code>edges</code> <code>iterable</code> <p>An iterable of edges to merge into the database.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if successful.</p> Source code in <code>biocypher/_core.py</code> <pre><code>def merge_edges(self, edges) -&gt; bool:\n    \"\"\"\n    Merge edges into database. Either takes an iterable of tuples (if given,\n    translates to ``BioCypherEdge`` objects) or an iterable of\n    ``BioCypherEdge`` objects.\n\n    Args:\n        edges (iterable): An iterable of edges to merge into the database.\n\n    Returns:\n        bool: True if successful.\n    \"\"\"\n\n    if not self._driver:\n        self._get_driver()\n\n    edges = peekable(edges)\n    if not isinstance(edges.peek(), BioCypherEdge):\n        tedges = self._translator.translate_edges(edges)\n    else:\n        tedges = edges\n    # write edge files\n    return self._driver.add_biocypher_edges(tedges)\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher.merge_nodes","title":"<code>merge_nodes(nodes)</code>","text":"<p>Merge nodes into database. Either takes an iterable of tuples (if given, translates to <code>BioCypherNode</code> objects) or an iterable of <code>BioCypherNode</code> objects.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>iterable</code> <p>An iterable of nodes to merge into the database.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if successful.</p> Source code in <code>biocypher/_core.py</code> <pre><code>def merge_nodes(self, nodes) -&gt; bool:\n    \"\"\"\n    Merge nodes into database. Either takes an iterable of tuples (if given,\n    translates to ``BioCypherNode`` objects) or an iterable of\n    ``BioCypherNode`` objects.\n\n    Args:\n        nodes (iterable): An iterable of nodes to merge into the database.\n\n    Returns:\n        bool: True if successful.\n    \"\"\"\n\n    if not self._driver:\n        self._get_driver()\n\n    nodes = peekable(nodes)\n    if not isinstance(nodes.peek(), BioCypherNode):\n        tnodes = self._translator.translate_nodes(nodes)\n    else:\n        tnodes = nodes\n    # write node files\n    return self._driver.add_biocypher_nodes(tnodes)\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher.reverse_translate_query","title":"<code>reverse_translate_query(query)</code>","text":"<p>Reverse translate a query from its BioCypher equivalent.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The BioCypher query to reverse translate.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The original query.</p> Source code in <code>biocypher/_core.py</code> <pre><code>def reverse_translate_query(self, query: str) -&gt; str:\n    \"\"\"\n    Reverse translate a query from its BioCypher equivalent.\n\n    Args:\n        query (str): The BioCypher query to reverse translate.\n\n    Returns:\n        str: The original query.\n    \"\"\"\n\n    # instantiate adapter if not exists\n    self.start_ontology()\n\n    return self._translator.reverse_translate(query)\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher.reverse_translate_term","title":"<code>reverse_translate_term(term)</code>","text":"<p>Reverse translate a term from its BioCypher equivalent.</p> <p>Parameters:</p> Name Type Description Default <code>term</code> <code>str</code> <p>The BioCypher term to reverse translate.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The original term.</p> Source code in <code>biocypher/_core.py</code> <pre><code>def reverse_translate_term(self, term: str) -&gt; str:\n    \"\"\"\n    Reverse translate a term from its BioCypher equivalent.\n\n    Args:\n        term (str): The BioCypher term to reverse translate.\n\n    Returns:\n        str: The original term.\n    \"\"\"\n\n    # instantiate adapter if not exists\n    self.start_ontology()\n\n    return self._translator.reverse_translate_term(term)\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher.show_ontology_structure","title":"<code>show_ontology_structure(**kwargs)</code>","text":"<p>Show the ontology structure using treelib or write to GRAPHML file.</p> <p>Args:</p> <pre><code>to_disk (str): If specified, the ontology structure will be saved\n    to disk as a GRAPHML file, to be opened in your favourite\n    graph visualisation tool.\n\nfull (bool): If True, the full ontology structure will be shown,\n    including all nodes and edges. If False, only the nodes and\n    edges that are relevant to the extended schema will be shown.\n</code></pre> Source code in <code>biocypher/_core.py</code> <pre><code>def show_ontology_structure(self, **kwargs) -&gt; None:\n    \"\"\"\n    Show the ontology structure using treelib or write to GRAPHML file.\n\n    Args:\n\n        to_disk (str): If specified, the ontology structure will be saved\n            to disk as a GRAPHML file, to be opened in your favourite\n            graph visualisation tool.\n\n        full (bool): If True, the full ontology structure will be shown,\n            including all nodes and edges. If False, only the nodes and\n            edges that are relevant to the extended schema will be shown.\n    \"\"\"\n\n    if not self._ontology:\n        self._get_ontology()\n\n    return self._ontology.show_ontology_structure(**kwargs)\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher.summary","title":"<code>summary()</code>","text":"<p>Wrapper for showing ontology structure and logging duplicates and missing input types.</p> Source code in <code>biocypher/_core.py</code> <pre><code>def summary(self) -&gt; None:\n    \"\"\"\n    Wrapper for showing ontology structure and logging duplicates and\n    missing input types.\n    \"\"\"\n\n    self.show_ontology_structure()\n    self.log_duplicates()\n    self.log_missing_input_labels()\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher.to_df","title":"<code>to_df()</code>","text":"<p>Convert entities to a pandas DataFrame for each entity type and return a list.</p> <p>Parameters:</p> Name Type Description Default <code>entities</code> <code>iterable</code> <p>An iterable of entities to convert to a DataFrame.</p> required <p>Returns:</p> Type Description <code>list[DataFrame]</code> <p>pd.DataFrame: A pandas DataFrame.</p> Source code in <code>biocypher/_core.py</code> <pre><code>def to_df(self) -&gt; list[pd.DataFrame]:\n    \"\"\"\n    Convert entities to a pandas DataFrame for each entity type and return\n    a list.\n\n    Args:\n        entities (iterable): An iterable of entities to convert to a\n            DataFrame.\n\n    Returns:\n        pd.DataFrame: A pandas DataFrame.\n    \"\"\"\n    if not self._pd:\n        raise ValueError(\n            \"No pandas instance found. Please call `add()` first.\"\n        )\n\n    return self._pd.dfs\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher.translate_query","title":"<code>translate_query(query)</code>","text":"<p>Translate a query to its BioCypher equivalent.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The query to translate.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The BioCypher equivalent of the query.</p> Source code in <code>biocypher/_core.py</code> <pre><code>def translate_query(self, query: str) -&gt; str:\n    \"\"\"\n    Translate a query to its BioCypher equivalent.\n\n    Args:\n        query (str): The query to translate.\n\n    Returns:\n        str: The BioCypher equivalent of the query.\n    \"\"\"\n\n    # instantiate adapter if not exists\n    self.start_ontology()\n\n    return self._translator.translate(query)\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher.translate_term","title":"<code>translate_term(term)</code>","text":"<p>Translate a term to its BioCypher equivalent.</p> <p>Parameters:</p> Name Type Description Default <code>term</code> <code>str</code> <p>The term to translate.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The BioCypher equivalent of the term.</p> Source code in <code>biocypher/_core.py</code> <pre><code>def translate_term(self, term: str) -&gt; str:\n    \"\"\"\n    Translate a term to its BioCypher equivalent.\n\n    Args:\n        term (str): The term to translate.\n\n    Returns:\n        str: The BioCypher equivalent of the term.\n    \"\"\"\n\n    # instantiate adapter if not exists\n    self.start_ontology()\n\n    return self._translator.translate_term(term)\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher.write_edges","title":"<code>write_edges(edges, batch_size=int(1000000.0))</code>","text":"<p>Write edges to database. Either takes an iterable of tuples (if given, translates to <code>BioCypherEdge</code> objects) or an iterable of <code>BioCypherEdge</code> objects.</p> <p>Parameters:</p> Name Type Description Default <code>edges</code> <code>iterable</code> <p>An iterable of edges to write to the database.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if successful.</p> Source code in <code>biocypher/_core.py</code> <pre><code>def write_edges(self, edges, batch_size: int = int(1e6)) -&gt; bool:\n    \"\"\"\n    Write edges to database. Either takes an iterable of tuples (if given,\n    translates to ``BioCypherEdge`` objects) or an iterable of\n    ``BioCypherEdge`` objects.\n\n    Args:\n        edges (iterable): An iterable of edges to write to the database.\n\n    Returns:\n        bool: True if successful.\n    \"\"\"\n\n    if not self._writer:\n        self._get_writer()\n\n    edges = peekable(edges)\n    if not isinstance(edges.peek(), BioCypherEdge):\n        tedges = self._translator.translate_edges(edges)\n    else:\n        tedges = edges\n    # write edge files\n    return self._writer.write_edges(tedges, batch_size=batch_size)\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher.write_import_call","title":"<code>write_import_call()</code>","text":"<p>Write a shell script to import the database depending on the chosen DBMS.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>path toward the file holding the import call.</p> Source code in <code>biocypher/_core.py</code> <pre><code>def write_import_call(self) -&gt; str:\n    \"\"\"\n    Write a shell script to import the database depending on the chosen\n    DBMS.\n\n    Returns:\n        str: path toward the file holding the import call.\n    \"\"\"\n\n    if not self._offline:\n        raise NotImplementedError(\n            \"Cannot write import call in online mode.\"\n        )\n\n    return self._writer.write_import_call()\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher.write_nodes","title":"<code>write_nodes(nodes, batch_size=int(1000000.0), force=False)</code>","text":"<p>Write nodes to database. Either takes an iterable of tuples (if given, translates to <code>BioCypherNode</code> objects) or an iterable of <code>BioCypherNode</code> objects.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>iterable</code> <p>An iterable of nodes to write to the database.</p> required <code>batch_size</code> <code>int</code> <p>The batch size to use when writing to disk.</p> <code>int(1000000.0)</code> <code>force</code> <code>bool</code> <p>Whether to force writing to the output directory even if the node type is not present in the schema config file.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if successful.</p> Source code in <code>biocypher/_core.py</code> <pre><code>def write_nodes(\n    self, nodes, batch_size: int = int(1e6), force: bool = False\n) -&gt; bool:\n    \"\"\"\n    Write nodes to database. Either takes an iterable of tuples (if given,\n    translates to ``BioCypherNode`` objects) or an iterable of\n    ``BioCypherNode`` objects.\n\n    Args:\n        nodes (iterable): An iterable of nodes to write to the database.\n\n        batch_size (int): The batch size to use when writing to disk.\n\n        force (bool): Whether to force writing to the output directory even\n            if the node type is not present in the schema config file.\n\n    Returns:\n        bool: True if successful.\n    \"\"\"\n\n    if not self._writer:\n        self._get_writer()\n\n    nodes = peekable(nodes)\n    if not isinstance(nodes.peek(), BioCypherNode):\n        tnodes = self._translator.translate_nodes(nodes)\n    else:\n        tnodes = nodes\n    # write node files\n    return self._writer.write_nodes(\n        tnodes, batch_size=batch_size, force=force\n    )\n</code></pre>"},{"location":"reference/source/#biocypher._core.BioCypher.write_schema_info","title":"<code>write_schema_info(as_node=False)</code>","text":"<p>Write an extended schema info YAML file that extends the <code>schema_config.yaml</code> with run-time information of the built KG. For instance, include information on whether something present in the actual knowledge graph, whether it is a relationship (which is important in the case of representing relationships as nodes) and the actual sources and targets of edges. Since this file can be used in place of the original <code>schema_config.yaml</code> file, it indicates that it is the extended schema by setting <code>is_schema_info</code> to <code>true</code>.</p> <p>We start by using the <code>extended_schema</code> dictionary from the ontology class instance, which contains all expanded entities and relationships. The information of whether something is a relationship can be gathered from the deduplicator instance, which keeps track of all entities that have been seen.</p> Source code in <code>biocypher/_core.py</code> <pre><code>def write_schema_info(self, as_node: bool = False) -&gt; None:\n    \"\"\"\n    Write an extended schema info YAML file that extends the\n    `schema_config.yaml` with run-time information of the built KG. For\n    instance, include information on whether something present in the actual\n    knowledge graph, whether it is a relationship (which is important in the\n    case of representing relationships as nodes) and the actual sources and\n    targets of edges. Since this file can be used in place of the original\n    `schema_config.yaml` file, it indicates that it is the extended schema\n    by setting `is_schema_info` to `true`.\n\n    We start by using the `extended_schema` dictionary from the ontology\n    class instance, which contains all expanded entities and relationships.\n    The information of whether something is a relationship can be gathered\n    from the deduplicator instance, which keeps track of all entities that\n    have been seen.\n    \"\"\"\n\n    if not self._offline:\n        raise NotImplementedError(\n            \"Cannot write schema info in online mode.\"\n        )\n\n    ontology = self._get_ontology()\n    schema = ontology.mapping.extended_schema.copy()\n    schema[\"is_schema_info\"] = True\n\n    deduplicator = self._get_deduplicator()\n    for node in deduplicator.entity_types:\n        if node in schema.keys():\n            schema[node][\"present_in_knowledge_graph\"] = True\n            schema[node][\"is_relationship\"] = False\n        else:\n            logger.info(\n                f\"Node {node} not present in extended schema. \"\n                \"Skipping schema info.\"\n            )\n\n    # find 'label_as_edge' cases in schema entries\n    changed_labels = {}\n    for k, v in schema.items():\n        if not isinstance(v, dict):\n            continue\n        if \"label_as_edge\" in v.keys():\n            if v[\"label_as_edge\"] in deduplicator.seen_relationships.keys():\n                changed_labels[v[\"label_as_edge\"]] = k\n\n    for edge in deduplicator.seen_relationships.keys():\n        if edge in changed_labels.keys():\n            edge = changed_labels[edge]\n        if edge in schema.keys():\n            schema[edge][\"present_in_knowledge_graph\"] = True\n            schema[edge][\"is_relationship\"] = True\n            # TODO information about source and target nodes\n        else:\n            logger.info(\n                f\"Edge {edge} not present in extended schema. \"\n                \"Skipping schema info.\"\n            )\n\n    # write to output directory as YAML file\n    path = os.path.join(self._output_directory, \"schema_info.yaml\")\n    with open(path, \"w\") as f:\n        f.write(yaml.dump(schema))\n\n    if as_node:\n        # write as node\n        node = BioCypherNode(\n            node_id=\"schema_info\",\n            node_label=\"schema_info\",\n            properties={\"schema_info\": json.dumps(schema)},\n        )\n        self.write_nodes([node], force=True)\n\n        # override import call with added schema info node\n        self.write_import_call()\n\n    return schema\n</code></pre>"},{"location":"reference/source/#_createpy","title":"_create.py","text":"<p>BioCypher 'create' module. Handles the creation of BioCypher node and edge dataclasses.</p>"},{"location":"reference/source/#biocypher._create.BioCypherEdge","title":"<code>BioCypherEdge</code>  <code>dataclass</code>","text":"<p>Handoff class to represent biomedical relationships in Neo4j.</p> <p>Has source and target ids, label, property dict; ids and label (in the Neo4j sense of a label, ie, the entity descriptor after the colon, such as \":TARGETS\") are non-optional and called source_id, target_id, and relationship_label to avoid confusion with properties called \"label\", which usually denotes the human-readable form. Relationship labels are written in UPPERCASE and as verbs, as per Neo4j consensus.</p> <p>Args:</p> <pre><code>source_id (string): consensus \"best\" id for biological entity\n\ntarget_id (string): consensus \"best\" id for biological entity\n\nrelationship_label (string): type of interaction, UPPERCASE\n\nproperties (dict): collection of all other properties of the\nrespective edge\n</code></pre> Source code in <code>biocypher/_create.py</code> <pre><code>@dataclass(frozen=True)\nclass BioCypherEdge:\n    \"\"\"\n    Handoff class to represent biomedical relationships in Neo4j.\n\n    Has source and target ids, label, property dict; ids and label (in\n    the Neo4j sense of a label, ie, the entity descriptor after the\n    colon, such as \":TARGETS\") are non-optional and called source_id,\n    target_id, and relationship_label to avoid confusion with properties\n    called \"label\", which usually denotes the human-readable form.\n    Relationship labels are written in UPPERCASE and as verbs, as per\n    Neo4j consensus.\n\n    Args:\n\n        source_id (string): consensus \"best\" id for biological entity\n\n        target_id (string): consensus \"best\" id for biological entity\n\n        relationship_label (string): type of interaction, UPPERCASE\n\n        properties (dict): collection of all other properties of the\n        respective edge\n\n    \"\"\"\n\n    source_id: str\n    target_id: str\n    relationship_label: str\n    relationship_id: str = None\n    properties: dict = field(default_factory=dict)\n\n    def __post_init__(self):\n        \"\"\"\n        Check for reserved keywords.\n        \"\"\"\n\n        if \":TYPE\" in self.properties.keys():\n            logger.debug(\n                \"Keyword ':TYPE' is reserved for Neo4j. \"\n                \"Removing from properties.\",\n                # \"Renaming to 'type'.\"\n            )\n            # self.properties[\"type\"] = self.properties[\":TYPE\"]\n            del self.properties[\":TYPE\"]\n        elif \"id\" in self.properties.keys():\n            logger.debug(\n                \"Keyword 'id' is reserved for Neo4j. \"\n                \"Removing from properties.\",\n                # \"Renaming to 'type'.\"\n            )\n            # self.properties[\"type\"] = self.properties[\":TYPE\"]\n            del self.properties[\"id\"]\n        elif \"_ID\" in self.properties.keys():\n            logger.debug(\n                \"Keyword '_ID' is reserved for Postgres. \"\n                \"Removing from properties.\",\n                # \"Renaming to 'type'.\"\n            )\n            # self.properties[\"type\"] = self.properties[\":TYPE\"]\n            del self.properties[\"_ID\"]\n\n    def get_id(self) -&gt; Union[str, None]:\n        \"\"\"\n        Returns primary node identifier or None.\n\n        Returns:\n            str: node_id\n        \"\"\"\n\n        return self.relationship_id\n\n    def get_source_id(self) -&gt; str:\n        \"\"\"\n        Returns primary node identifier of relationship source.\n\n        Returns:\n            str: source_id\n        \"\"\"\n        return self.source_id\n\n    def get_target_id(self) -&gt; str:\n        \"\"\"\n        Returns primary node identifier of relationship target.\n\n        Returns:\n            str: target_id\n        \"\"\"\n        return self.target_id\n\n    def get_label(self) -&gt; str:\n        \"\"\"\n        Returns relationship label.\n\n        Returns:\n            str: relationship_label\n        \"\"\"\n        return self.relationship_label\n\n    def get_type(self) -&gt; str:\n        \"\"\"\n        Returns relationship label.\n\n        Returns:\n            str: relationship_label\n        \"\"\"\n        return self.relationship_label\n\n    def get_properties(self) -&gt; dict:\n        \"\"\"\n        Returns all other relationship properties apart from primary ids\n        and label as key-value pairs.\n\n        Returns:\n            dict: properties\n        \"\"\"\n        return self.properties\n\n    def get_dict(self) -&gt; dict:\n        \"\"\"\n        Return dict of ids, label, and properties.\n\n        Returns:\n            dict: source_id, target_id and relationship_label as\n                top-level key-value pairs, properties as second-level\n                dict.\n        \"\"\"\n        return {\n            \"relationship_id\": self.relationship_id or None,\n            \"source_id\": self.source_id,\n            \"target_id\": self.target_id,\n            \"relationship_label\": self.relationship_label,\n            \"properties\": self.properties,\n        }\n</code></pre>"},{"location":"reference/source/#biocypher._create.BioCypherEdge.__post_init__","title":"<code>__post_init__()</code>","text":"<p>Check for reserved keywords.</p> Source code in <code>biocypher/_create.py</code> <pre><code>def __post_init__(self):\n    \"\"\"\n    Check for reserved keywords.\n    \"\"\"\n\n    if \":TYPE\" in self.properties.keys():\n        logger.debug(\n            \"Keyword ':TYPE' is reserved for Neo4j. \"\n            \"Removing from properties.\",\n            # \"Renaming to 'type'.\"\n        )\n        # self.properties[\"type\"] = self.properties[\":TYPE\"]\n        del self.properties[\":TYPE\"]\n    elif \"id\" in self.properties.keys():\n        logger.debug(\n            \"Keyword 'id' is reserved for Neo4j. \"\n            \"Removing from properties.\",\n            # \"Renaming to 'type'.\"\n        )\n        # self.properties[\"type\"] = self.properties[\":TYPE\"]\n        del self.properties[\"id\"]\n    elif \"_ID\" in self.properties.keys():\n        logger.debug(\n            \"Keyword '_ID' is reserved for Postgres. \"\n            \"Removing from properties.\",\n            # \"Renaming to 'type'.\"\n        )\n        # self.properties[\"type\"] = self.properties[\":TYPE\"]\n        del self.properties[\"_ID\"]\n</code></pre>"},{"location":"reference/source/#biocypher._create.BioCypherEdge.get_dict","title":"<code>get_dict()</code>","text":"<p>Return dict of ids, label, and properties.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>source_id, target_id and relationship_label as top-level key-value pairs, properties as second-level dict.</p> Source code in <code>biocypher/_create.py</code> <pre><code>def get_dict(self) -&gt; dict:\n    \"\"\"\n    Return dict of ids, label, and properties.\n\n    Returns:\n        dict: source_id, target_id and relationship_label as\n            top-level key-value pairs, properties as second-level\n            dict.\n    \"\"\"\n    return {\n        \"relationship_id\": self.relationship_id or None,\n        \"source_id\": self.source_id,\n        \"target_id\": self.target_id,\n        \"relationship_label\": self.relationship_label,\n        \"properties\": self.properties,\n    }\n</code></pre>"},{"location":"reference/source/#biocypher._create.BioCypherEdge.get_id","title":"<code>get_id()</code>","text":"<p>Returns primary node identifier or None.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>Union[str, None]</code> <p>node_id</p> Source code in <code>biocypher/_create.py</code> <pre><code>def get_id(self) -&gt; Union[str, None]:\n    \"\"\"\n    Returns primary node identifier or None.\n\n    Returns:\n        str: node_id\n    \"\"\"\n\n    return self.relationship_id\n</code></pre>"},{"location":"reference/source/#biocypher._create.BioCypherEdge.get_label","title":"<code>get_label()</code>","text":"<p>Returns relationship label.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>relationship_label</p> Source code in <code>biocypher/_create.py</code> <pre><code>def get_label(self) -&gt; str:\n    \"\"\"\n    Returns relationship label.\n\n    Returns:\n        str: relationship_label\n    \"\"\"\n    return self.relationship_label\n</code></pre>"},{"location":"reference/source/#biocypher._create.BioCypherEdge.get_properties","title":"<code>get_properties()</code>","text":"<p>Returns all other relationship properties apart from primary ids and label as key-value pairs.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>properties</p> Source code in <code>biocypher/_create.py</code> <pre><code>def get_properties(self) -&gt; dict:\n    \"\"\"\n    Returns all other relationship properties apart from primary ids\n    and label as key-value pairs.\n\n    Returns:\n        dict: properties\n    \"\"\"\n    return self.properties\n</code></pre>"},{"location":"reference/source/#biocypher._create.BioCypherEdge.get_source_id","title":"<code>get_source_id()</code>","text":"<p>Returns primary node identifier of relationship source.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>source_id</p> Source code in <code>biocypher/_create.py</code> <pre><code>def get_source_id(self) -&gt; str:\n    \"\"\"\n    Returns primary node identifier of relationship source.\n\n    Returns:\n        str: source_id\n    \"\"\"\n    return self.source_id\n</code></pre>"},{"location":"reference/source/#biocypher._create.BioCypherEdge.get_target_id","title":"<code>get_target_id()</code>","text":"<p>Returns primary node identifier of relationship target.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>target_id</p> Source code in <code>biocypher/_create.py</code> <pre><code>def get_target_id(self) -&gt; str:\n    \"\"\"\n    Returns primary node identifier of relationship target.\n\n    Returns:\n        str: target_id\n    \"\"\"\n    return self.target_id\n</code></pre>"},{"location":"reference/source/#biocypher._create.BioCypherEdge.get_type","title":"<code>get_type()</code>","text":"<p>Returns relationship label.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>relationship_label</p> Source code in <code>biocypher/_create.py</code> <pre><code>def get_type(self) -&gt; str:\n    \"\"\"\n    Returns relationship label.\n\n    Returns:\n        str: relationship_label\n    \"\"\"\n    return self.relationship_label\n</code></pre>"},{"location":"reference/source/#biocypher._create.BioCypherNode","title":"<code>BioCypherNode</code>  <code>dataclass</code>","text":"<p>Handoff class to represent biomedical entities as Neo4j nodes.</p> <p>Has id, label, property dict; id and label (in the Neo4j sense of a label, ie, the entity descriptor after the colon, such as \":Protein\") are non-optional and called node_id and node_label to avoid confusion with \"label\" properties. Node labels are written in PascalCase and as nouns, as per Neo4j consensus.</p> <p>Parameters:</p> Name Type Description Default <code>node_id</code> <code>string</code> <p>consensus \"best\" id for biological entity</p> required <code>node_label</code> <code>string</code> <p>primary type of entity, capitalised</p> required <code>**properties</code> <code>kwargs</code> <p>collection of all other properties to be passed to neo4j for the respective node (dict)</p> <code>dict()</code> Todo <ul> <li>check and correct small inconsistencies such as capitalisation     of ID names (\"uniprot\" vs \"UniProt\")</li> <li>check for correct ID patterns (eg \"ENSG\" + string of numbers,     uniprot length)</li> <li>ID conversion using pypath translation facilities for now</li> </ul> Source code in <code>biocypher/_create.py</code> <pre><code>@dataclass(frozen=True)\nclass BioCypherNode:\n    \"\"\"\n    Handoff class to represent biomedical entities as Neo4j nodes.\n\n    Has id, label, property dict; id and label (in the Neo4j sense of a\n    label, ie, the entity descriptor after the colon, such as\n    \":Protein\") are non-optional and called node_id and node_label to\n    avoid confusion with \"label\" properties. Node labels are written in\n    PascalCase and as nouns, as per Neo4j consensus.\n\n    Args:\n        node_id (string): consensus \"best\" id for biological entity\n        node_label (string): primary type of entity, capitalised\n        **properties (kwargs): collection of all other properties to be\n            passed to neo4j for the respective node (dict)\n\n    Todo:\n        - check and correct small inconsistencies such as capitalisation\n            of ID names (\"uniprot\" vs \"UniProt\")\n        - check for correct ID patterns (eg \"ENSG\" + string of numbers,\n            uniprot length)\n        - ID conversion using pypath translation facilities for now\n    \"\"\"\n\n    node_id: str\n    node_label: str\n    preferred_id: str = \"id\"\n    properties: dict = field(default_factory=dict)\n\n    def __post_init__(self):\n        \"\"\"\n        Add id field to properties.\n\n        Check for reserved keywords.\n\n        Replace unwanted characters in properties.\n        \"\"\"\n        self.properties[\"id\"] = self.node_id\n        self.properties[\"preferred_id\"] = self.preferred_id or None\n        # TODO actually make None possible here; as is, \"id\" is the default in\n        # the dataclass as well as in the configuration file\n\n        if \":TYPE\" in self.properties.keys():\n            logger.warning(\n                \"Keyword ':TYPE' is reserved for Neo4j. \"\n                \"Removing from properties.\",\n                # \"Renaming to 'type'.\"\n            )\n            # self.properties[\"type\"] = self.properties[\":TYPE\"]\n            del self.properties[\":TYPE\"]\n\n        for k, v in self.properties.items():\n            if isinstance(v, str):\n                self.properties[k] = (\n                    v.replace(\n                        os.linesep,\n                        \" \",\n                    )\n                    .replace(\n                        \"\\n\",\n                        \" \",\n                    )\n                    .replace(\n                        \"\\r\",\n                        \" \",\n                    )\n                )\n\n            elif isinstance(v, list):\n                self.properties[k] = [\n                    val.replace(\n                        os.linesep,\n                        \" \",\n                    )\n                    .replace(\n                        \"\\n\",\n                        \" \",\n                    )\n                    .replace(\"\\r\", \" \")\n                    for val in v\n                ]\n\n    def get_id(self) -&gt; str:\n        \"\"\"\n        Returns primary node identifier.\n\n        Returns:\n            str: node_id\n        \"\"\"\n        return self.node_id\n\n    def get_label(self) -&gt; str:\n        \"\"\"\n        Returns primary node label.\n\n        Returns:\n            str: node_label\n        \"\"\"\n        return self.node_label\n\n    def get_type(self) -&gt; str:\n        \"\"\"\n        Returns primary node label.\n\n        Returns:\n            str: node_label\n        \"\"\"\n        return self.node_label\n\n    def get_preferred_id(self) -&gt; str:\n        \"\"\"\n        Returns preferred id.\n\n        Returns:\n            str: preferred_id\n        \"\"\"\n        return self.preferred_id\n\n    def get_properties(self) -&gt; dict:\n        \"\"\"\n        Returns all other node properties apart from primary id and\n        label as key-value pairs.\n\n        Returns:\n            dict: properties\n        \"\"\"\n        return self.properties\n\n    def get_dict(self) -&gt; dict:\n        \"\"\"\n        Return dict of id, labels, and properties.\n\n        Returns:\n            dict: node_id and node_label as top-level key-value pairs,\n            properties as second-level dict.\n        \"\"\"\n        return {\n            \"node_id\": self.node_id,\n            \"node_label\": self.node_label,\n            \"properties\": self.properties,\n        }\n</code></pre>"},{"location":"reference/source/#biocypher._create.BioCypherNode.__post_init__","title":"<code>__post_init__()</code>","text":"<p>Add id field to properties.</p> <p>Check for reserved keywords.</p> <p>Replace unwanted characters in properties.</p> Source code in <code>biocypher/_create.py</code> <pre><code>def __post_init__(self):\n    \"\"\"\n    Add id field to properties.\n\n    Check for reserved keywords.\n\n    Replace unwanted characters in properties.\n    \"\"\"\n    self.properties[\"id\"] = self.node_id\n    self.properties[\"preferred_id\"] = self.preferred_id or None\n    # TODO actually make None possible here; as is, \"id\" is the default in\n    # the dataclass as well as in the configuration file\n\n    if \":TYPE\" in self.properties.keys():\n        logger.warning(\n            \"Keyword ':TYPE' is reserved for Neo4j. \"\n            \"Removing from properties.\",\n            # \"Renaming to 'type'.\"\n        )\n        # self.properties[\"type\"] = self.properties[\":TYPE\"]\n        del self.properties[\":TYPE\"]\n\n    for k, v in self.properties.items():\n        if isinstance(v, str):\n            self.properties[k] = (\n                v.replace(\n                    os.linesep,\n                    \" \",\n                )\n                .replace(\n                    \"\\n\",\n                    \" \",\n                )\n                .replace(\n                    \"\\r\",\n                    \" \",\n                )\n            )\n\n        elif isinstance(v, list):\n            self.properties[k] = [\n                val.replace(\n                    os.linesep,\n                    \" \",\n                )\n                .replace(\n                    \"\\n\",\n                    \" \",\n                )\n                .replace(\"\\r\", \" \")\n                for val in v\n            ]\n</code></pre>"},{"location":"reference/source/#biocypher._create.BioCypherNode.get_dict","title":"<code>get_dict()</code>","text":"<p>Return dict of id, labels, and properties.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>node_id and node_label as top-level key-value pairs,</p> <code>dict</code> <p>properties as second-level dict.</p> Source code in <code>biocypher/_create.py</code> <pre><code>def get_dict(self) -&gt; dict:\n    \"\"\"\n    Return dict of id, labels, and properties.\n\n    Returns:\n        dict: node_id and node_label as top-level key-value pairs,\n        properties as second-level dict.\n    \"\"\"\n    return {\n        \"node_id\": self.node_id,\n        \"node_label\": self.node_label,\n        \"properties\": self.properties,\n    }\n</code></pre>"},{"location":"reference/source/#biocypher._create.BioCypherNode.get_id","title":"<code>get_id()</code>","text":"<p>Returns primary node identifier.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>node_id</p> Source code in <code>biocypher/_create.py</code> <pre><code>def get_id(self) -&gt; str:\n    \"\"\"\n    Returns primary node identifier.\n\n    Returns:\n        str: node_id\n    \"\"\"\n    return self.node_id\n</code></pre>"},{"location":"reference/source/#biocypher._create.BioCypherNode.get_label","title":"<code>get_label()</code>","text":"<p>Returns primary node label.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>node_label</p> Source code in <code>biocypher/_create.py</code> <pre><code>def get_label(self) -&gt; str:\n    \"\"\"\n    Returns primary node label.\n\n    Returns:\n        str: node_label\n    \"\"\"\n    return self.node_label\n</code></pre>"},{"location":"reference/source/#biocypher._create.BioCypherNode.get_preferred_id","title":"<code>get_preferred_id()</code>","text":"<p>Returns preferred id.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>preferred_id</p> Source code in <code>biocypher/_create.py</code> <pre><code>def get_preferred_id(self) -&gt; str:\n    \"\"\"\n    Returns preferred id.\n\n    Returns:\n        str: preferred_id\n    \"\"\"\n    return self.preferred_id\n</code></pre>"},{"location":"reference/source/#biocypher._create.BioCypherNode.get_properties","title":"<code>get_properties()</code>","text":"<p>Returns all other node properties apart from primary id and label as key-value pairs.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>properties</p> Source code in <code>biocypher/_create.py</code> <pre><code>def get_properties(self) -&gt; dict:\n    \"\"\"\n    Returns all other node properties apart from primary id and\n    label as key-value pairs.\n\n    Returns:\n        dict: properties\n    \"\"\"\n    return self.properties\n</code></pre>"},{"location":"reference/source/#biocypher._create.BioCypherNode.get_type","title":"<code>get_type()</code>","text":"<p>Returns primary node label.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>node_label</p> Source code in <code>biocypher/_create.py</code> <pre><code>def get_type(self) -&gt; str:\n    \"\"\"\n    Returns primary node label.\n\n    Returns:\n        str: node_label\n    \"\"\"\n    return self.node_label\n</code></pre>"},{"location":"reference/source/#biocypher._create.BioCypherRelAsNode","title":"<code>BioCypherRelAsNode</code>  <code>dataclass</code>","text":"<p>Class to represent relationships as nodes (with in- and outgoing edges) as a triplet of a BioCypherNode and two BioCypherEdges. Main usage in type checking (instances where the receiving function needs to check whether it receives a relationship as a single edge or as a triplet).</p> <p>Args:</p> <pre><code>node (BioCypherNode): node representing the relationship\n\nsource_edge (BioCypherEdge): edge representing the source of the\n    relationship\n\ntarget_edge (BioCypherEdge): edge representing the target of the\n    relationship\n</code></pre> Source code in <code>biocypher/_create.py</code> <pre><code>@dataclass(frozen=True)\nclass BioCypherRelAsNode:\n    \"\"\"\n    Class to represent relationships as nodes (with in- and outgoing\n    edges) as a triplet of a BioCypherNode and two BioCypherEdges. Main\n    usage in type checking (instances where the receiving function needs\n    to check whether it receives a relationship as a single edge or as\n    a triplet).\n\n    Args:\n\n        node (BioCypherNode): node representing the relationship\n\n        source_edge (BioCypherEdge): edge representing the source of the\n            relationship\n\n        target_edge (BioCypherEdge): edge representing the target of the\n            relationship\n\n    \"\"\"\n\n    node: BioCypherNode\n    source_edge: BioCypherEdge\n    target_edge: BioCypherEdge\n\n    def __post_init__(self):\n        if not isinstance(self.node, BioCypherNode):\n            raise TypeError(\n                f\"BioCypherRelAsNode.node must be a BioCypherNode, \"\n                f\"not {type(self.node)}.\",\n            )\n\n        if not isinstance(self.source_edge, BioCypherEdge):\n            raise TypeError(\n                f\"BioCypherRelAsNode.source_edge must be a BioCypherEdge, \"\n                f\"not {type(self.source_edge)}.\",\n            )\n\n        if not isinstance(self.target_edge, BioCypherEdge):\n            raise TypeError(\n                f\"BioCypherRelAsNode.target_edge must be a BioCypherEdge, \"\n                f\"not {type(self.target_edge)}.\",\n            )\n\n    def get_node(self) -&gt; BioCypherNode:\n        return self.node\n\n    def get_source_edge(self) -&gt; BioCypherEdge:\n        return self.source_edge\n\n    def get_target_edge(self) -&gt; BioCypherEdge:\n        return self.target_edge\n</code></pre>"},{"location":"reference/source/#_deduplicatepy","title":"_deduplicate.py","text":""},{"location":"reference/source/#biocypher._deduplicate.Deduplicator","title":"<code>Deduplicator</code>","text":"<p>Singleton class responsible of deduplicating BioCypher inputs. Maintains sets/dictionaries of node and edge types and their unique identifiers.</p> <p>Nodes identifiers should be globally unique (represented as a set), while edge identifiers are only unique per edge type (represented as a dict of sets, keyed by edge type).</p> <p>Stores collection of duplicate node and edge identifiers and types for troubleshooting and to avoid overloading the log.</p> Source code in <code>biocypher/_deduplicate.py</code> <pre><code>class Deduplicator:\n    \"\"\"\n    Singleton class responsible of deduplicating BioCypher inputs. Maintains\n    sets/dictionaries of node and edge types and their unique identifiers.\n\n    Nodes identifiers should be globally unique (represented as a set), while\n    edge identifiers are only unique per edge type (represented as a dict of\n    sets, keyed by edge type).\n\n    Stores collection of duplicate node and edge identifiers and types for\n    troubleshooting and to avoid overloading the log.\n    \"\"\"\n\n    def __init__(self):\n        self.seen_entity_ids = set()\n        self.duplicate_entity_ids = set()\n\n        self.entity_types = set()\n        self.duplicate_entity_types = set()\n\n        self.seen_relationships = {}\n        self.duplicate_relationship_ids = set()\n        self.duplicate_relationship_types = set()\n\n    def node_seen(self, entity: BioCypherNode) -&gt; bool:\n        \"\"\"\n        Adds a node to the instance and checks if it has been seen before.\n\n        Args:\n            node: BioCypherNode to be added.\n\n        Returns:\n            True if the node has been seen before, False otherwise.\n        \"\"\"\n        if entity.get_label() not in self.entity_types:\n            self.entity_types.add(entity.get_label())\n\n        if entity.get_id() in self.seen_entity_ids:\n            self.duplicate_entity_ids.add(entity.get_id())\n            if entity.get_label() not in self.duplicate_entity_types:\n                logger.warning(\n                    f\"Duplicate node type {entity.get_label()} found. \"\n                )\n                self.duplicate_entity_types.add(entity.get_label())\n            return True\n\n        self.seen_entity_ids.add(entity.get_id())\n        return False\n\n    def edge_seen(self, relationship: BioCypherEdge) -&gt; bool:\n        \"\"\"\n        Adds an edge to the instance and checks if it has been seen before.\n\n        Args:\n            edge: BioCypherEdge to be added.\n\n        Returns:\n            True if the edge has been seen before, False otherwise.\n        \"\"\"\n        if relationship.get_type() not in self.seen_relationships:\n            self.seen_relationships[relationship.get_type()] = set()\n\n        # concatenate source and target if no id is present\n        if not relationship.get_id():\n            _id = (\n                f\"{relationship.get_source_id()}_{relationship.get_target_id()}\"\n            )\n        else:\n            _id = relationship.get_id()\n\n        if _id in self.seen_relationships[relationship.get_type()]:\n            self.duplicate_relationship_ids.add(_id)\n            if relationship.get_type() not in self.duplicate_relationship_types:\n                logger.warning(\n                    f\"Duplicate edge type {relationship.get_type()} found. \"\n                )\n                self.duplicate_relationship_types.add(relationship.get_type())\n            return True\n\n        self.seen_relationships[relationship.get_type()].add(_id)\n        return False\n\n    def rel_as_node_seen(self, rel_as_node: BioCypherRelAsNode) -&gt; bool:\n        \"\"\"\n        Adds a rel_as_node to the instance (one entity and two relationships)\n        and checks if it has been seen before. Only the node is relevant for\n        identifying the rel_as_node as a duplicate.\n\n        Args:\n            rel_as_node: BioCypherRelAsNode to be added.\n\n        Returns:\n            True if the rel_as_node has been seen before, False otherwise.\n        \"\"\"\n        node = rel_as_node.get_node()\n\n        if node.get_label() not in self.seen_relationships:\n            self.seen_relationships[node.get_label()] = set()\n\n        # rel as node always has an id\n        _id = node.get_id()\n\n        if _id in self.seen_relationships[node.get_type()]:\n            self.duplicate_relationship_ids.add(_id)\n            if node.get_type() not in self.duplicate_relationship_types:\n                logger.warning(f\"Duplicate edge type {node.get_type()} found. \")\n                self.duplicate_relationship_types.add(node.get_type())\n            return True\n\n        self.seen_relationships[node.get_type()].add(_id)\n        return False\n\n    def get_duplicate_nodes(self):\n        \"\"\"\n        Function to return a list of duplicate nodes.\n\n        Returns:\n            list: list of duplicate nodes\n        \"\"\"\n\n        if self.duplicate_entity_types:\n            return (self.duplicate_entity_types, self.duplicate_entity_ids)\n        else:\n            return None\n\n    def get_duplicate_edges(self):\n        \"\"\"\n        Function to return a list of duplicate edges.\n\n        Returns:\n            list: list of duplicate edges\n        \"\"\"\n\n        if self.duplicate_relationship_types:\n            return (\n                self.duplicate_relationship_types,\n                self.duplicate_relationship_ids,\n            )\n        else:\n            return None\n</code></pre>"},{"location":"reference/source/#biocypher._deduplicate.Deduplicator.edge_seen","title":"<code>edge_seen(relationship)</code>","text":"<p>Adds an edge to the instance and checks if it has been seen before.</p> <p>Parameters:</p> Name Type Description Default <code>edge</code> <p>BioCypherEdge to be added.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the edge has been seen before, False otherwise.</p> Source code in <code>biocypher/_deduplicate.py</code> <pre><code>def edge_seen(self, relationship: BioCypherEdge) -&gt; bool:\n    \"\"\"\n    Adds an edge to the instance and checks if it has been seen before.\n\n    Args:\n        edge: BioCypherEdge to be added.\n\n    Returns:\n        True if the edge has been seen before, False otherwise.\n    \"\"\"\n    if relationship.get_type() not in self.seen_relationships:\n        self.seen_relationships[relationship.get_type()] = set()\n\n    # concatenate source and target if no id is present\n    if not relationship.get_id():\n        _id = (\n            f\"{relationship.get_source_id()}_{relationship.get_target_id()}\"\n        )\n    else:\n        _id = relationship.get_id()\n\n    if _id in self.seen_relationships[relationship.get_type()]:\n        self.duplicate_relationship_ids.add(_id)\n        if relationship.get_type() not in self.duplicate_relationship_types:\n            logger.warning(\n                f\"Duplicate edge type {relationship.get_type()} found. \"\n            )\n            self.duplicate_relationship_types.add(relationship.get_type())\n        return True\n\n    self.seen_relationships[relationship.get_type()].add(_id)\n    return False\n</code></pre>"},{"location":"reference/source/#biocypher._deduplicate.Deduplicator.get_duplicate_edges","title":"<code>get_duplicate_edges()</code>","text":"<p>Function to return a list of duplicate edges.</p> <p>Returns:</p> Name Type Description <code>list</code> <p>list of duplicate edges</p> Source code in <code>biocypher/_deduplicate.py</code> <pre><code>def get_duplicate_edges(self):\n    \"\"\"\n    Function to return a list of duplicate edges.\n\n    Returns:\n        list: list of duplicate edges\n    \"\"\"\n\n    if self.duplicate_relationship_types:\n        return (\n            self.duplicate_relationship_types,\n            self.duplicate_relationship_ids,\n        )\n    else:\n        return None\n</code></pre>"},{"location":"reference/source/#biocypher._deduplicate.Deduplicator.get_duplicate_nodes","title":"<code>get_duplicate_nodes()</code>","text":"<p>Function to return a list of duplicate nodes.</p> <p>Returns:</p> Name Type Description <code>list</code> <p>list of duplicate nodes</p> Source code in <code>biocypher/_deduplicate.py</code> <pre><code>def get_duplicate_nodes(self):\n    \"\"\"\n    Function to return a list of duplicate nodes.\n\n    Returns:\n        list: list of duplicate nodes\n    \"\"\"\n\n    if self.duplicate_entity_types:\n        return (self.duplicate_entity_types, self.duplicate_entity_ids)\n    else:\n        return None\n</code></pre>"},{"location":"reference/source/#biocypher._deduplicate.Deduplicator.node_seen","title":"<code>node_seen(entity)</code>","text":"<p>Adds a node to the instance and checks if it has been seen before.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <p>BioCypherNode to be added.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the node has been seen before, False otherwise.</p> Source code in <code>biocypher/_deduplicate.py</code> <pre><code>def node_seen(self, entity: BioCypherNode) -&gt; bool:\n    \"\"\"\n    Adds a node to the instance and checks if it has been seen before.\n\n    Args:\n        node: BioCypherNode to be added.\n\n    Returns:\n        True if the node has been seen before, False otherwise.\n    \"\"\"\n    if entity.get_label() not in self.entity_types:\n        self.entity_types.add(entity.get_label())\n\n    if entity.get_id() in self.seen_entity_ids:\n        self.duplicate_entity_ids.add(entity.get_id())\n        if entity.get_label() not in self.duplicate_entity_types:\n            logger.warning(\n                f\"Duplicate node type {entity.get_label()} found. \"\n            )\n            self.duplicate_entity_types.add(entity.get_label())\n        return True\n\n    self.seen_entity_ids.add(entity.get_id())\n    return False\n</code></pre>"},{"location":"reference/source/#biocypher._deduplicate.Deduplicator.rel_as_node_seen","title":"<code>rel_as_node_seen(rel_as_node)</code>","text":"<p>Adds a rel_as_node to the instance (one entity and two relationships) and checks if it has been seen before. Only the node is relevant for identifying the rel_as_node as a duplicate.</p> <p>Parameters:</p> Name Type Description Default <code>rel_as_node</code> <code>BioCypherRelAsNode</code> <p>BioCypherRelAsNode to be added.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the rel_as_node has been seen before, False otherwise.</p> Source code in <code>biocypher/_deduplicate.py</code> <pre><code>def rel_as_node_seen(self, rel_as_node: BioCypherRelAsNode) -&gt; bool:\n    \"\"\"\n    Adds a rel_as_node to the instance (one entity and two relationships)\n    and checks if it has been seen before. Only the node is relevant for\n    identifying the rel_as_node as a duplicate.\n\n    Args:\n        rel_as_node: BioCypherRelAsNode to be added.\n\n    Returns:\n        True if the rel_as_node has been seen before, False otherwise.\n    \"\"\"\n    node = rel_as_node.get_node()\n\n    if node.get_label() not in self.seen_relationships:\n        self.seen_relationships[node.get_label()] = set()\n\n    # rel as node always has an id\n    _id = node.get_id()\n\n    if _id in self.seen_relationships[node.get_type()]:\n        self.duplicate_relationship_ids.add(_id)\n        if node.get_type() not in self.duplicate_relationship_types:\n            logger.warning(f\"Duplicate edge type {node.get_type()} found. \")\n            self.duplicate_relationship_types.add(node.get_type())\n        return True\n\n    self.seen_relationships[node.get_type()].add(_id)\n    return False\n</code></pre>"},{"location":"reference/source/#_getpy","title":"_get.py","text":"<p>BioCypher get module. Used to download and cache data from external sources.</p>"},{"location":"reference/source/#biocypher._get.APIRequest","title":"<code>APIRequest</code>","text":"<p>               Bases: <code>Resource</code></p> Source code in <code>biocypher/_get.py</code> <pre><code>class APIRequest(Resource):\n    def __init__(self, name: str, url_s: str | list[str], lifetime: int = 0):\n        \"\"\"\n        Represents basic information for an API Request.\n\n        Args:\n            name(str): The name of the API Request.\n\n            url_s(str|list): The URL of the API endpoint.\n\n            lifetime(int): The lifetime of the API Request in days. If 0, the\n                API Request is cached indefinitely.\n\n        \"\"\"\n        super().__init__(name, url_s, lifetime)\n</code></pre>"},{"location":"reference/source/#biocypher._get.APIRequest.__init__","title":"<code>__init__(name, url_s, lifetime=0)</code>","text":"<p>Represents basic information for an API Request.</p> <p>Parameters:</p> Name Type Description Default <code>name(str)</code> <p>The name of the API Request.</p> required <code>url_s(str|list)</code> <p>The URL of the API endpoint.</p> required <code>lifetime(int)</code> <p>The lifetime of the API Request in days. If 0, the API Request is cached indefinitely.</p> required Source code in <code>biocypher/_get.py</code> <pre><code>def __init__(self, name: str, url_s: str | list[str], lifetime: int = 0):\n    \"\"\"\n    Represents basic information for an API Request.\n\n    Args:\n        name(str): The name of the API Request.\n\n        url_s(str|list): The URL of the API endpoint.\n\n        lifetime(int): The lifetime of the API Request in days. If 0, the\n            API Request is cached indefinitely.\n\n    \"\"\"\n    super().__init__(name, url_s, lifetime)\n</code></pre>"},{"location":"reference/source/#biocypher._get.Downloader","title":"<code>Downloader</code>","text":"Source code in <code>biocypher/_get.py</code> <pre><code>class Downloader:\n    def __init__(self, cache_dir: Optional[str] = None) -&gt; None:\n        \"\"\"\n        The Downloader is a class that manages resources that can be downloaded\n        and cached locally. It manages the lifetime of downloaded resources by\n        keeping a JSON record of the download date of each resource.\n\n        Args:\n            cache_dir (str): The directory where the resources are cached. If\n                not given, a temporary directory is created.\n        \"\"\"\n        self.cache_dir = cache_dir or TemporaryDirectory().name\n        self.cache_file = os.path.join(self.cache_dir, \"cache.json\")\n        self.cache_dict = self._load_cache_dict()\n\n    def download(self, *resources: Resource):\n        \"\"\"\n        Download one or multiple resources. Load from cache if the resource is\n        already downloaded and the cache is not expired.\n\n        Args:\n            resources (Resource): The resource(s) to download or load from\n                cache.\n\n        Returns:\n            list[str]: The path or paths to the resource(s) that were downloaded\n                or loaded from cache.\n\n        \"\"\"\n        paths = []\n        for resource in resources:\n            paths.append(self._download_or_cache(resource))\n\n        # flatten list if it is nested\n        if is_nested(paths):\n            paths = [path for sublist in paths for path in sublist]\n\n        return paths\n\n    def _download_or_cache(self, resource: Resource, cache: bool = True):\n        \"\"\"\n        Download a resource if it is not cached or exceeded its lifetime.\n\n        Args:\n            resource (Resource): The resource to download.\n        Returns:\n            list[str]: The path or paths to the downloaded resource(s).\n\n\n        \"\"\"\n        expired = self._is_cache_expired(resource)\n\n        if expired or not cache:\n            self._delete_expired_cache(resource)\n            if isinstance(resource, FileDownload):\n                logger.info(f\"Asking for download of resource {resource.name}.\")\n                paths = self._download_files(cache, resource)\n            elif isinstance(resource, APIRequest):\n                logger.info(\n                    f\"Asking for download of api request {resource.name}.\"\n                )\n                paths = self._download_api_request(resource)\n\n            else:\n                raise TypeError(f\"Unknown resource type: {type(resource)}\")\n\n        else:\n            paths = self.get_cached_version(resource)\n        self._update_cache_record(resource)\n        return paths\n\n    def _is_cache_expired(self, resource: Resource) -&gt; bool:\n        \"\"\"\n        Check if resource or API request cache is expired.\n\n        Args:\n\n            resource (Resource): The resource or API request to download.\n\n        Returns:\n            bool: True if cache is expired, False if not.\n        \"\"\"\n        cache_record = self._get_cache_record(resource)\n        if cache_record:\n            download_time = datetime.strptime(\n                cache_record.get(\"date_downloaded\"), \"%Y-%m-%d %H:%M:%S.%f\"\n            )\n            lifetime = timedelta(days=resource.lifetime)\n            expired = download_time + lifetime &lt; datetime.now()\n        else:\n            expired = True\n        return expired\n\n    def _delete_expired_cache(self, resource: Resource):\n        cache_resource_path = self.cache_dir + \"/\" + resource.name\n        if os.path.exists(cache_resource_path) and os.path.isdir(\n            cache_resource_path\n        ):\n            shutil.rmtree(cache_resource_path)\n\n    def _download_files(self, cache, file_download: FileDownload):\n        \"\"\"\n        Download a resource given it is a file or a directory and return the\n        path.\n\n        Args:\n            cache (bool): Whether to cache the resource or not.\n            file_download (FileDownload): The resource to download.\n\n        Returns:\n            list[str]: The path or paths to the downloaded resource(s).\n        \"\"\"\n        if file_download.is_dir:\n            files = self._get_files(file_download)\n            file_download.url_s = [\n                file_download.url_s + \"/\" + file for file in files\n            ]\n            file_download.is_dir = False\n            paths = self._download_or_cache(file_download, cache)\n        elif isinstance(file_download.url_s, list):\n            paths = []\n            for url in file_download.url_s:\n                fname = url[url.rfind(\"/\") + 1 :].split(\"?\")[0]\n                paths.append(\n                    self._retrieve(\n                        url=url,\n                        fname=fname,\n                        path=os.path.join(self.cache_dir, file_download.name),\n                    )\n                )\n        else:\n            paths = []\n            fname = file_download.url_s[\n                file_download.url_s.rfind(\"/\") + 1 :\n            ].split(\"?\")[0]\n            results = self._retrieve(\n                url=file_download.url_s,\n                fname=fname,\n                path=os.path.join(self.cache_dir, file_download.name),\n            )\n            if isinstance(results, list):\n                paths.extend(results)\n            else:\n                paths.append(results)\n\n        # sometimes a compressed file contains multiple files\n        # TODO ask for a list of files in the archive to be used from the\n        # adapter\n        return paths\n\n    def _download_api_request(self, api_request: APIRequest):\n        \"\"\"\n        Download an API request and return the path.\n\n        Args:\n            api_request(APIRequest): The API request result that is being\n                cached.\n        Returns:\n            list[str]: The path to the cached API request.\n\n        \"\"\"\n        urls = (\n            api_request.url_s\n            if isinstance(api_request.url_s, list)\n            else [api_request.url_s]\n        )\n        paths = []\n        for url in urls:\n            fname = url[url.rfind(\"/\") + 1 :].rsplit(\".\", 1)[0]\n            logger.info(\n                f\"Asking for caching API of {api_request.name} {fname}.\"\n            )\n            response = requests.get(url=url)\n\n            if response.status_code != 200:\n                response.raise_for_status()\n            response_data = response.json()\n            api_path = os.path.join(\n                self.cache_dir, api_request.name, f\"{fname}.json\"\n            )\n\n            os.makedirs(os.path.dirname(api_path), exist_ok=True)\n            with open(api_path, \"w\") as f:\n                json.dump(response_data, f)\n                logger.info(f\"Caching API request to {api_path}.\")\n            paths.append(api_path)\n        return paths\n\n    def get_cached_version(self, resource: Resource) -&gt; list[str]:\n        \"\"\"Get the cached version of a resource.\n\n        Args:\n            resource(Resource): The resource to get the cached version of.\n\n        Returns:\n            list[str]: The paths to the cached resource(s).\n\n        \"\"\"\n        cached_location = os.path.join(self.cache_dir, resource.name)\n        logger.info(f\"Use cached version from {cached_location}.\")\n        paths = []\n        for file in os.listdir(cached_location):\n            paths.append(os.path.join(cached_location, file))\n        return paths\n\n    def _retrieve(\n        self,\n        url: str,\n        fname: str,\n        path: str,\n        known_hash: str = None,\n    ):\n        \"\"\"\n        Retrieve a file from a URL using Pooch. Infer type of file from\n        extension and use appropriate processor.\n\n        Args:\n            url (str): The URL to retrieve the file from.\n\n            fname (str): The name of the file.\n\n            path (str): The path to the file.\n        \"\"\"\n        if fname.endswith(\".zip\"):\n            return pooch.retrieve(\n                url=url,\n                known_hash=known_hash,\n                fname=fname,\n                path=path,\n                processor=pooch.Unzip(),\n                progressbar=True,\n            )\n\n        elif fname.endswith(\".tar.gz\"):\n            return pooch.retrieve(\n                url=url,\n                known_hash=known_hash,\n                fname=fname,\n                path=path,\n                processor=pooch.Untar(),\n                progressbar=True,\n            )\n\n        elif fname.endswith(\".gz\"):\n            return pooch.retrieve(\n                url=url,\n                known_hash=known_hash,\n                fname=fname,\n                path=path,\n                processor=pooch.Decompress(),\n                progressbar=True,\n            )\n\n        else:\n            return pooch.retrieve(\n                url=url,\n                known_hash=known_hash,\n                fname=fname,\n                path=path,\n                progressbar=True,\n            )\n\n    def _get_files(self, file_download: FileDownload):\n        \"\"\"\n        Get the files contained in a directory file.\n\n        Args:\n            file_download (FileDownload): The directory file.\n\n        Returns:\n            list: The files contained in the directory.\n        \"\"\"\n        if file_download.url_s.startswith(\"ftp://\"):\n            # remove protocol\n            url = file_download.url_s[6:]\n            # get base url\n            url = url[: url.find(\"/\")]\n            # get directory (remove initial slash as well)\n            dir = file_download.url_s[7 + len(url) :]\n            # get files\n            ftp = ftplib.FTP(url)\n            ftp.login()\n            ftp.cwd(dir)\n            files = ftp.nlst()\n            ftp.quit()\n        else:\n            raise NotImplementedError(\n                \"Only FTP directories are supported at the moment.\"\n            )\n\n        return files\n\n    def _load_cache_dict(self):\n        \"\"\"\n        Load the cache dictionary from the cache file. Create an empty cache\n        file if it does not exist.\n        \"\"\"\n        if not os.path.exists(self.cache_dir):\n            logger.info(f\"Creating cache directory {self.cache_dir}.\")\n            os.makedirs(self.cache_dir)\n\n        if not os.path.exists(self.cache_file):\n            logger.info(f\"Creating cache file {self.cache_file}.\")\n            with open(self.cache_file, \"w\") as f:\n                json.dump({}, f)\n\n        with open(self.cache_file, \"r\") as f:\n            logger.info(f\"Loading cache file {self.cache_file}.\")\n            return json.load(f)\n\n    def _get_cache_record(self, resource: Resource):\n        \"\"\"\n        Get the cache record of a resource.\n\n        Args:\n            resource (Resource): The resource to get the cache record of.\n\n        Returns:\n            The cache record of the resource.\n        \"\"\"\n        return self.cache_dict.get(resource.name, {})\n\n    def _update_cache_record(self, resource: Resource):\n        \"\"\"\n        Update the cache record of a resource.\n\n        Args:\n            resource (Resource): The resource to update the cache record of.\n        \"\"\"\n        cache_record = {}\n        cache_record[\"url\"] = to_list(resource.url_s)\n        cache_record[\"date_downloaded\"] = str(datetime.now())\n        cache_record[\"lifetime\"] = resource.lifetime\n        self.cache_dict[resource.name] = cache_record\n        with open(self.cache_file, \"w\") as f:\n            json.dump(self.cache_dict, f, default=str)\n</code></pre>"},{"location":"reference/source/#biocypher._get.Downloader.__init__","title":"<code>__init__(cache_dir=None)</code>","text":"<p>The Downloader is a class that manages resources that can be downloaded and cached locally. It manages the lifetime of downloaded resources by keeping a JSON record of the download date of each resource.</p> <p>Parameters:</p> Name Type Description Default <code>cache_dir</code> <code>str</code> <p>The directory where the resources are cached. If not given, a temporary directory is created.</p> <code>None</code> Source code in <code>biocypher/_get.py</code> <pre><code>def __init__(self, cache_dir: Optional[str] = None) -&gt; None:\n    \"\"\"\n    The Downloader is a class that manages resources that can be downloaded\n    and cached locally. It manages the lifetime of downloaded resources by\n    keeping a JSON record of the download date of each resource.\n\n    Args:\n        cache_dir (str): The directory where the resources are cached. If\n            not given, a temporary directory is created.\n    \"\"\"\n    self.cache_dir = cache_dir or TemporaryDirectory().name\n    self.cache_file = os.path.join(self.cache_dir, \"cache.json\")\n    self.cache_dict = self._load_cache_dict()\n</code></pre>"},{"location":"reference/source/#biocypher._get.Downloader._download_api_request","title":"<code>_download_api_request(api_request)</code>","text":"<p>Download an API request and return the path.</p> <p>Parameters:</p> Name Type Description Default <code>api_request(APIRequest)</code> <p>The API request result that is being cached.</p> required <p>Returns:     list[str]: The path to the cached API request.</p> Source code in <code>biocypher/_get.py</code> <pre><code>def _download_api_request(self, api_request: APIRequest):\n    \"\"\"\n    Download an API request and return the path.\n\n    Args:\n        api_request(APIRequest): The API request result that is being\n            cached.\n    Returns:\n        list[str]: The path to the cached API request.\n\n    \"\"\"\n    urls = (\n        api_request.url_s\n        if isinstance(api_request.url_s, list)\n        else [api_request.url_s]\n    )\n    paths = []\n    for url in urls:\n        fname = url[url.rfind(\"/\") + 1 :].rsplit(\".\", 1)[0]\n        logger.info(\n            f\"Asking for caching API of {api_request.name} {fname}.\"\n        )\n        response = requests.get(url=url)\n\n        if response.status_code != 200:\n            response.raise_for_status()\n        response_data = response.json()\n        api_path = os.path.join(\n            self.cache_dir, api_request.name, f\"{fname}.json\"\n        )\n\n        os.makedirs(os.path.dirname(api_path), exist_ok=True)\n        with open(api_path, \"w\") as f:\n            json.dump(response_data, f)\n            logger.info(f\"Caching API request to {api_path}.\")\n        paths.append(api_path)\n    return paths\n</code></pre>"},{"location":"reference/source/#biocypher._get.Downloader._download_files","title":"<code>_download_files(cache, file_download)</code>","text":"<p>Download a resource given it is a file or a directory and return the path.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>bool</code> <p>Whether to cache the resource or not.</p> required <code>file_download</code> <code>FileDownload</code> <p>The resource to download.</p> required <p>Returns:</p> Type Description <p>list[str]: The path or paths to the downloaded resource(s).</p> Source code in <code>biocypher/_get.py</code> <pre><code>def _download_files(self, cache, file_download: FileDownload):\n    \"\"\"\n    Download a resource given it is a file or a directory and return the\n    path.\n\n    Args:\n        cache (bool): Whether to cache the resource or not.\n        file_download (FileDownload): The resource to download.\n\n    Returns:\n        list[str]: The path or paths to the downloaded resource(s).\n    \"\"\"\n    if file_download.is_dir:\n        files = self._get_files(file_download)\n        file_download.url_s = [\n            file_download.url_s + \"/\" + file for file in files\n        ]\n        file_download.is_dir = False\n        paths = self._download_or_cache(file_download, cache)\n    elif isinstance(file_download.url_s, list):\n        paths = []\n        for url in file_download.url_s:\n            fname = url[url.rfind(\"/\") + 1 :].split(\"?\")[0]\n            paths.append(\n                self._retrieve(\n                    url=url,\n                    fname=fname,\n                    path=os.path.join(self.cache_dir, file_download.name),\n                )\n            )\n    else:\n        paths = []\n        fname = file_download.url_s[\n            file_download.url_s.rfind(\"/\") + 1 :\n        ].split(\"?\")[0]\n        results = self._retrieve(\n            url=file_download.url_s,\n            fname=fname,\n            path=os.path.join(self.cache_dir, file_download.name),\n        )\n        if isinstance(results, list):\n            paths.extend(results)\n        else:\n            paths.append(results)\n\n    # sometimes a compressed file contains multiple files\n    # TODO ask for a list of files in the archive to be used from the\n    # adapter\n    return paths\n</code></pre>"},{"location":"reference/source/#biocypher._get.Downloader._download_or_cache","title":"<code>_download_or_cache(resource, cache=True)</code>","text":"<p>Download a resource if it is not cached or exceeded its lifetime.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>Resource</code> <p>The resource to download.</p> required <p>Returns:     list[str]: The path or paths to the downloaded resource(s).</p> Source code in <code>biocypher/_get.py</code> <pre><code>def _download_or_cache(self, resource: Resource, cache: bool = True):\n    \"\"\"\n    Download a resource if it is not cached or exceeded its lifetime.\n\n    Args:\n        resource (Resource): The resource to download.\n    Returns:\n        list[str]: The path or paths to the downloaded resource(s).\n\n\n    \"\"\"\n    expired = self._is_cache_expired(resource)\n\n    if expired or not cache:\n        self._delete_expired_cache(resource)\n        if isinstance(resource, FileDownload):\n            logger.info(f\"Asking for download of resource {resource.name}.\")\n            paths = self._download_files(cache, resource)\n        elif isinstance(resource, APIRequest):\n            logger.info(\n                f\"Asking for download of api request {resource.name}.\"\n            )\n            paths = self._download_api_request(resource)\n\n        else:\n            raise TypeError(f\"Unknown resource type: {type(resource)}\")\n\n    else:\n        paths = self.get_cached_version(resource)\n    self._update_cache_record(resource)\n    return paths\n</code></pre>"},{"location":"reference/source/#biocypher._get.Downloader._get_cache_record","title":"<code>_get_cache_record(resource)</code>","text":"<p>Get the cache record of a resource.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>Resource</code> <p>The resource to get the cache record of.</p> required <p>Returns:</p> Type Description <p>The cache record of the resource.</p> Source code in <code>biocypher/_get.py</code> <pre><code>def _get_cache_record(self, resource: Resource):\n    \"\"\"\n    Get the cache record of a resource.\n\n    Args:\n        resource (Resource): The resource to get the cache record of.\n\n    Returns:\n        The cache record of the resource.\n    \"\"\"\n    return self.cache_dict.get(resource.name, {})\n</code></pre>"},{"location":"reference/source/#biocypher._get.Downloader._get_files","title":"<code>_get_files(file_download)</code>","text":"<p>Get the files contained in a directory file.</p> <p>Parameters:</p> Name Type Description Default <code>file_download</code> <code>FileDownload</code> <p>The directory file.</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>The files contained in the directory.</p> Source code in <code>biocypher/_get.py</code> <pre><code>def _get_files(self, file_download: FileDownload):\n    \"\"\"\n    Get the files contained in a directory file.\n\n    Args:\n        file_download (FileDownload): The directory file.\n\n    Returns:\n        list: The files contained in the directory.\n    \"\"\"\n    if file_download.url_s.startswith(\"ftp://\"):\n        # remove protocol\n        url = file_download.url_s[6:]\n        # get base url\n        url = url[: url.find(\"/\")]\n        # get directory (remove initial slash as well)\n        dir = file_download.url_s[7 + len(url) :]\n        # get files\n        ftp = ftplib.FTP(url)\n        ftp.login()\n        ftp.cwd(dir)\n        files = ftp.nlst()\n        ftp.quit()\n    else:\n        raise NotImplementedError(\n            \"Only FTP directories are supported at the moment.\"\n        )\n\n    return files\n</code></pre>"},{"location":"reference/source/#biocypher._get.Downloader._is_cache_expired","title":"<code>_is_cache_expired(resource)</code>","text":"<p>Check if resource or API request cache is expired.</p> <p>Args:</p> <pre><code>resource (Resource): The resource or API request to download.\n</code></pre> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if cache is expired, False if not.</p> Source code in <code>biocypher/_get.py</code> <pre><code>def _is_cache_expired(self, resource: Resource) -&gt; bool:\n    \"\"\"\n    Check if resource or API request cache is expired.\n\n    Args:\n\n        resource (Resource): The resource or API request to download.\n\n    Returns:\n        bool: True if cache is expired, False if not.\n    \"\"\"\n    cache_record = self._get_cache_record(resource)\n    if cache_record:\n        download_time = datetime.strptime(\n            cache_record.get(\"date_downloaded\"), \"%Y-%m-%d %H:%M:%S.%f\"\n        )\n        lifetime = timedelta(days=resource.lifetime)\n        expired = download_time + lifetime &lt; datetime.now()\n    else:\n        expired = True\n    return expired\n</code></pre>"},{"location":"reference/source/#biocypher._get.Downloader._load_cache_dict","title":"<code>_load_cache_dict()</code>","text":"<p>Load the cache dictionary from the cache file. Create an empty cache file if it does not exist.</p> Source code in <code>biocypher/_get.py</code> <pre><code>def _load_cache_dict(self):\n    \"\"\"\n    Load the cache dictionary from the cache file. Create an empty cache\n    file if it does not exist.\n    \"\"\"\n    if not os.path.exists(self.cache_dir):\n        logger.info(f\"Creating cache directory {self.cache_dir}.\")\n        os.makedirs(self.cache_dir)\n\n    if not os.path.exists(self.cache_file):\n        logger.info(f\"Creating cache file {self.cache_file}.\")\n        with open(self.cache_file, \"w\") as f:\n            json.dump({}, f)\n\n    with open(self.cache_file, \"r\") as f:\n        logger.info(f\"Loading cache file {self.cache_file}.\")\n        return json.load(f)\n</code></pre>"},{"location":"reference/source/#biocypher._get.Downloader._retrieve","title":"<code>_retrieve(url, fname, path, known_hash=None)</code>","text":"<p>Retrieve a file from a URL using Pooch. Infer type of file from extension and use appropriate processor.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to retrieve the file from.</p> required <code>fname</code> <code>str</code> <p>The name of the file.</p> required <code>path</code> <code>str</code> <p>The path to the file.</p> required Source code in <code>biocypher/_get.py</code> <pre><code>def _retrieve(\n    self,\n    url: str,\n    fname: str,\n    path: str,\n    known_hash: str = None,\n):\n    \"\"\"\n    Retrieve a file from a URL using Pooch. Infer type of file from\n    extension and use appropriate processor.\n\n    Args:\n        url (str): The URL to retrieve the file from.\n\n        fname (str): The name of the file.\n\n        path (str): The path to the file.\n    \"\"\"\n    if fname.endswith(\".zip\"):\n        return pooch.retrieve(\n            url=url,\n            known_hash=known_hash,\n            fname=fname,\n            path=path,\n            processor=pooch.Unzip(),\n            progressbar=True,\n        )\n\n    elif fname.endswith(\".tar.gz\"):\n        return pooch.retrieve(\n            url=url,\n            known_hash=known_hash,\n            fname=fname,\n            path=path,\n            processor=pooch.Untar(),\n            progressbar=True,\n        )\n\n    elif fname.endswith(\".gz\"):\n        return pooch.retrieve(\n            url=url,\n            known_hash=known_hash,\n            fname=fname,\n            path=path,\n            processor=pooch.Decompress(),\n            progressbar=True,\n        )\n\n    else:\n        return pooch.retrieve(\n            url=url,\n            known_hash=known_hash,\n            fname=fname,\n            path=path,\n            progressbar=True,\n        )\n</code></pre>"},{"location":"reference/source/#biocypher._get.Downloader._update_cache_record","title":"<code>_update_cache_record(resource)</code>","text":"<p>Update the cache record of a resource.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>Resource</code> <p>The resource to update the cache record of.</p> required Source code in <code>biocypher/_get.py</code> <pre><code>def _update_cache_record(self, resource: Resource):\n    \"\"\"\n    Update the cache record of a resource.\n\n    Args:\n        resource (Resource): The resource to update the cache record of.\n    \"\"\"\n    cache_record = {}\n    cache_record[\"url\"] = to_list(resource.url_s)\n    cache_record[\"date_downloaded\"] = str(datetime.now())\n    cache_record[\"lifetime\"] = resource.lifetime\n    self.cache_dict[resource.name] = cache_record\n    with open(self.cache_file, \"w\") as f:\n        json.dump(self.cache_dict, f, default=str)\n</code></pre>"},{"location":"reference/source/#biocypher._get.Downloader.download","title":"<code>download(*resources)</code>","text":"<p>Download one or multiple resources. Load from cache if the resource is already downloaded and the cache is not expired.</p> <p>Parameters:</p> Name Type Description Default <code>resources</code> <code>Resource</code> <p>The resource(s) to download or load from cache.</p> <code>()</code> <p>Returns:</p> Type Description <p>list[str]: The path or paths to the resource(s) that were downloaded or loaded from cache.</p> Source code in <code>biocypher/_get.py</code> <pre><code>def download(self, *resources: Resource):\n    \"\"\"\n    Download one or multiple resources. Load from cache if the resource is\n    already downloaded and the cache is not expired.\n\n    Args:\n        resources (Resource): The resource(s) to download or load from\n            cache.\n\n    Returns:\n        list[str]: The path or paths to the resource(s) that were downloaded\n            or loaded from cache.\n\n    \"\"\"\n    paths = []\n    for resource in resources:\n        paths.append(self._download_or_cache(resource))\n\n    # flatten list if it is nested\n    if is_nested(paths):\n        paths = [path for sublist in paths for path in sublist]\n\n    return paths\n</code></pre>"},{"location":"reference/source/#biocypher._get.Downloader.get_cached_version","title":"<code>get_cached_version(resource)</code>","text":"<p>Get the cached version of a resource.</p> <p>Parameters:</p> Name Type Description Default <code>resource(Resource)</code> <p>The resource to get the cached version of.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: The paths to the cached resource(s).</p> Source code in <code>biocypher/_get.py</code> <pre><code>def get_cached_version(self, resource: Resource) -&gt; list[str]:\n    \"\"\"Get the cached version of a resource.\n\n    Args:\n        resource(Resource): The resource to get the cached version of.\n\n    Returns:\n        list[str]: The paths to the cached resource(s).\n\n    \"\"\"\n    cached_location = os.path.join(self.cache_dir, resource.name)\n    logger.info(f\"Use cached version from {cached_location}.\")\n    paths = []\n    for file in os.listdir(cached_location):\n        paths.append(os.path.join(cached_location, file))\n    return paths\n</code></pre>"},{"location":"reference/source/#biocypher._get.FileDownload","title":"<code>FileDownload</code>","text":"<p>               Bases: <code>Resource</code></p> Source code in <code>biocypher/_get.py</code> <pre><code>class FileDownload(Resource):\n    def __init__(\n        self,\n        name: str,\n        url_s: str | list[str],\n        lifetime: int = 0,\n        is_dir: bool = False,\n    ):\n        \"\"\"\n        Represents basic information for a File Download.\n\n        Args:\n            name(str): The name of the File Download.\n\n            url_s(str|list[str]): The URL(s) of the File Download.\n\n            lifetime(int): The lifetime of the File Download in days. If 0, the\n                File Download is cached indefinitely.\n\n            is_dir (bool): Whether the URL points to a directory or not.\n        \"\"\"\n\n        super().__init__(name, url_s, lifetime)\n        self.is_dir = is_dir\n</code></pre>"},{"location":"reference/source/#biocypher._get.FileDownload.__init__","title":"<code>__init__(name, url_s, lifetime=0, is_dir=False)</code>","text":"<p>Represents basic information for a File Download.</p> <p>Parameters:</p> Name Type Description Default <code>name(str)</code> <p>The name of the File Download.</p> required <code>url_s(str|list[str])</code> <p>The URL(s) of the File Download.</p> required <code>lifetime(int)</code> <p>The lifetime of the File Download in days. If 0, the File Download is cached indefinitely.</p> required <code>is_dir</code> <code>bool</code> <p>Whether the URL points to a directory or not.</p> <code>False</code> Source code in <code>biocypher/_get.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    url_s: str | list[str],\n    lifetime: int = 0,\n    is_dir: bool = False,\n):\n    \"\"\"\n    Represents basic information for a File Download.\n\n    Args:\n        name(str): The name of the File Download.\n\n        url_s(str|list[str]): The URL(s) of the File Download.\n\n        lifetime(int): The lifetime of the File Download in days. If 0, the\n            File Download is cached indefinitely.\n\n        is_dir (bool): Whether the URL points to a directory or not.\n    \"\"\"\n\n    super().__init__(name, url_s, lifetime)\n    self.is_dir = is_dir\n</code></pre>"},{"location":"reference/source/#biocypher._get.Resource","title":"<code>Resource</code>","text":"<p>               Bases: <code>ABC</code></p> Source code in <code>biocypher/_get.py</code> <pre><code>class Resource(ABC):\n    def __init__(\n        self,\n        name: str,\n        url_s: str | list[str],\n        lifetime: int = 0,\n    ):\n        \"\"\"\n\n        A Resource is a file, a list of files, an API request, or a list of API\n        requests, any of which can be downloaded from the given URL(s) and\n        cached locally. This class implements checks of the minimum requirements\n        for a resource, to be implemented by a biocypher adapter.\n\n        Args:\n            name (str): The name of the resource.\n\n            url_s (str | list[str]): The URL or URLs of the resource.\n\n            lifetime (int): The lifetime of the resource in days. If 0, the\n                resource is considered to be permanent.\n        \"\"\"\n        self.name = name\n        self.url_s = url_s\n        self.lifetime = lifetime\n</code></pre>"},{"location":"reference/source/#biocypher._get.Resource.__init__","title":"<code>__init__(name, url_s, lifetime=0)</code>","text":"<p>A Resource is a file, a list of files, an API request, or a list of API requests, any of which can be downloaded from the given URL(s) and cached locally. This class implements checks of the minimum requirements for a resource, to be implemented by a biocypher adapter.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the resource.</p> required <code>url_s</code> <code>str | list[str]</code> <p>The URL or URLs of the resource.</p> required <code>lifetime</code> <code>int</code> <p>The lifetime of the resource in days. If 0, the resource is considered to be permanent.</p> <code>0</code> Source code in <code>biocypher/_get.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    url_s: str | list[str],\n    lifetime: int = 0,\n):\n    \"\"\"\n\n    A Resource is a file, a list of files, an API request, or a list of API\n    requests, any of which can be downloaded from the given URL(s) and\n    cached locally. This class implements checks of the minimum requirements\n    for a resource, to be implemented by a biocypher adapter.\n\n    Args:\n        name (str): The name of the resource.\n\n        url_s (str | list[str]): The URL or URLs of the resource.\n\n        lifetime (int): The lifetime of the resource in days. If 0, the\n            resource is considered to be permanent.\n    \"\"\"\n    self.name = name\n    self.url_s = url_s\n    self.lifetime = lifetime\n</code></pre>"},{"location":"reference/source/#_loggerpy","title":"_.logger.py","text":"<p>Configuration of the module logger.</p>"},{"location":"reference/source/#biocypher._logger.get_logger","title":"<code>get_logger(name='biocypher')</code>","text":"<p>Access the module logger, create a new one if does not exist yet.</p> <p>Method providing central logger instance to main module. Is called only from main submodule, :mod:<code>biocypher.driver</code>. In child modules, the standard Python logging facility is called (using <code>logging.getLogger(__name__)</code>), automatically inheriting the handlers from the central logger.</p> <p>The file handler creates a log file named after the current date and time. Levels to output to file and console can be set here.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the logger instance.</p> <code>'biocypher'</code> <p>Returns:</p> Type Description <code>Logger</code> <p>An instance of the Python mod:<code>logging.Logger</code>.</p> Source code in <code>biocypher/_logger.py</code> <pre><code>def get_logger(name: str = \"biocypher\") -&gt; logging.Logger:\n    \"\"\"\n    Access the module logger, create a new one if does not exist yet.\n\n    Method providing central logger instance to main module. Is called\n    only from main submodule, :mod:`biocypher.driver`. In child modules,\n    the standard Python logging facility is called\n    (using ``logging.getLogger(__name__)``), automatically inheriting\n    the handlers from the central logger.\n\n    The file handler creates a log file named after the current date and\n    time. Levels to output to file and console can be set here.\n\n    Args:\n        name:\n            Name of the logger instance.\n\n    Returns:\n        An instance of the Python :py:mod:`logging.Logger`.\n    \"\"\"\n\n    if not logging.getLogger(name).hasHandlers():\n        # create logger\n        logger = logging.getLogger(name)\n        logger.setLevel(logging.DEBUG)\n        logger.propagate = True\n\n        # formatting\n        file_formatter = logging.Formatter(\n            \"%(asctime)s\\t%(levelname)s\\tmodule:%(module)s\\n%(message)s\",\n        )\n        stdout_formatter = logging.Formatter(\"%(levelname)s -- %(message)s\")\n\n        # file name and creation\n        now = datetime.now()\n        date_time = now.strftime(\"%Y%m%d-%H%M%S\")\n\n        log_to_disk = _config.config(\"biocypher\").get(\"log_to_disk\")\n\n        if log_to_disk:\n            logdir = (\n                _config.config(\"biocypher\").get(\"log_directory\")\n                or \"biocypher-log\"\n            )\n            os.makedirs(logdir, exist_ok=True)\n            logfile = os.path.join(logdir, f\"biocypher-{date_time}.log\")\n\n            # file handler\n            file_handler = logging.FileHandler(logfile)\n\n            if _config.config(\"biocypher\").get(\"debug\"):\n                file_handler.setLevel(logging.DEBUG)\n            else:\n                file_handler.setLevel(logging.INFO)\n\n            file_handler.setFormatter(file_formatter)\n\n            logger.addHandler(file_handler)\n\n        # handlers\n        # stream handler\n        stdout_handler = logging.StreamHandler()\n        stdout_handler.setLevel(logging.INFO)\n        stdout_handler.setFormatter(stdout_formatter)\n\n        # add handlers\n        logger.addHandler(stdout_handler)\n\n        # startup message\n        logger.info(f\"This is BioCypher v{__version__}.\")\n        if log_to_disk:\n            logger.info(f\"Logging into `{logfile}`.\")\n        else:\n            logger.info(\"Logging into stdout.\")\n\n    return logging.getLogger(name)\n</code></pre>"},{"location":"reference/source/#biocypher._logger.log","title":"<code>log()</code>","text":"<p>Browse the log file.</p> Source code in <code>biocypher/_logger.py</code> <pre><code>def log():\n    \"\"\"\n    Browse the log file.\n    \"\"\"\n\n    with open(logfile()) as fp:\n        pydoc.pager(fp.read())\n</code></pre>"},{"location":"reference/source/#biocypher._logger.logfile","title":"<code>logfile()</code>","text":"<p>Path to the log file.</p> Source code in <code>biocypher/_logger.py</code> <pre><code>def logfile() -&gt; str:\n    \"\"\"\n    Path to the log file.\n    \"\"\"\n\n    return get_logger().handlers[0].baseFilename\n</code></pre>"},{"location":"reference/source/#_mappingpy","title":"_mapping.py","text":"<p>BioCypher 'mapping' module. Handles the mapping of user-defined schema to the underlying ontology.</p>"},{"location":"reference/source/#biocypher._mapping.OntologyMapping","title":"<code>OntologyMapping</code>","text":"<p>Class to store the ontology mapping and extensions.</p> Source code in <code>biocypher/_mapping.py</code> <pre><code>class OntologyMapping:\n    \"\"\"\n    Class to store the ontology mapping and extensions.\n    \"\"\"\n\n    def __init__(self, config_file: str = None):\n        self.schema = self._read_config(config_file)\n\n        self.extended_schema = self._extend_schema()\n\n    def _read_config(self, config_file: str = None):\n        \"\"\"\n        Read the configuration file and store the ontology mapping and extensions.\n        \"\"\"\n        if config_file is None:\n            schema_config = {}\n\n        # load yaml file from web\n        elif config_file.startswith(\"http\"):\n            with urlopen(config_file) as f:\n                schema_config = yaml.safe_load(f)\n\n        # get graph state from config (assume file is local)\n        else:\n            with open(config_file, \"r\") as f:\n                schema_config = yaml.safe_load(f)\n\n        return schema_config\n\n    def _extend_schema(self, d: Optional[dict] = None) -&gt; dict:\n        \"\"\"\n        Get leaves of the tree hierarchy from the data structure dict\n        contained in the `schema_config.yaml`. Creates virtual leaves\n        (as children) from entries that provide more than one preferred\n        id type (and corresponding inputs).\n\n        Args:\n            d:\n                Data structure dict from yaml file.\n\n        \"\"\"\n\n        d = d or self.schema\n\n        extended_schema = dict()\n\n        # first pass: get parent leaves with direct representation in ontology\n        for k, v in d.items():\n            # k is not an entity\n            if \"represented_as\" not in v:\n                continue\n\n            # preferred_id optional: if not provided, use `id`\n            if not v.get(\"preferred_id\"):\n                v[\"preferred_id\"] = \"id\"\n\n            # k is an entity that is present in the ontology\n            if \"is_a\" not in v:\n                extended_schema[k] = v\n\n        # second pass: \"vertical\" inheritance\n        d = self._vertical_property_inheritance(d)\n        for k, v in d.items():\n            if \"is_a\" in v:\n                # prevent loops\n                if k == v[\"is_a\"]:\n                    logger.warning(\n                        f\"Loop detected in ontology mapping: {k} -&gt; {v}. \"\n                        \"Removing item. Please fix the inheritance if you want \"\n                        \"to use this item.\"\n                    )\n                    continue\n\n                extended_schema[k] = v\n\n        # \"horizontal\" inheritance: create siblings for multiple identifiers or\n        # sources -&gt; virtual leaves or implicit children\n        mi_leaves = {}\n        ms_leaves = {}\n        for k, v in d.items():\n            # k is not an entity\n            if \"represented_as\" not in v:\n                continue\n\n            if isinstance(v.get(\"preferred_id\"), list):\n                mi_leaves = self._horizontal_inheritance_pid(k, v)\n                extended_schema.update(mi_leaves)\n\n            elif isinstance(v.get(\"source\"), list):\n                ms_leaves = self._horizontal_inheritance_source(k, v)\n                extended_schema.update(ms_leaves)\n\n        return extended_schema\n\n    def _vertical_property_inheritance(self, d):\n        \"\"\"\n        Inherit properties from parents to children and update `d` accordingly.\n        \"\"\"\n        for k, v in d.items():\n            # k is not an entity\n            if \"represented_as\" not in v:\n                continue\n\n            # k is an entity that is present in the ontology\n            if \"is_a\" not in v:\n                continue\n\n            # \"vertical\" inheritance: inherit properties from parent\n            if v.get(\"inherit_properties\", False):\n                # get direct ancestor\n                if isinstance(v[\"is_a\"], list):\n                    parent = v[\"is_a\"][0]\n                else:\n                    parent = v[\"is_a\"]\n\n                # ensure child has properties and exclude_properties\n                if \"properties\" not in v:\n                    v[\"properties\"] = {}\n                if \"exclude_properties\" not in v:\n                    v[\"exclude_properties\"] = {}\n\n                # update properties of child\n                parent_props = self.schema[parent].get(\"properties\", {})\n                if parent_props:\n                    v[\"properties\"].update(parent_props)\n\n                parent_excl_props = self.schema[parent].get(\n                    \"exclude_properties\", {}\n                )\n                if parent_excl_props:\n                    v[\"exclude_properties\"].update(parent_excl_props)\n\n                # update schema (d)\n                d[k] = v\n\n        return d\n\n    def _horizontal_inheritance_pid(self, key, value):\n        \"\"\"\n        Create virtual leaves for multiple preferred id types or sources.\n\n        If we create virtual leaves, input_label/label_in_input always has to be\n        a list.\n        \"\"\"\n\n        leaves = {}\n\n        preferred_id = value[\"preferred_id\"]\n        input_label = value.get(\"input_label\") or value[\"label_in_input\"]\n        represented_as = value[\"represented_as\"]\n\n        # adjust lengths\n        max_l = max(\n            [\n                len(_misc.to_list(preferred_id)),\n                len(_misc.to_list(input_label)),\n                len(_misc.to_list(represented_as)),\n            ],\n        )\n\n        # adjust pid length if necessary\n        if isinstance(preferred_id, str):\n            pids = [preferred_id] * max_l\n        else:\n            pids = preferred_id\n\n        # adjust rep length if necessary\n        if isinstance(represented_as, str):\n            reps = [represented_as] * max_l\n        else:\n            reps = represented_as\n\n        for pid, lab, rep in zip(pids, input_label, reps):\n            skey = pid + \".\" + key\n            svalue = {\n                \"preferred_id\": pid,\n                \"input_label\": lab,\n                \"represented_as\": rep,\n                # mark as virtual\n                \"virtual\": True,\n            }\n\n            # inherit is_a if exists\n            if \"is_a\" in value.keys():\n                # treat as multiple inheritance\n                if isinstance(value[\"is_a\"], list):\n                    v = list(value[\"is_a\"])\n                    v.insert(0, key)\n                    svalue[\"is_a\"] = v\n\n                else:\n                    svalue[\"is_a\"] = [key, value[\"is_a\"]]\n\n            else:\n                # set parent as is_a\n                svalue[\"is_a\"] = key\n\n            # inherit everything except core attributes\n            for k, v in value.items():\n                if k not in [\n                    \"is_a\",\n                    \"preferred_id\",\n                    \"input_label\",\n                    \"label_in_input\",\n                    \"represented_as\",\n                ]:\n                    svalue[k] = v\n\n            leaves[skey] = svalue\n\n        return leaves\n\n    def _horizontal_inheritance_source(self, key, value):\n        \"\"\"\n        Create virtual leaves for multiple sources.\n\n        If we create virtual leaves, input_label/label_in_input always has to be\n        a list.\n        \"\"\"\n\n        leaves = {}\n\n        source = value[\"source\"]\n        input_label = value.get(\"input_label\") or value[\"label_in_input\"]\n        represented_as = value[\"represented_as\"]\n\n        # adjust lengths\n        src_l = len(source)\n\n        # adjust label length if necessary\n        if isinstance(input_label, str):\n            labels = [input_label] * src_l\n        else:\n            labels = input_label\n\n        # adjust rep length if necessary\n        if isinstance(represented_as, str):\n            reps = [represented_as] * src_l\n        else:\n            reps = represented_as\n\n        for src, lab, rep in zip(source, labels, reps):\n            skey = src + \".\" + key\n            svalue = {\n                \"source\": src,\n                \"input_label\": lab,\n                \"represented_as\": rep,\n                # mark as virtual\n                \"virtual\": True,\n            }\n\n            # inherit is_a if exists\n            if \"is_a\" in value.keys():\n                # treat as multiple inheritance\n                if isinstance(value[\"is_a\"], list):\n                    v = list(value[\"is_a\"])\n                    v.insert(0, key)\n                    svalue[\"is_a\"] = v\n\n                else:\n                    svalue[\"is_a\"] = [key, value[\"is_a\"]]\n\n            else:\n                # set parent as is_a\n                svalue[\"is_a\"] = key\n\n            # inherit everything except core attributes\n            for k, v in value.items():\n                if k not in [\n                    \"is_a\",\n                    \"source\",\n                    \"input_label\",\n                    \"label_in_input\",\n                    \"represented_as\",\n                ]:\n                    svalue[k] = v\n\n            leaves[skey] = svalue\n\n        return leaves\n</code></pre>"},{"location":"reference/source/#biocypher._mapping.OntologyMapping._extend_schema","title":"<code>_extend_schema(d=None)</code>","text":"<p>Get leaves of the tree hierarchy from the data structure dict contained in the <code>schema_config.yaml</code>. Creates virtual leaves (as children) from entries that provide more than one preferred id type (and corresponding inputs).</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>Optional[dict]</code> <p>Data structure dict from yaml file.</p> <code>None</code> Source code in <code>biocypher/_mapping.py</code> <pre><code>def _extend_schema(self, d: Optional[dict] = None) -&gt; dict:\n    \"\"\"\n    Get leaves of the tree hierarchy from the data structure dict\n    contained in the `schema_config.yaml`. Creates virtual leaves\n    (as children) from entries that provide more than one preferred\n    id type (and corresponding inputs).\n\n    Args:\n        d:\n            Data structure dict from yaml file.\n\n    \"\"\"\n\n    d = d or self.schema\n\n    extended_schema = dict()\n\n    # first pass: get parent leaves with direct representation in ontology\n    for k, v in d.items():\n        # k is not an entity\n        if \"represented_as\" not in v:\n            continue\n\n        # preferred_id optional: if not provided, use `id`\n        if not v.get(\"preferred_id\"):\n            v[\"preferred_id\"] = \"id\"\n\n        # k is an entity that is present in the ontology\n        if \"is_a\" not in v:\n            extended_schema[k] = v\n\n    # second pass: \"vertical\" inheritance\n    d = self._vertical_property_inheritance(d)\n    for k, v in d.items():\n        if \"is_a\" in v:\n            # prevent loops\n            if k == v[\"is_a\"]:\n                logger.warning(\n                    f\"Loop detected in ontology mapping: {k} -&gt; {v}. \"\n                    \"Removing item. Please fix the inheritance if you want \"\n                    \"to use this item.\"\n                )\n                continue\n\n            extended_schema[k] = v\n\n    # \"horizontal\" inheritance: create siblings for multiple identifiers or\n    # sources -&gt; virtual leaves or implicit children\n    mi_leaves = {}\n    ms_leaves = {}\n    for k, v in d.items():\n        # k is not an entity\n        if \"represented_as\" not in v:\n            continue\n\n        if isinstance(v.get(\"preferred_id\"), list):\n            mi_leaves = self._horizontal_inheritance_pid(k, v)\n            extended_schema.update(mi_leaves)\n\n        elif isinstance(v.get(\"source\"), list):\n            ms_leaves = self._horizontal_inheritance_source(k, v)\n            extended_schema.update(ms_leaves)\n\n    return extended_schema\n</code></pre>"},{"location":"reference/source/#biocypher._mapping.OntologyMapping._horizontal_inheritance_pid","title":"<code>_horizontal_inheritance_pid(key, value)</code>","text":"<p>Create virtual leaves for multiple preferred id types or sources.</p> <p>If we create virtual leaves, input_label/label_in_input always has to be a list.</p> Source code in <code>biocypher/_mapping.py</code> <pre><code>def _horizontal_inheritance_pid(self, key, value):\n    \"\"\"\n    Create virtual leaves for multiple preferred id types or sources.\n\n    If we create virtual leaves, input_label/label_in_input always has to be\n    a list.\n    \"\"\"\n\n    leaves = {}\n\n    preferred_id = value[\"preferred_id\"]\n    input_label = value.get(\"input_label\") or value[\"label_in_input\"]\n    represented_as = value[\"represented_as\"]\n\n    # adjust lengths\n    max_l = max(\n        [\n            len(_misc.to_list(preferred_id)),\n            len(_misc.to_list(input_label)),\n            len(_misc.to_list(represented_as)),\n        ],\n    )\n\n    # adjust pid length if necessary\n    if isinstance(preferred_id, str):\n        pids = [preferred_id] * max_l\n    else:\n        pids = preferred_id\n\n    # adjust rep length if necessary\n    if isinstance(represented_as, str):\n        reps = [represented_as] * max_l\n    else:\n        reps = represented_as\n\n    for pid, lab, rep in zip(pids, input_label, reps):\n        skey = pid + \".\" + key\n        svalue = {\n            \"preferred_id\": pid,\n            \"input_label\": lab,\n            \"represented_as\": rep,\n            # mark as virtual\n            \"virtual\": True,\n        }\n\n        # inherit is_a if exists\n        if \"is_a\" in value.keys():\n            # treat as multiple inheritance\n            if isinstance(value[\"is_a\"], list):\n                v = list(value[\"is_a\"])\n                v.insert(0, key)\n                svalue[\"is_a\"] = v\n\n            else:\n                svalue[\"is_a\"] = [key, value[\"is_a\"]]\n\n        else:\n            # set parent as is_a\n            svalue[\"is_a\"] = key\n\n        # inherit everything except core attributes\n        for k, v in value.items():\n            if k not in [\n                \"is_a\",\n                \"preferred_id\",\n                \"input_label\",\n                \"label_in_input\",\n                \"represented_as\",\n            ]:\n                svalue[k] = v\n\n        leaves[skey] = svalue\n\n    return leaves\n</code></pre>"},{"location":"reference/source/#biocypher._mapping.OntologyMapping._horizontal_inheritance_source","title":"<code>_horizontal_inheritance_source(key, value)</code>","text":"<p>Create virtual leaves for multiple sources.</p> <p>If we create virtual leaves, input_label/label_in_input always has to be a list.</p> Source code in <code>biocypher/_mapping.py</code> <pre><code>def _horizontal_inheritance_source(self, key, value):\n    \"\"\"\n    Create virtual leaves for multiple sources.\n\n    If we create virtual leaves, input_label/label_in_input always has to be\n    a list.\n    \"\"\"\n\n    leaves = {}\n\n    source = value[\"source\"]\n    input_label = value.get(\"input_label\") or value[\"label_in_input\"]\n    represented_as = value[\"represented_as\"]\n\n    # adjust lengths\n    src_l = len(source)\n\n    # adjust label length if necessary\n    if isinstance(input_label, str):\n        labels = [input_label] * src_l\n    else:\n        labels = input_label\n\n    # adjust rep length if necessary\n    if isinstance(represented_as, str):\n        reps = [represented_as] * src_l\n    else:\n        reps = represented_as\n\n    for src, lab, rep in zip(source, labels, reps):\n        skey = src + \".\" + key\n        svalue = {\n            \"source\": src,\n            \"input_label\": lab,\n            \"represented_as\": rep,\n            # mark as virtual\n            \"virtual\": True,\n        }\n\n        # inherit is_a if exists\n        if \"is_a\" in value.keys():\n            # treat as multiple inheritance\n            if isinstance(value[\"is_a\"], list):\n                v = list(value[\"is_a\"])\n                v.insert(0, key)\n                svalue[\"is_a\"] = v\n\n            else:\n                svalue[\"is_a\"] = [key, value[\"is_a\"]]\n\n        else:\n            # set parent as is_a\n            svalue[\"is_a\"] = key\n\n        # inherit everything except core attributes\n        for k, v in value.items():\n            if k not in [\n                \"is_a\",\n                \"source\",\n                \"input_label\",\n                \"label_in_input\",\n                \"represented_as\",\n            ]:\n                svalue[k] = v\n\n        leaves[skey] = svalue\n\n    return leaves\n</code></pre>"},{"location":"reference/source/#biocypher._mapping.OntologyMapping._read_config","title":"<code>_read_config(config_file=None)</code>","text":"<p>Read the configuration file and store the ontology mapping and extensions.</p> Source code in <code>biocypher/_mapping.py</code> <pre><code>def _read_config(self, config_file: str = None):\n    \"\"\"\n    Read the configuration file and store the ontology mapping and extensions.\n    \"\"\"\n    if config_file is None:\n        schema_config = {}\n\n    # load yaml file from web\n    elif config_file.startswith(\"http\"):\n        with urlopen(config_file) as f:\n            schema_config = yaml.safe_load(f)\n\n    # get graph state from config (assume file is local)\n    else:\n        with open(config_file, \"r\") as f:\n            schema_config = yaml.safe_load(f)\n\n    return schema_config\n</code></pre>"},{"location":"reference/source/#biocypher._mapping.OntologyMapping._vertical_property_inheritance","title":"<code>_vertical_property_inheritance(d)</code>","text":"<p>Inherit properties from parents to children and update <code>d</code> accordingly.</p> Source code in <code>biocypher/_mapping.py</code> <pre><code>def _vertical_property_inheritance(self, d):\n    \"\"\"\n    Inherit properties from parents to children and update `d` accordingly.\n    \"\"\"\n    for k, v in d.items():\n        # k is not an entity\n        if \"represented_as\" not in v:\n            continue\n\n        # k is an entity that is present in the ontology\n        if \"is_a\" not in v:\n            continue\n\n        # \"vertical\" inheritance: inherit properties from parent\n        if v.get(\"inherit_properties\", False):\n            # get direct ancestor\n            if isinstance(v[\"is_a\"], list):\n                parent = v[\"is_a\"][0]\n            else:\n                parent = v[\"is_a\"]\n\n            # ensure child has properties and exclude_properties\n            if \"properties\" not in v:\n                v[\"properties\"] = {}\n            if \"exclude_properties\" not in v:\n                v[\"exclude_properties\"] = {}\n\n            # update properties of child\n            parent_props = self.schema[parent].get(\"properties\", {})\n            if parent_props:\n                v[\"properties\"].update(parent_props)\n\n            parent_excl_props = self.schema[parent].get(\n                \"exclude_properties\", {}\n            )\n            if parent_excl_props:\n                v[\"exclude_properties\"].update(parent_excl_props)\n\n            # update schema (d)\n            d[k] = v\n\n    return d\n</code></pre>"},{"location":"reference/source/#_metadatapy","title":"_metadata.py","text":"<p>Package metadata (version, authors, etc).</p>"},{"location":"reference/source/#biocypher._metadata.get_metadata","title":"<code>get_metadata()</code>","text":"<p>Basic package metadata.</p> <p>Retrieves package metadata from the current project directory or from the installed package.</p> Source code in <code>biocypher/_metadata.py</code> <pre><code>def get_metadata():\n    \"\"\"\n    Basic package metadata.\n\n    Retrieves package metadata from the current project directory or from\n    the installed package.\n    \"\"\"\n\n    here = pathlib.Path(__file__).parent\n    pyproj_toml = \"pyproject.toml\"\n    meta = {}\n\n    for project_dir in (here, here.parent):\n        toml_path = str(project_dir.joinpath(pyproj_toml).absolute())\n\n        if os.path.exists(toml_path):\n            pyproject = toml.load(toml_path)\n\n            meta = {\n                \"name\": pyproject[\"tool\"][\"poetry\"][\"name\"],\n                \"version\": pyproject[\"tool\"][\"poetry\"][\"version\"],\n                \"author\": pyproject[\"tool\"][\"poetry\"][\"authors\"],\n                \"license\": pyproject[\"tool\"][\"poetry\"][\"license\"],\n                \"full_metadata\": pyproject,\n            }\n\n            break\n\n    if not meta:\n        try:\n            meta = {\n                k.lower(): v\n                for k, v in importlib.metadata.metadata(here.name).items()\n            }\n\n        except importlib.metadata.PackageNotFoundError:\n            pass\n\n    meta[\"version\"] = meta.get(\"version\", None) or _VERSION\n\n    return meta\n</code></pre>"},{"location":"reference/source/#_miscpy","title":"_misc.py","text":"<p>Handy functions for use in various places.</p>"},{"location":"reference/source/#biocypher._misc._get_inheritance_tree","title":"<code>_get_inheritance_tree(inheritance_graph)</code>","text":"<p>Transforms an inheritance_graph into an inheritance_tree.</p> <p>Parameters:</p> Name Type Description Default <code>inheritance_graph</code> <code>Union[dict, Graph]</code> <p>A dict or nx.Graph representing the inheritance graph.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dict representing the inheritance tree.</p> Source code in <code>biocypher/_misc.py</code> <pre><code>def _get_inheritance_tree(inheritance_graph: Union[dict, nx.Graph]) -&gt; dict:\n    \"\"\"Transforms an inheritance_graph into an inheritance_tree.\n\n    Args:\n        inheritance_graph: A dict or nx.Graph representing the inheritance graph.\n\n    Returns:\n        A dict representing the inheritance tree.\n    \"\"\"\n    if isinstance(inheritance_graph, nx.Graph):\n        inheritance_tree = nx.to_dict_of_lists(inheritance_graph)\n\n        multiple_parents_present = _multiple_inheritance_present(\n            inheritance_tree\n        )\n        if multiple_parents_present:\n            logger.warning(\n                \"The ontology contains multiple inheritance (one child node \"\n                \"has multiple parent nodes). This is not visualized in the \"\n                \"following hierarchy tree (the child node is only added once). \"\n                \"If you wish to browse all relationships of the parsed \"\n                \"ontologies, write a graphml file to disk using \"\n                \"`to_disk = &lt;directory&gt;` and view this file.\"\n            )\n\n        # unlist values\n        inheritance_tree = {k: v[0] for k, v in inheritance_tree.items() if v}\n        return inheritance_tree\n    elif not _multiple_inheritance_present(inheritance_graph):\n        return inheritance_graph\n</code></pre>"},{"location":"reference/source/#biocypher._misc._multiple_inheritance_present","title":"<code>_multiple_inheritance_present(inheritance_tree)</code>","text":"<p>Checks if multiple inheritance is present in the inheritance_tree.</p> Source code in <code>biocypher/_misc.py</code> <pre><code>def _multiple_inheritance_present(inheritance_tree: dict) -&gt; bool:\n    \"\"\"Checks if multiple inheritance is present in the inheritance_tree.\"\"\"\n    return any(len(value) &gt; 1 for value in inheritance_tree.values())\n</code></pre>"},{"location":"reference/source/#biocypher._misc.create_tree_visualisation","title":"<code>create_tree_visualisation(inheritance_graph)</code>","text":"<p>Creates a visualisation of the inheritance tree using treelib.</p> Source code in <code>biocypher/_misc.py</code> <pre><code>def create_tree_visualisation(inheritance_graph: Union[dict, nx.Graph]) -&gt; Tree:\n    \"\"\"\n    Creates a visualisation of the inheritance tree using treelib.\n    \"\"\"\n    inheritance_tree = _get_inheritance_tree(inheritance_graph)\n    classes, root = _find_root_node(inheritance_tree)\n\n    tree = Tree()\n    tree.create_node(root, root)\n    while classes:\n        for child in classes:\n            parent = inheritance_tree[child]\n            if parent in tree.nodes.keys() or parent == root:\n                tree.create_node(child, child, parent=parent)\n\n        for node in tree.nodes.keys():\n            if node in classes:\n                classes.remove(node)\n\n    return tree\n</code></pre>"},{"location":"reference/source/#biocypher._misc.ensure_iterable","title":"<code>ensure_iterable(value)</code>","text":"<p>Returns iterables, except strings, wraps simple types into tuple.</p> Source code in <code>biocypher/_misc.py</code> <pre><code>def ensure_iterable(value: Any) -&gt; Iterable:\n    \"\"\"\n    Returns iterables, except strings, wraps simple types into tuple.\n    \"\"\"\n\n    return value if isinstance(value, LIST_LIKE) else (value,)\n</code></pre>"},{"location":"reference/source/#biocypher._misc.is_nested","title":"<code>is_nested(lst)</code>","text":"<p>Check if a list is nested.</p> <p>Parameters:</p> Name Type Description Default <code>lst</code> <code>list</code> <p>The list to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the list is nested, False otherwise.</p> Source code in <code>biocypher/_misc.py</code> <pre><code>def is_nested(lst) -&gt; bool:\n    \"\"\"\n    Check if a list is nested.\n\n    Args:\n        lst (list): The list to check.\n\n    Returns:\n        bool: True if the list is nested, False otherwise.\n    \"\"\"\n    for item in lst:\n        if isinstance(item, list):\n            return True\n    return False\n</code></pre>"},{"location":"reference/source/#biocypher._misc.pascalcase_to_sentencecase","title":"<code>pascalcase_to_sentencecase(s)</code>","text":"<p>Convert PascalCase to sentence case.</p> <p>Parameters:</p> Name Type Description Default <code>s</code> <code>str</code> <p>Input string in PascalCase</p> required <p>Returns:</p> Type Description <code>str</code> <p>string in sentence case form</p> Source code in <code>biocypher/_misc.py</code> <pre><code>def pascalcase_to_sentencecase(s: str) -&gt; str:\n    \"\"\"\n    Convert PascalCase to sentence case.\n\n    Args:\n        s: Input string in PascalCase\n\n    Returns:\n        string in sentence case form\n    \"\"\"\n    return from_pascal(s, sep=\" \")\n</code></pre>"},{"location":"reference/source/#biocypher._misc.sentencecase_to_pascalcase","title":"<code>sentencecase_to_pascalcase(s, sep='\\\\s')</code>","text":"<p>Convert sentence case to PascalCase.</p> <p>Parameters:</p> Name Type Description Default <code>s</code> <code>str</code> <p>Input string in sentence case</p> required <p>Returns:</p> Type Description <code>str</code> <p>string in PascalCase form</p> Source code in <code>biocypher/_misc.py</code> <pre><code>def sentencecase_to_pascalcase(s: str, sep: str = r\"\\s\") -&gt; str:\n    \"\"\"\n    Convert sentence case to PascalCase.\n\n    Args:\n        s: Input string in sentence case\n\n    Returns:\n        string in PascalCase form\n    \"\"\"\n    return re.sub(\n        r\"(?:^|[\" + sep + \"])([a-zA-Z])\",\n        lambda match: match.group(1).upper(),\n        s,\n    )\n</code></pre>"},{"location":"reference/source/#biocypher._misc.sentencecase_to_snakecase","title":"<code>sentencecase_to_snakecase(s)</code>","text":"<p>Convert sentence case to snake_case.</p> <p>Parameters:</p> Name Type Description Default <code>s</code> <code>str</code> <p>Input string in sentence case</p> required <p>Returns:</p> Type Description <code>str</code> <p>string in snake_case form</p> Source code in <code>biocypher/_misc.py</code> <pre><code>def sentencecase_to_snakecase(s: str) -&gt; str:\n    \"\"\"\n    Convert sentence case to snake_case.\n\n    Args:\n        s: Input string in sentence case\n\n    Returns:\n        string in snake_case form\n    \"\"\"\n    return stringcase.snakecase(s).lower()\n</code></pre>"},{"location":"reference/source/#biocypher._misc.snakecase_to_sentencecase","title":"<code>snakecase_to_sentencecase(s)</code>","text":"<p>Convert snake_case to sentence case.</p> <p>Parameters:</p> Name Type Description Default <code>s</code> <code>str</code> <p>Input string in snake_case</p> required <p>Returns:</p> Type Description <code>str</code> <p>string in sentence case form</p> Source code in <code>biocypher/_misc.py</code> <pre><code>def snakecase_to_sentencecase(s: str) -&gt; str:\n    \"\"\"\n    Convert snake_case to sentence case.\n\n    Args:\n        s: Input string in snake_case\n\n    Returns:\n        string in sentence case form\n    \"\"\"\n    return stringcase.sentencecase(s).lower()\n</code></pre>"},{"location":"reference/source/#biocypher._misc.to_list","title":"<code>to_list(value)</code>","text":"<p>Ensures that <code>value</code> is a list.</p> Source code in <code>biocypher/_misc.py</code> <pre><code>def to_list(value: Any) -&gt; list:\n    \"\"\"\n    Ensures that ``value`` is a list.\n    \"\"\"\n\n    if isinstance(value, LIST_LIKE):\n        value = list(value)\n\n    else:\n        value = [value]\n\n    return value\n</code></pre>"},{"location":"reference/source/#biocypher._misc.to_lower_sentence_case","title":"<code>to_lower_sentence_case(s)</code>","text":"<p>Convert any string to lower sentence case. Works with snake_case, PascalCase, and sentence case.</p> <p>Parameters:</p> Name Type Description Default <code>s</code> <code>str</code> <p>Input string</p> required <p>Returns:</p> Type Description <code>str</code> <p>string in lower sentence case form</p> Source code in <code>biocypher/_misc.py</code> <pre><code>def to_lower_sentence_case(s: str) -&gt; str:\n    \"\"\"\n    Convert any string to lower sentence case. Works with snake_case,\n    PascalCase, and sentence case.\n\n    Args:\n        s: Input string\n\n    Returns:\n        string in lower sentence case form\n    \"\"\"\n    if \"_\" in s:\n        return snakecase_to_sentencecase(s)\n    elif \" \" in s:\n        return s.lower()\n    elif s[0].isupper():\n        return pascalcase_to_sentencecase(s)\n    else:\n        return s\n</code></pre>"},{"location":"reference/source/#_ontologypy","title":"_ontology.py","text":"<p>BioCypher 'ontology' module. Contains classes and functions to handle parsing and representation of single ontologies as well as their hybridisation and other advanced operations.</p>"},{"location":"reference/source/#biocypher._ontology.Ontology","title":"<code>Ontology</code>","text":"<p>A class that represents the ontological \"backbone\" of a BioCypher knowledge graph. The ontology can be built from a single resource, or hybridised from a combination of resources, with one resource being the \"head\" ontology, while an arbitrary number of other resources can become \"tail\" ontologies at arbitrary fusion points inside the \"head\" ontology.</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>class Ontology:\n    \"\"\"\n    A class that represents the ontological \"backbone\" of a BioCypher knowledge\n    graph. The ontology can be built from a single resource, or hybridised from\n    a combination of resources, with one resource being the \"head\" ontology,\n    while an arbitrary number of other resources can become \"tail\" ontologies at\n    arbitrary fusion points inside the \"head\" ontology.\n    \"\"\"\n\n    def __init__(\n        self,\n        head_ontology: dict,\n        ontology_mapping: Optional[\"OntologyMapping\"] = None,\n        tail_ontologies: Optional[dict] = None,\n    ):\n        \"\"\"\n        Initialize the Ontology class.\n\n        Args:\n            head_ontology (OntologyAdapter): The head ontology.\n\n            tail_ontologies (list): A list of OntologyAdapters that will be\n                added to the head ontology. Defaults to None.\n        \"\"\"\n\n        self._head_ontology_meta = head_ontology\n        self.mapping = ontology_mapping\n        self._tail_ontology_meta = tail_ontologies\n\n        self._tail_ontologies = None\n        self._nx_graph = None\n\n        # keep track of nodes that have been extended\n        self._extended_nodes = set()\n\n        self._main()\n\n    def _main(self) -&gt; None:\n        \"\"\"\n        Main method to be run on instantiation. Loads the ontologies, joins\n        them, and returns the hybrid ontology. Loads only the head ontology\n        if nothing else is given. Adds user extensions and properties from\n        the mapping.\n        \"\"\"\n        self._load_ontologies()\n\n        if self._tail_ontologies:\n            for adapter in self._tail_ontologies.values():\n                head_join_node = self._get_head_join_node(adapter)\n                self._join_ontologies(adapter, head_join_node)\n        else:\n            self._nx_graph = self._head_ontology.get_nx_graph()\n\n        if self.mapping:\n            self._extend_ontology()\n\n            # experimental: add connections of disjoint classes to entity\n            # self._connect_biolink_classes()\n\n            self._add_properties()\n\n    def _load_ontologies(self) -&gt; None:\n        \"\"\"\n        For each ontology, load the OntologyAdapter object and store it as an\n        instance variable (head) or a dictionary (tail).\n        \"\"\"\n\n        logger.info(\"Loading ontologies...\")\n\n        self._head_ontology = OntologyAdapter(\n            ontology_file=self._head_ontology_meta[\"url\"],\n            root_label=self._head_ontology_meta[\"root_node\"],\n            ontology_file_format=self._head_ontology_meta.get(\"format\", None),\n            switch_label_and_id=self._head_ontology_meta.get(\n                \"switch_label_and_id\", True\n            ),\n        )\n\n        if self._tail_ontology_meta:\n            self._tail_ontologies = {}\n            for key, value in self._tail_ontology_meta.items():\n                self._tail_ontologies[key] = OntologyAdapter(\n                    ontology_file=value[\"url\"],\n                    root_label=value[\"tail_join_node\"],\n                    head_join_node_label=value[\"head_join_node\"],\n                    ontology_file_format=value.get(\"format\", None),\n                    merge_nodes=value.get(\"merge_nodes\", True),\n                    switch_label_and_id=value.get(\"switch_label_and_id\", True),\n                )\n\n    def _get_head_join_node(self, adapter: OntologyAdapter) -&gt; str:\n        \"\"\"\n        Tries to find the head join node of the given ontology adapter in the\n        head ontology. If the join node is not found, the method will raise an\n        error.\n\n        Args:\n            adapter (OntologyAdapter): The ontology adapter of which to find the\n                join node in the head ontology.\n        \"\"\"\n\n        head_join_node = None\n        user_defined_head_join_node_label = adapter.get_head_join_node()\n        head_join_node_label_in_bc_format = to_lower_sentence_case(\n            user_defined_head_join_node_label.replace(\"_\", \" \")\n        )\n\n        if self._head_ontology._switch_label_and_id:\n            head_join_node = head_join_node_label_in_bc_format\n        elif not self._head_ontology._switch_label_and_id:\n            for node_id, data in self._head_ontology.get_nx_graph().nodes(\n                data=True\n            ):\n                if (\n                    \"label\" in data\n                    and data[\"label\"] == head_join_node_label_in_bc_format\n                ):\n                    head_join_node = node_id\n                    break\n\n        if head_join_node not in self._head_ontology.get_nx_graph().nodes:\n            head_ontology = self._head_ontology._rdf_to_nx(\n                self._head_ontology.get_rdf_graph(),\n                self._head_ontology._root_label,\n                self._head_ontology._switch_label_and_id,\n                rename_nodes=False,\n            )\n            raise ValueError(\n                f\"Head join node '{head_join_node}' not found in head ontology. \"\n                f\"The head ontology contains the following nodes: {head_ontology.nodes}.\"\n            )\n        return head_join_node\n\n    def _join_ontologies(\n        self, adapter: OntologyAdapter, head_join_node\n    ) -&gt; None:\n        \"\"\"\n        Joins the ontologies by adding the tail ontology as a subgraph to the\n        head ontology at the specified join nodes.\n\n        Args:\n            adapter (OntologyAdapter): The ontology adapter of the tail ontology\n                to be added to the head ontology.\n        \"\"\"\n\n        if not self._nx_graph:\n            self._nx_graph = self._head_ontology.get_nx_graph().copy()\n\n        tail_join_node = adapter.get_root_node()\n        tail_ontology = adapter.get_nx_graph()\n\n        # subtree of tail ontology at join node\n        tail_ontology_subtree = nx.dfs_tree(\n            tail_ontology.reverse(), tail_join_node\n        ).reverse()\n\n        # transfer node attributes from tail ontology to subtree\n        for node in tail_ontology_subtree.nodes:\n            tail_ontology_subtree.nodes[node].update(tail_ontology.nodes[node])\n\n        # if merge_nodes is False, create parent of tail join node from head\n        # join node\n        if not adapter._merge_nodes:\n            # add head join node from head ontology to tail ontology subtree\n            # as parent of tail join node\n            tail_ontology_subtree.add_node(\n                head_join_node,\n                **self._head_ontology.get_nx_graph().nodes[head_join_node],\n            )\n            tail_ontology_subtree.add_edge(tail_join_node, head_join_node)\n\n        # else rename tail join node to match head join node if necessary\n        elif not tail_join_node == head_join_node:\n            tail_ontology_subtree = nx.relabel_nodes(\n                tail_ontology_subtree, {tail_join_node: head_join_node}\n            )\n\n        # combine head ontology and tail subtree\n        self._nx_graph = nx.compose(self._nx_graph, tail_ontology_subtree)\n\n    def _extend_ontology(self) -&gt; None:\n        \"\"\"\n        Adds the user extensions to the ontology. Tries to find the parent in\n        the ontology, adds it if necessary, and adds the child and a directed\n        edge from child to parent. Can handle multiple parents.\n        \"\"\"\n\n        if not self._nx_graph:\n            self._nx_graph = self._head_ontology.get_nx_graph().copy()\n\n        for key, value in self.mapping.extended_schema.items():\n            if not value.get(\"is_a\"):\n                if self._nx_graph.has_node(value.get(\"synonym_for\")):\n                    continue\n\n                if not self._nx_graph.has_node(key):\n                    raise ValueError(\n                        f\"Node {key} not found in ontology, but also has no \"\n                        \"inheritance definition. Please check your schema for \"\n                        \"spelling errors, first letter not in lower case, use of underscores, a missing `is_a` definition (SubClassOf a root node), or missing labels in class or super-classes.\"\n                    )\n\n                continue\n\n            parents = to_list(value.get(\"is_a\"))\n            child = key\n\n            while parents:\n                parent = parents.pop(0)\n\n                if parent not in self._nx_graph.nodes:\n                    self._nx_graph.add_node(parent)\n                    self._nx_graph.nodes[parent][\n                        \"label\"\n                    ] = sentencecase_to_pascalcase(parent)\n\n                    # mark parent as user extension\n                    self._nx_graph.nodes[parent][\"user_extension\"] = True\n                    self._extended_nodes.add(parent)\n\n                if child not in self._nx_graph.nodes:\n                    self._nx_graph.add_node(child)\n                    self._nx_graph.nodes[child][\n                        \"label\"\n                    ] = sentencecase_to_pascalcase(child)\n\n                    # mark child as user extension\n                    self._nx_graph.nodes[child][\"user_extension\"] = True\n                    self._extended_nodes.add(child)\n\n                self._nx_graph.add_edge(child, parent)\n\n                child = parent\n\n    def _connect_biolink_classes(self) -&gt; None:\n        \"\"\"\n        Experimental: Adds edges from disjoint classes to the entity node.\n        \"\"\"\n\n        if not self._nx_graph:\n            self._nx_graph = self._head_ontology.get_nx_graph().copy()\n\n        if \"entity\" not in self._nx_graph.nodes:\n            return\n\n        # biolink classes that are disjoint from entity\n        disjoint_classes = [\n            \"frequency qualifier mixin\",\n            \"chemical entity to entity association mixin\",\n            \"ontology class\",\n            \"relationship quantifier\",\n            \"physical essence or occurrent\",\n            \"gene or gene product\",\n            \"subject of investigation\",\n        ]\n\n        for node in disjoint_classes:\n            if not self._nx_graph.nodes.get(node):\n                self._nx_graph.add_node(node)\n                self._nx_graph.nodes[node][\n                    \"label\"\n                ] = sentencecase_to_pascalcase(node)\n\n            self._nx_graph.add_edge(node, \"entity\")\n\n    def _add_properties(self) -&gt; None:\n        \"\"\"\n        For each entity in the mapping, update the ontology with the properties\n        specified in the mapping. Updates synonym information in the graph,\n        setting the synonym as the primary node label.\n        \"\"\"\n\n        for key, value in self.mapping.extended_schema.items():\n            if key in self._nx_graph.nodes:\n                self._nx_graph.nodes[key].update(value)\n\n            if value.get(\"synonym_for\"):\n                # change node label to synonym\n                if value[\"synonym_for\"] not in self._nx_graph.nodes:\n                    raise ValueError(\n                        f'Node {value[\"synonym_for\"]} not found in ontology.'\n                    )\n\n                self._nx_graph = nx.relabel_nodes(\n                    self._nx_graph, {value[\"synonym_for\"]: key}\n                )\n\n    def get_ancestors(self, node_label: str) -&gt; list:\n        \"\"\"\n        Get the ancestors of a node in the ontology.\n\n        Args:\n            node_label (str): The label of the node in the ontology.\n\n        Returns:\n            list: A list of the ancestors of the node.\n        \"\"\"\n\n        return nx.dfs_tree(self._nx_graph, node_label)\n\n    def show_ontology_structure(self, to_disk: str = None, full: bool = False):\n        \"\"\"\n        Show the ontology structure using treelib or write to GRAPHML file.\n\n        Args:\n\n            to_disk (str): If specified, the ontology structure will be saved\n                to disk as a GRAPHML file at the location (directory) specified\n                by the `to_disk` string, to be opened in your favourite graph\n                visualisation tool.\n\n            full (bool): If True, the full ontology structure will be shown,\n                including all nodes and edges. If False, only the nodes and\n                edges that are relevant to the extended schema will be shown.\n        \"\"\"\n\n        if not full and not self.mapping.extended_schema:\n            raise ValueError(\n                \"You are attempting to visualise a subset of the loaded\"\n                \"ontology, but have not provided a schema configuration. \"\n                \"To display a partial ontology graph, please provide a schema \"\n                \"configuration file; to visualise the full graph, please use \"\n                \"the parameter `full = True`.\"\n            )\n\n        if not self._nx_graph:\n            raise ValueError(\"Ontology not loaded.\")\n\n        if not self._tail_ontologies:\n            msg = f\"Showing ontology structure based on {self._head_ontology._ontology_file}\"\n\n        else:\n            msg = f\"Showing ontology structure based on {len(self._tail_ontology_meta)+1} ontologies: \"\n\n        logger.info(msg)\n\n        if not full:\n            # set of leaves and their intermediate parents up to the root\n            filter_nodes = set(self.mapping.extended_schema.keys())\n\n            for node in self.mapping.extended_schema.keys():\n                filter_nodes.update(self.get_ancestors(node).nodes)\n\n            # filter graph\n            G = self._nx_graph.subgraph(filter_nodes)\n\n        else:\n            G = self._nx_graph\n\n        if not to_disk:\n            # create tree\n            tree = create_tree_visualisation(G)\n\n            # add synonym information\n            for node in self.mapping.extended_schema:\n                if not isinstance(self.mapping.extended_schema[node], dict):\n                    continue\n                if self.mapping.extended_schema[node].get(\"synonym_for\"):\n                    tree.nodes[node].tag = (\n                        f\"{node} = \"\n                        f\"{self.mapping.extended_schema[node].get('synonym_for')}\"\n                    )\n\n            logger.info(f\"\\n{tree}\")\n\n            return tree\n\n        else:\n            # convert lists/dicts to strings for vis only\n            for node in G.nodes:\n                # rename node and use former id as label\n                label = G.nodes[node].get(\"label\")\n\n                if not label:\n                    label = node\n\n                G = nx.relabel_nodes(G, {node: label})\n                G.nodes[label][\"label\"] = node\n\n                for attrib in G.nodes[label]:\n                    if type(G.nodes[label][attrib]) in [list, dict]:\n                        G.nodes[label][attrib] = str(G.nodes[label][attrib])\n\n            path = os.path.join(to_disk, \"ontology_structure.graphml\")\n\n            logger.info(f\"Writing ontology structure to {path}.\")\n\n            nx.write_graphml(G, path)\n\n            return True\n\n    def get_dict(self) -&gt; dict:\n        \"\"\"\n        Returns a dictionary compatible with a BioCypher node for compatibility\n        with the Neo4j driver.\n        \"\"\"\n\n        d = {\n            \"node_id\": self._get_current_id(),\n            \"node_label\": \"BioCypher\",\n            \"properties\": {\n                \"schema\": \"self.ontology_mapping.extended_schema\",\n            },\n        }\n\n        return d\n\n    def _get_current_id(self):\n        \"\"\"\n        Instantiate a version ID for the current session. For now does simple\n        versioning using datetime.\n\n        Can later implement incremental versioning, versioning from\n        config file, or manual specification via argument.\n        \"\"\"\n\n        now = datetime.now()\n        return now.strftime(\"v%Y%m%d-%H%M%S\")\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.Ontology.__init__","title":"<code>__init__(head_ontology, ontology_mapping=None, tail_ontologies=None)</code>","text":"<p>Initialize the Ontology class.</p> <p>Parameters:</p> Name Type Description Default <code>head_ontology</code> <code>OntologyAdapter</code> <p>The head ontology.</p> required <code>tail_ontologies</code> <code>list</code> <p>A list of OntologyAdapters that will be added to the head ontology. Defaults to None.</p> <code>None</code> Source code in <code>biocypher/_ontology.py</code> <pre><code>def __init__(\n    self,\n    head_ontology: dict,\n    ontology_mapping: Optional[\"OntologyMapping\"] = None,\n    tail_ontologies: Optional[dict] = None,\n):\n    \"\"\"\n    Initialize the Ontology class.\n\n    Args:\n        head_ontology (OntologyAdapter): The head ontology.\n\n        tail_ontologies (list): A list of OntologyAdapters that will be\n            added to the head ontology. Defaults to None.\n    \"\"\"\n\n    self._head_ontology_meta = head_ontology\n    self.mapping = ontology_mapping\n    self._tail_ontology_meta = tail_ontologies\n\n    self._tail_ontologies = None\n    self._nx_graph = None\n\n    # keep track of nodes that have been extended\n    self._extended_nodes = set()\n\n    self._main()\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.Ontology._add_properties","title":"<code>_add_properties()</code>","text":"<p>For each entity in the mapping, update the ontology with the properties specified in the mapping. Updates synonym information in the graph, setting the synonym as the primary node label.</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def _add_properties(self) -&gt; None:\n    \"\"\"\n    For each entity in the mapping, update the ontology with the properties\n    specified in the mapping. Updates synonym information in the graph,\n    setting the synonym as the primary node label.\n    \"\"\"\n\n    for key, value in self.mapping.extended_schema.items():\n        if key in self._nx_graph.nodes:\n            self._nx_graph.nodes[key].update(value)\n\n        if value.get(\"synonym_for\"):\n            # change node label to synonym\n            if value[\"synonym_for\"] not in self._nx_graph.nodes:\n                raise ValueError(\n                    f'Node {value[\"synonym_for\"]} not found in ontology.'\n                )\n\n            self._nx_graph = nx.relabel_nodes(\n                self._nx_graph, {value[\"synonym_for\"]: key}\n            )\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.Ontology._connect_biolink_classes","title":"<code>_connect_biolink_classes()</code>","text":"<p>Experimental: Adds edges from disjoint classes to the entity node.</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def _connect_biolink_classes(self) -&gt; None:\n    \"\"\"\n    Experimental: Adds edges from disjoint classes to the entity node.\n    \"\"\"\n\n    if not self._nx_graph:\n        self._nx_graph = self._head_ontology.get_nx_graph().copy()\n\n    if \"entity\" not in self._nx_graph.nodes:\n        return\n\n    # biolink classes that are disjoint from entity\n    disjoint_classes = [\n        \"frequency qualifier mixin\",\n        \"chemical entity to entity association mixin\",\n        \"ontology class\",\n        \"relationship quantifier\",\n        \"physical essence or occurrent\",\n        \"gene or gene product\",\n        \"subject of investigation\",\n    ]\n\n    for node in disjoint_classes:\n        if not self._nx_graph.nodes.get(node):\n            self._nx_graph.add_node(node)\n            self._nx_graph.nodes[node][\n                \"label\"\n            ] = sentencecase_to_pascalcase(node)\n\n        self._nx_graph.add_edge(node, \"entity\")\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.Ontology._extend_ontology","title":"<code>_extend_ontology()</code>","text":"<p>Adds the user extensions to the ontology. Tries to find the parent in the ontology, adds it if necessary, and adds the child and a directed edge from child to parent. Can handle multiple parents.</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def _extend_ontology(self) -&gt; None:\n    \"\"\"\n    Adds the user extensions to the ontology. Tries to find the parent in\n    the ontology, adds it if necessary, and adds the child and a directed\n    edge from child to parent. Can handle multiple parents.\n    \"\"\"\n\n    if not self._nx_graph:\n        self._nx_graph = self._head_ontology.get_nx_graph().copy()\n\n    for key, value in self.mapping.extended_schema.items():\n        if not value.get(\"is_a\"):\n            if self._nx_graph.has_node(value.get(\"synonym_for\")):\n                continue\n\n            if not self._nx_graph.has_node(key):\n                raise ValueError(\n                    f\"Node {key} not found in ontology, but also has no \"\n                    \"inheritance definition. Please check your schema for \"\n                    \"spelling errors, first letter not in lower case, use of underscores, a missing `is_a` definition (SubClassOf a root node), or missing labels in class or super-classes.\"\n                )\n\n            continue\n\n        parents = to_list(value.get(\"is_a\"))\n        child = key\n\n        while parents:\n            parent = parents.pop(0)\n\n            if parent not in self._nx_graph.nodes:\n                self._nx_graph.add_node(parent)\n                self._nx_graph.nodes[parent][\n                    \"label\"\n                ] = sentencecase_to_pascalcase(parent)\n\n                # mark parent as user extension\n                self._nx_graph.nodes[parent][\"user_extension\"] = True\n                self._extended_nodes.add(parent)\n\n            if child not in self._nx_graph.nodes:\n                self._nx_graph.add_node(child)\n                self._nx_graph.nodes[child][\n                    \"label\"\n                ] = sentencecase_to_pascalcase(child)\n\n                # mark child as user extension\n                self._nx_graph.nodes[child][\"user_extension\"] = True\n                self._extended_nodes.add(child)\n\n            self._nx_graph.add_edge(child, parent)\n\n            child = parent\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.Ontology._get_current_id","title":"<code>_get_current_id()</code>","text":"<p>Instantiate a version ID for the current session. For now does simple versioning using datetime.</p> <p>Can later implement incremental versioning, versioning from config file, or manual specification via argument.</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def _get_current_id(self):\n    \"\"\"\n    Instantiate a version ID for the current session. For now does simple\n    versioning using datetime.\n\n    Can later implement incremental versioning, versioning from\n    config file, or manual specification via argument.\n    \"\"\"\n\n    now = datetime.now()\n    return now.strftime(\"v%Y%m%d-%H%M%S\")\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.Ontology._get_head_join_node","title":"<code>_get_head_join_node(adapter)</code>","text":"<p>Tries to find the head join node of the given ontology adapter in the head ontology. If the join node is not found, the method will raise an error.</p> <p>Parameters:</p> Name Type Description Default <code>adapter</code> <code>OntologyAdapter</code> <p>The ontology adapter of which to find the join node in the head ontology.</p> required Source code in <code>biocypher/_ontology.py</code> <pre><code>def _get_head_join_node(self, adapter: OntologyAdapter) -&gt; str:\n    \"\"\"\n    Tries to find the head join node of the given ontology adapter in the\n    head ontology. If the join node is not found, the method will raise an\n    error.\n\n    Args:\n        adapter (OntologyAdapter): The ontology adapter of which to find the\n            join node in the head ontology.\n    \"\"\"\n\n    head_join_node = None\n    user_defined_head_join_node_label = adapter.get_head_join_node()\n    head_join_node_label_in_bc_format = to_lower_sentence_case(\n        user_defined_head_join_node_label.replace(\"_\", \" \")\n    )\n\n    if self._head_ontology._switch_label_and_id:\n        head_join_node = head_join_node_label_in_bc_format\n    elif not self._head_ontology._switch_label_and_id:\n        for node_id, data in self._head_ontology.get_nx_graph().nodes(\n            data=True\n        ):\n            if (\n                \"label\" in data\n                and data[\"label\"] == head_join_node_label_in_bc_format\n            ):\n                head_join_node = node_id\n                break\n\n    if head_join_node not in self._head_ontology.get_nx_graph().nodes:\n        head_ontology = self._head_ontology._rdf_to_nx(\n            self._head_ontology.get_rdf_graph(),\n            self._head_ontology._root_label,\n            self._head_ontology._switch_label_and_id,\n            rename_nodes=False,\n        )\n        raise ValueError(\n            f\"Head join node '{head_join_node}' not found in head ontology. \"\n            f\"The head ontology contains the following nodes: {head_ontology.nodes}.\"\n        )\n    return head_join_node\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.Ontology._join_ontologies","title":"<code>_join_ontologies(adapter, head_join_node)</code>","text":"<p>Joins the ontologies by adding the tail ontology as a subgraph to the head ontology at the specified join nodes.</p> <p>Parameters:</p> Name Type Description Default <code>adapter</code> <code>OntologyAdapter</code> <p>The ontology adapter of the tail ontology to be added to the head ontology.</p> required Source code in <code>biocypher/_ontology.py</code> <pre><code>def _join_ontologies(\n    self, adapter: OntologyAdapter, head_join_node\n) -&gt; None:\n    \"\"\"\n    Joins the ontologies by adding the tail ontology as a subgraph to the\n    head ontology at the specified join nodes.\n\n    Args:\n        adapter (OntologyAdapter): The ontology adapter of the tail ontology\n            to be added to the head ontology.\n    \"\"\"\n\n    if not self._nx_graph:\n        self._nx_graph = self._head_ontology.get_nx_graph().copy()\n\n    tail_join_node = adapter.get_root_node()\n    tail_ontology = adapter.get_nx_graph()\n\n    # subtree of tail ontology at join node\n    tail_ontology_subtree = nx.dfs_tree(\n        tail_ontology.reverse(), tail_join_node\n    ).reverse()\n\n    # transfer node attributes from tail ontology to subtree\n    for node in tail_ontology_subtree.nodes:\n        tail_ontology_subtree.nodes[node].update(tail_ontology.nodes[node])\n\n    # if merge_nodes is False, create parent of tail join node from head\n    # join node\n    if not adapter._merge_nodes:\n        # add head join node from head ontology to tail ontology subtree\n        # as parent of tail join node\n        tail_ontology_subtree.add_node(\n            head_join_node,\n            **self._head_ontology.get_nx_graph().nodes[head_join_node],\n        )\n        tail_ontology_subtree.add_edge(tail_join_node, head_join_node)\n\n    # else rename tail join node to match head join node if necessary\n    elif not tail_join_node == head_join_node:\n        tail_ontology_subtree = nx.relabel_nodes(\n            tail_ontology_subtree, {tail_join_node: head_join_node}\n        )\n\n    # combine head ontology and tail subtree\n    self._nx_graph = nx.compose(self._nx_graph, tail_ontology_subtree)\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.Ontology._load_ontologies","title":"<code>_load_ontologies()</code>","text":"<p>For each ontology, load the OntologyAdapter object and store it as an instance variable (head) or a dictionary (tail).</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def _load_ontologies(self) -&gt; None:\n    \"\"\"\n    For each ontology, load the OntologyAdapter object and store it as an\n    instance variable (head) or a dictionary (tail).\n    \"\"\"\n\n    logger.info(\"Loading ontologies...\")\n\n    self._head_ontology = OntologyAdapter(\n        ontology_file=self._head_ontology_meta[\"url\"],\n        root_label=self._head_ontology_meta[\"root_node\"],\n        ontology_file_format=self._head_ontology_meta.get(\"format\", None),\n        switch_label_and_id=self._head_ontology_meta.get(\n            \"switch_label_and_id\", True\n        ),\n    )\n\n    if self._tail_ontology_meta:\n        self._tail_ontologies = {}\n        for key, value in self._tail_ontology_meta.items():\n            self._tail_ontologies[key] = OntologyAdapter(\n                ontology_file=value[\"url\"],\n                root_label=value[\"tail_join_node\"],\n                head_join_node_label=value[\"head_join_node\"],\n                ontology_file_format=value.get(\"format\", None),\n                merge_nodes=value.get(\"merge_nodes\", True),\n                switch_label_and_id=value.get(\"switch_label_and_id\", True),\n            )\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.Ontology._main","title":"<code>_main()</code>","text":"<p>Main method to be run on instantiation. Loads the ontologies, joins them, and returns the hybrid ontology. Loads only the head ontology if nothing else is given. Adds user extensions and properties from the mapping.</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def _main(self) -&gt; None:\n    \"\"\"\n    Main method to be run on instantiation. Loads the ontologies, joins\n    them, and returns the hybrid ontology. Loads only the head ontology\n    if nothing else is given. Adds user extensions and properties from\n    the mapping.\n    \"\"\"\n    self._load_ontologies()\n\n    if self._tail_ontologies:\n        for adapter in self._tail_ontologies.values():\n            head_join_node = self._get_head_join_node(adapter)\n            self._join_ontologies(adapter, head_join_node)\n    else:\n        self._nx_graph = self._head_ontology.get_nx_graph()\n\n    if self.mapping:\n        self._extend_ontology()\n\n        # experimental: add connections of disjoint classes to entity\n        # self._connect_biolink_classes()\n\n        self._add_properties()\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.Ontology.get_ancestors","title":"<code>get_ancestors(node_label)</code>","text":"<p>Get the ancestors of a node in the ontology.</p> <p>Parameters:</p> Name Type Description Default <code>node_label</code> <code>str</code> <p>The label of the node in the ontology.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of the ancestors of the node.</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def get_ancestors(self, node_label: str) -&gt; list:\n    \"\"\"\n    Get the ancestors of a node in the ontology.\n\n    Args:\n        node_label (str): The label of the node in the ontology.\n\n    Returns:\n        list: A list of the ancestors of the node.\n    \"\"\"\n\n    return nx.dfs_tree(self._nx_graph, node_label)\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.Ontology.get_dict","title":"<code>get_dict()</code>","text":"<p>Returns a dictionary compatible with a BioCypher node for compatibility with the Neo4j driver.</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def get_dict(self) -&gt; dict:\n    \"\"\"\n    Returns a dictionary compatible with a BioCypher node for compatibility\n    with the Neo4j driver.\n    \"\"\"\n\n    d = {\n        \"node_id\": self._get_current_id(),\n        \"node_label\": \"BioCypher\",\n        \"properties\": {\n            \"schema\": \"self.ontology_mapping.extended_schema\",\n        },\n    }\n\n    return d\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.Ontology.show_ontology_structure","title":"<code>show_ontology_structure(to_disk=None, full=False)</code>","text":"<p>Show the ontology structure using treelib or write to GRAPHML file.</p> <p>Args:</p> <pre><code>to_disk (str): If specified, the ontology structure will be saved\n    to disk as a GRAPHML file at the location (directory) specified\n    by the `to_disk` string, to be opened in your favourite graph\n    visualisation tool.\n\nfull (bool): If True, the full ontology structure will be shown,\n    including all nodes and edges. If False, only the nodes and\n    edges that are relevant to the extended schema will be shown.\n</code></pre> Source code in <code>biocypher/_ontology.py</code> <pre><code>def show_ontology_structure(self, to_disk: str = None, full: bool = False):\n    \"\"\"\n    Show the ontology structure using treelib or write to GRAPHML file.\n\n    Args:\n\n        to_disk (str): If specified, the ontology structure will be saved\n            to disk as a GRAPHML file at the location (directory) specified\n            by the `to_disk` string, to be opened in your favourite graph\n            visualisation tool.\n\n        full (bool): If True, the full ontology structure will be shown,\n            including all nodes and edges. If False, only the nodes and\n            edges that are relevant to the extended schema will be shown.\n    \"\"\"\n\n    if not full and not self.mapping.extended_schema:\n        raise ValueError(\n            \"You are attempting to visualise a subset of the loaded\"\n            \"ontology, but have not provided a schema configuration. \"\n            \"To display a partial ontology graph, please provide a schema \"\n            \"configuration file; to visualise the full graph, please use \"\n            \"the parameter `full = True`.\"\n        )\n\n    if not self._nx_graph:\n        raise ValueError(\"Ontology not loaded.\")\n\n    if not self._tail_ontologies:\n        msg = f\"Showing ontology structure based on {self._head_ontology._ontology_file}\"\n\n    else:\n        msg = f\"Showing ontology structure based on {len(self._tail_ontology_meta)+1} ontologies: \"\n\n    logger.info(msg)\n\n    if not full:\n        # set of leaves and their intermediate parents up to the root\n        filter_nodes = set(self.mapping.extended_schema.keys())\n\n        for node in self.mapping.extended_schema.keys():\n            filter_nodes.update(self.get_ancestors(node).nodes)\n\n        # filter graph\n        G = self._nx_graph.subgraph(filter_nodes)\n\n    else:\n        G = self._nx_graph\n\n    if not to_disk:\n        # create tree\n        tree = create_tree_visualisation(G)\n\n        # add synonym information\n        for node in self.mapping.extended_schema:\n            if not isinstance(self.mapping.extended_schema[node], dict):\n                continue\n            if self.mapping.extended_schema[node].get(\"synonym_for\"):\n                tree.nodes[node].tag = (\n                    f\"{node} = \"\n                    f\"{self.mapping.extended_schema[node].get('synonym_for')}\"\n                )\n\n        logger.info(f\"\\n{tree}\")\n\n        return tree\n\n    else:\n        # convert lists/dicts to strings for vis only\n        for node in G.nodes:\n            # rename node and use former id as label\n            label = G.nodes[node].get(\"label\")\n\n            if not label:\n                label = node\n\n            G = nx.relabel_nodes(G, {node: label})\n            G.nodes[label][\"label\"] = node\n\n            for attrib in G.nodes[label]:\n                if type(G.nodes[label][attrib]) in [list, dict]:\n                    G.nodes[label][attrib] = str(G.nodes[label][attrib])\n\n        path = os.path.join(to_disk, \"ontology_structure.graphml\")\n\n        logger.info(f\"Writing ontology structure to {path}.\")\n\n        nx.write_graphml(G, path)\n\n        return True\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.OntologyAdapter","title":"<code>OntologyAdapter</code>","text":"<p>Class that represents an ontology to be used in the Biocypher framework. Can read from a variety of formats, including OWL, OBO, and RDF/XML. The ontology is represented by a networkx.DiGraph object; an RDFlib graph is also kept. By default, the DiGraph reverses the label and identifier of the nodes, such that the node name in the graph is the human-readable label. The edges are oriented from child to parent. Labels are formatted in lower sentence case and underscores are replaced by spaces. Identifiers are taken as defined and the prefixes are removed by default.</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>class OntologyAdapter:\n    \"\"\"\n    Class that represents an ontology to be used in the Biocypher framework. Can\n    read from a variety of formats, including OWL, OBO, and RDF/XML. The\n    ontology is represented by a networkx.DiGraph object; an RDFlib graph is\n    also kept. By default, the DiGraph reverses the label and identifier of the\n    nodes, such that the node name in the graph is the human-readable label. The\n    edges are oriented from child to parent.\n    Labels are formatted in lower sentence case and underscores are replaced by spaces.\n    Identifiers are taken as defined and the prefixes are removed by default.\n    \"\"\"\n\n    def __init__(\n        self,\n        ontology_file: str,\n        root_label: str,\n        ontology_file_format: Optional[str] = None,\n        head_join_node_label: Optional[str] = None,\n        merge_nodes: Optional[bool] = True,\n        switch_label_and_id: bool = True,\n        remove_prefixes: bool = True,\n    ):\n        \"\"\"\n        Initialize the OntologyAdapter class.\n\n        Args:\n            ontology_file (str): Path to the ontology file. Can be local or\n                remote.\n\n            root_label (str): The label of the root node in the ontology. In\n                case of a tail ontology, this is the tail join node.\n\n            ontology_file_format (str): The format of the ontology file (e.g. \"application/rdf+xml\")\n                If format is not passed, it is determined automatically.\n\n            head_join_node_label (str): Optional variable to store the label of the\n                node in the head ontology that should be used to join to the\n                root node of the tail ontology. Defaults to None.\n\n            merge_nodes (bool): If True, head and tail join nodes will be\n                merged, using the label of the head join node. If False, the\n                tail join node will be attached as a child of the head join\n                node.\n\n            switch_label_and_id (bool): If True, the node names in the graph will be\n                the human-readable labels. If False, the node names will be the\n                identifiers. Defaults to True.\n\n            remove_prefixes (bool): If True, the prefixes of the identifiers will\n                be removed. Defaults to True.\n        \"\"\"\n\n        logger.info(f\"Instantiating OntologyAdapter class for {ontology_file}.\")\n\n        self._ontology_file = ontology_file\n        self._root_label = root_label\n        self._format = ontology_file_format\n        self._merge_nodes = merge_nodes\n        self._head_join_node = head_join_node_label\n        self._switch_label_and_id = switch_label_and_id\n        self._remove_prefixes = remove_prefixes\n\n        self._rdf_graph = self._load_rdf_graph(ontology_file)\n\n        self._nx_graph = self._rdf_to_nx(\n            self._rdf_graph, root_label, switch_label_and_id\n        )\n\n    def _rdf_to_nx(\n        self,\n        _rdf_graph: rdflib.Graph,\n        root_label: str,\n        switch_label_and_id: bool,\n        rename_nodes: bool = True,\n    ) -&gt; nx.DiGraph:\n        one_to_one_triples, one_to_many_dict = self._get_relevant_rdf_triples(\n            _rdf_graph\n        )\n        nx_graph = self._convert_to_nx(one_to_one_triples, one_to_many_dict)\n        nx_graph = self._add_labels_to_nodes(nx_graph, switch_label_and_id)\n        nx_graph = self._change_nodes_to_biocypher_format(\n            nx_graph, switch_label_and_id, rename_nodes\n        )\n        nx_graph = self._get_all_ancestors(\n            nx_graph, root_label, switch_label_and_id, rename_nodes\n        )\n        return nx.DiGraph(nx_graph)\n\n    def _get_relevant_rdf_triples(self, g: rdflib.Graph) -&gt; tuple:\n        one_to_one_inheritance_graph = self._get_one_to_one_inheritance_triples(\n            g\n        )\n        intersection = self._get_multiple_inheritance_dict(g)\n        return one_to_one_inheritance_graph, intersection\n\n    def _get_one_to_one_inheritance_triples(\n        self, g: rdflib.Graph\n    ) -&gt; rdflib.Graph:\n        \"\"\"Get the one to one inheritance triples from the RDF graph.\n\n        Args:\n            g (rdflib.Graph): The RDF graph\n\n        Returns:\n            rdflib.Graph: The one to one inheritance graph\n        \"\"\"\n        one_to_one_inheritance_graph = Graph()\n        for s, p, o in g.triples((None, rdflib.RDFS.subClassOf, None)):\n            if self.has_label(s, g):\n                one_to_one_inheritance_graph.add((s, p, o))\n        return one_to_one_inheritance_graph\n\n    def _get_multiple_inheritance_dict(self, g: rdflib.Graph) -&gt; dict:\n        \"\"\"Get the multiple inheritance dictionary from the RDF graph.\n\n        Args:\n            g (rdflib.Graph): The RDF graph\n\n        Returns:\n            dict: The multiple inheritance dictionary\n        \"\"\"\n        multiple_inheritance = g.triples(\n            (None, rdflib.OWL.intersectionOf, None)\n        )\n        intersection = {}\n        for (\n            node,\n            has_multiple_parents,\n            first_node_of_intersection_list,\n        ) in multiple_inheritance:\n            parents = self._retrieve_rdf_linked_list(\n                first_node_of_intersection_list\n            )\n            child_name = None\n            for s_, _, _ in g.triples((None, rdflib.RDFS.subClassOf, node)):\n                child_name = s_\n\n            # Handle Snomed CT post coordinated expressions\n            if not child_name:\n                for s_, _, _ in g.triples(\n                    (None, rdflib.OWL.equivalentClass, node)\n                ):\n                    child_name = s_\n\n            if child_name:\n                intersection[node] = {\n                    \"child_name\": child_name,\n                    \"parent_node_names\": parents,\n                }\n        return intersection\n\n    def has_label(self, node: rdflib.URIRef, g: rdflib.Graph) -&gt; bool:\n        \"\"\"Does the node have a label in g?\n\n        Args:\n            node (rdflib.URIRef): The node to check\n            g (rdflib.Graph): The graph to check in\n        Returns:\n            bool: True if the node has a label, False otherwise\n        \"\"\"\n        return (node, rdflib.RDFS.label, None) in g\n\n    def _retrieve_rdf_linked_list(self, subject: rdflib.URIRef) -&gt; list:\n        \"\"\"Recursively retrieves a linked list from RDF.\n        Example RDF list with the items [item1, item2]:\n        list_node - first -&gt; item1\n        list_node - rest -&gt; list_node2\n        list_node2 - first -&gt; item2\n        list_node2 - rest -&gt; nil\n        Args:\n            subject (rdflib.URIRef): One list_node of the RDF list\n        Returns:\n            list: The items of the RDF list\n        \"\"\"\n        g = self._rdf_graph\n        rdf_list = []\n        for s, p, o in g.triples((subject, rdflib.RDF.first, None)):\n            rdf_list.append(o)\n        for s, p, o in g.triples((subject, rdflib.RDF.rest, None)):\n            if o != rdflib.RDF.nil:\n                rdf_list.extend(self._retrieve_rdf_linked_list(o))\n        return rdf_list\n\n    def _convert_to_nx(\n        self, one_to_one: rdflib.Graph, one_to_many: dict\n    ) -&gt; nx.DiGraph:\n        \"\"\"Convert the one to one and one to many inheritance graphs to networkx.\n\n        Args:\n            one_to_one (rdflib.Graph): The one to one inheritance graph\n            one_to_many (dict): The one to many inheritance dictionary\n\n        Returns:\n            nx.DiGraph: The networkx graph\n        \"\"\"\n        nx_graph = rdflib_to_networkx_digraph(\n            one_to_one, edge_attrs=lambda s, p, o: {}, calc_weights=False\n        )\n        for key, value in one_to_many.items():\n            nx_graph.add_edges_from(\n                [\n                    (value[\"child_name\"], parent)\n                    for parent in value[\"parent_node_names\"]\n                ]\n            )\n            if key in nx_graph.nodes:\n                nx_graph.remove_node(key)\n        return nx_graph\n\n    def _add_labels_to_nodes(\n        self, nx_graph: nx.DiGraph, switch_label_and_id: bool\n    ) -&gt; nx.DiGraph:\n        \"\"\"Add labels to the nodes in the networkx graph.\n\n        Args:\n            nx_graph (nx.DiGraph): The networkx graph\n            switch_label_and_id (bool): If True, id and label are switched\n\n        Returns:\n            nx.DiGraph: The networkx graph with labels\n        \"\"\"\n        for node in list(nx_graph.nodes):\n            nx_id, nx_label = self._get_nx_id_and_label(\n                node, switch_label_and_id\n            )\n            if nx_id == \"none\":\n                # remove node if it has no id\n                nx_graph.remove_node(node)\n                continue\n\n            nx_graph.nodes[node][\"label\"] = nx_label\n        return nx_graph\n\n    def _change_nodes_to_biocypher_format(\n        self,\n        nx_graph: nx.DiGraph,\n        switch_label_and_id: bool,\n        rename_nodes: bool = True,\n    ) -&gt; nx.DiGraph:\n        \"\"\"Change the nodes in the networkx graph to BioCypher format:\n            - remove the prefix of the identifier\n            - switch id and label\n            - adapt the labels (replace _ with space and convert to lower sentence case)\n\n        Args:\n            nx_graph (nx.DiGraph): The networkx graph\n            switch_label_and_id (bool): If True, id and label are switched\n            rename_nodes (bool): If True, the nodes are renamed\n\n        Returns:\n            nx.DiGraph: The networkx ontology graph in BioCypher format\n        \"\"\"\n        mapping = {\n            node: self._get_nx_id_and_label(\n                node, switch_label_and_id, rename_nodes\n            )[0]\n            for node in nx_graph.nodes\n        }\n        renamed = nx.relabel_nodes(nx_graph, mapping, copy=False)\n        return renamed\n\n    def _get_all_ancestors(\n        self,\n        renamed: nx.DiGraph,\n        root_label: str,\n        switch_label_and_id: bool,\n        rename_nodes: bool = True,\n    ) -&gt; nx.DiGraph:\n        \"\"\"Get all ancestors of the root node in the networkx graph.\n\n        Args:\n            renamed (nx.DiGraph): The renamed networkx graph\n            root_label (str): The label of the root node in the ontology\n            switch_label_and_id (bool): If True, id and label are switched\n            rename_nodes (bool): If True, the nodes are renamed\n\n        Returns:\n            nx.DiGraph: The filtered networkx graph\n        \"\"\"\n        root = self._get_nx_id_and_label(\n            self._find_root_label(self._rdf_graph, root_label),\n            switch_label_and_id,\n            rename_nodes,\n        )[0]\n        ancestors = nx.ancestors(renamed, root)\n        ancestors.add(root)\n        filtered_graph = renamed.subgraph(ancestors)\n        return filtered_graph\n\n    def _get_nx_id_and_label(\n        self, node, switch_id_and_label: bool, rename_nodes: bool = True\n    ) -&gt; tuple[str, str]:\n        \"\"\"Rename node id and label for nx graph.\n\n        Args:\n            node (str): The node to rename\n            switch_id_and_label (bool): If True, switch id and label\n\n        Returns:\n            tuple[str, str]: The renamed node id and label\n        \"\"\"\n        node_id_str = self._remove_prefix(str(node))\n        node_label_str = str(self._rdf_graph.value(node, rdflib.RDFS.label))\n        if rename_nodes:\n            node_label_str = node_label_str.replace(\"_\", \" \")\n            node_label_str = to_lower_sentence_case(node_label_str)\n        nx_id = node_label_str if switch_id_and_label else node_id_str\n        nx_label = node_id_str if switch_id_and_label else node_label_str\n        return nx_id, nx_label\n\n    def _find_root_label(self, g, root_label):\n        # Loop through all labels in the ontology\n        for label_subject, _, label_in_ontology in g.triples(\n            (None, rdflib.RDFS.label, None)\n        ):\n            # If the label is the root label, set the root node to the label's subject\n            if str(label_in_ontology) == root_label:\n                root = label_subject\n                break\n        else:\n            labels_in_ontology = []\n            for label_subject, _, label_in_ontology in g.triples(\n                (None, rdflib.RDFS.label, None)\n            ):\n                labels_in_ontology.append(str(label_in_ontology))\n            raise ValueError(\n                f\"Could not find root node with label '{root_label}'. \"\n                f\"The ontology contains the following labels: {labels_in_ontology}\"\n            )\n        return root\n\n    def _remove_prefix(self, uri: str) -&gt; str:\n        \"\"\"\n        Remove the prefix of a URI. URIs can contain either \"#\" or \"/\" as a\n        separator between the prefix and the local name. The prefix is\n        everything before the last separator.\n        \"\"\"\n        if self._remove_prefixes:\n            return uri.rsplit(\"#\", 1)[-1].rsplit(\"/\", 1)[-1]\n        else:\n            return uri\n\n    def _load_rdf_graph(self, ontology_file):\n        \"\"\"\n        Load the ontology into an RDFlib graph. The ontology file can be in\n        OWL, OBO, or RDF/XML format.\n        \"\"\"\n        g = rdflib.Graph()\n        g.parse(ontology_file, format=self._get_format(ontology_file))\n        return g\n\n    def _get_format(self, ontology_file):\n        \"\"\"\n        Get the format of the ontology file.\n        \"\"\"\n        if self._format:\n            if self._format == \"owl\":\n                return \"application/rdf+xml\"\n            elif self._format == \"obo\":\n                raise NotImplementedError(\"OBO format not yet supported\")\n            elif self._format == \"rdf\":\n                return \"application/rdf+xml\"\n            elif self._format == \"ttl\":\n                return self._format\n            else:\n                raise ValueError(\n                    f\"Could not determine format of ontology file {ontology_file}\"\n                )\n\n        if ontology_file.endswith(\".owl\"):\n            return \"application/rdf+xml\"\n        elif ontology_file.endswith(\".obo\"):\n            raise NotImplementedError(\"OBO format not yet supported\")\n        elif ontology_file.endswith(\".rdf\"):\n            return \"application/rdf+xml\"\n        elif ontology_file.endswith(\".ttl\"):\n            return \"ttl\"\n        else:\n            raise ValueError(\n                f\"Could not determine format of ontology file {ontology_file}\"\n            )\n\n    def get_nx_graph(self):\n        \"\"\"\n        Get the networkx graph representing the ontology.\n        \"\"\"\n        return self._nx_graph\n\n    def get_rdf_graph(self):\n        \"\"\"\n        Get the RDFlib graph representing the ontology.\n        \"\"\"\n        return self._rdf_graph\n\n    def get_root_node(self):\n        \"\"\"\n        Get root node in the ontology.\n\n        Returns:\n            root_node: If _switch_label_and_id is True, the root node label is returned,\n                otherwise the root node id is returned.\n        \"\"\"\n\n        root_node = None\n        root_label = self._root_label.replace(\"_\", \" \")\n\n        if self._switch_label_and_id:\n            root_node = to_lower_sentence_case(root_label)\n        elif not self._switch_label_and_id:\n            for node, data in self.get_nx_graph().nodes(data=True):\n                if \"label\" in data and data[\"label\"] == to_lower_sentence_case(\n                    root_label\n                ):\n                    root_node = node\n                    break\n\n        return root_node\n\n    def get_ancestors(self, node_label):\n        \"\"\"\n        Get the ancestors of a node in the ontology.\n        \"\"\"\n        return nx.dfs_preorder_nodes(self._nx_graph, node_label)\n\n    def get_head_join_node(self):\n        \"\"\"\n        Get the head join node of the ontology.\n        \"\"\"\n        return self._head_join_node\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.OntologyAdapter.__init__","title":"<code>__init__(ontology_file, root_label, ontology_file_format=None, head_join_node_label=None, merge_nodes=True, switch_label_and_id=True, remove_prefixes=True)</code>","text":"<p>Initialize the OntologyAdapter class.</p> <p>Parameters:</p> Name Type Description Default <code>ontology_file</code> <code>str</code> <p>Path to the ontology file. Can be local or remote.</p> required <code>root_label</code> <code>str</code> <p>The label of the root node in the ontology. In case of a tail ontology, this is the tail join node.</p> required <code>ontology_file_format</code> <code>str</code> <p>The format of the ontology file (e.g. \"application/rdf+xml\") If format is not passed, it is determined automatically.</p> <code>None</code> <code>head_join_node_label</code> <code>str</code> <p>Optional variable to store the label of the node in the head ontology that should be used to join to the root node of the tail ontology. Defaults to None.</p> <code>None</code> <code>merge_nodes</code> <code>bool</code> <p>If True, head and tail join nodes will be merged, using the label of the head join node. If False, the tail join node will be attached as a child of the head join node.</p> <code>True</code> <code>switch_label_and_id</code> <code>bool</code> <p>If True, the node names in the graph will be the human-readable labels. If False, the node names will be the identifiers. Defaults to True.</p> <code>True</code> <code>remove_prefixes</code> <code>bool</code> <p>If True, the prefixes of the identifiers will be removed. Defaults to True.</p> <code>True</code> Source code in <code>biocypher/_ontology.py</code> <pre><code>def __init__(\n    self,\n    ontology_file: str,\n    root_label: str,\n    ontology_file_format: Optional[str] = None,\n    head_join_node_label: Optional[str] = None,\n    merge_nodes: Optional[bool] = True,\n    switch_label_and_id: bool = True,\n    remove_prefixes: bool = True,\n):\n    \"\"\"\n    Initialize the OntologyAdapter class.\n\n    Args:\n        ontology_file (str): Path to the ontology file. Can be local or\n            remote.\n\n        root_label (str): The label of the root node in the ontology. In\n            case of a tail ontology, this is the tail join node.\n\n        ontology_file_format (str): The format of the ontology file (e.g. \"application/rdf+xml\")\n            If format is not passed, it is determined automatically.\n\n        head_join_node_label (str): Optional variable to store the label of the\n            node in the head ontology that should be used to join to the\n            root node of the tail ontology. Defaults to None.\n\n        merge_nodes (bool): If True, head and tail join nodes will be\n            merged, using the label of the head join node. If False, the\n            tail join node will be attached as a child of the head join\n            node.\n\n        switch_label_and_id (bool): If True, the node names in the graph will be\n            the human-readable labels. If False, the node names will be the\n            identifiers. Defaults to True.\n\n        remove_prefixes (bool): If True, the prefixes of the identifiers will\n            be removed. Defaults to True.\n    \"\"\"\n\n    logger.info(f\"Instantiating OntologyAdapter class for {ontology_file}.\")\n\n    self._ontology_file = ontology_file\n    self._root_label = root_label\n    self._format = ontology_file_format\n    self._merge_nodes = merge_nodes\n    self._head_join_node = head_join_node_label\n    self._switch_label_and_id = switch_label_and_id\n    self._remove_prefixes = remove_prefixes\n\n    self._rdf_graph = self._load_rdf_graph(ontology_file)\n\n    self._nx_graph = self._rdf_to_nx(\n        self._rdf_graph, root_label, switch_label_and_id\n    )\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.OntologyAdapter._add_labels_to_nodes","title":"<code>_add_labels_to_nodes(nx_graph, switch_label_and_id)</code>","text":"<p>Add labels to the nodes in the networkx graph.</p> <p>Parameters:</p> Name Type Description Default <code>nx_graph</code> <code>DiGraph</code> <p>The networkx graph</p> required <code>switch_label_and_id</code> <code>bool</code> <p>If True, id and label are switched</p> required <p>Returns:</p> Type Description <code>DiGraph</code> <p>nx.DiGraph: The networkx graph with labels</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def _add_labels_to_nodes(\n    self, nx_graph: nx.DiGraph, switch_label_and_id: bool\n) -&gt; nx.DiGraph:\n    \"\"\"Add labels to the nodes in the networkx graph.\n\n    Args:\n        nx_graph (nx.DiGraph): The networkx graph\n        switch_label_and_id (bool): If True, id and label are switched\n\n    Returns:\n        nx.DiGraph: The networkx graph with labels\n    \"\"\"\n    for node in list(nx_graph.nodes):\n        nx_id, nx_label = self._get_nx_id_and_label(\n            node, switch_label_and_id\n        )\n        if nx_id == \"none\":\n            # remove node if it has no id\n            nx_graph.remove_node(node)\n            continue\n\n        nx_graph.nodes[node][\"label\"] = nx_label\n    return nx_graph\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.OntologyAdapter._change_nodes_to_biocypher_format","title":"<code>_change_nodes_to_biocypher_format(nx_graph, switch_label_and_id, rename_nodes=True)</code>","text":"Change the nodes in the networkx graph to BioCypher format <ul> <li>remove the prefix of the identifier</li> <li>switch id and label</li> <li>adapt the labels (replace _ with space and convert to lower sentence case)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>nx_graph</code> <code>DiGraph</code> <p>The networkx graph</p> required <code>switch_label_and_id</code> <code>bool</code> <p>If True, id and label are switched</p> required <code>rename_nodes</code> <code>bool</code> <p>If True, the nodes are renamed</p> <code>True</code> <p>Returns:</p> Type Description <code>DiGraph</code> <p>nx.DiGraph: The networkx ontology graph in BioCypher format</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def _change_nodes_to_biocypher_format(\n    self,\n    nx_graph: nx.DiGraph,\n    switch_label_and_id: bool,\n    rename_nodes: bool = True,\n) -&gt; nx.DiGraph:\n    \"\"\"Change the nodes in the networkx graph to BioCypher format:\n        - remove the prefix of the identifier\n        - switch id and label\n        - adapt the labels (replace _ with space and convert to lower sentence case)\n\n    Args:\n        nx_graph (nx.DiGraph): The networkx graph\n        switch_label_and_id (bool): If True, id and label are switched\n        rename_nodes (bool): If True, the nodes are renamed\n\n    Returns:\n        nx.DiGraph: The networkx ontology graph in BioCypher format\n    \"\"\"\n    mapping = {\n        node: self._get_nx_id_and_label(\n            node, switch_label_and_id, rename_nodes\n        )[0]\n        for node in nx_graph.nodes\n    }\n    renamed = nx.relabel_nodes(nx_graph, mapping, copy=False)\n    return renamed\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.OntologyAdapter._convert_to_nx","title":"<code>_convert_to_nx(one_to_one, one_to_many)</code>","text":"<p>Convert the one to one and one to many inheritance graphs to networkx.</p> <p>Parameters:</p> Name Type Description Default <code>one_to_one</code> <code>Graph</code> <p>The one to one inheritance graph</p> required <code>one_to_many</code> <code>dict</code> <p>The one to many inheritance dictionary</p> required <p>Returns:</p> Type Description <code>DiGraph</code> <p>nx.DiGraph: The networkx graph</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def _convert_to_nx(\n    self, one_to_one: rdflib.Graph, one_to_many: dict\n) -&gt; nx.DiGraph:\n    \"\"\"Convert the one to one and one to many inheritance graphs to networkx.\n\n    Args:\n        one_to_one (rdflib.Graph): The one to one inheritance graph\n        one_to_many (dict): The one to many inheritance dictionary\n\n    Returns:\n        nx.DiGraph: The networkx graph\n    \"\"\"\n    nx_graph = rdflib_to_networkx_digraph(\n        one_to_one, edge_attrs=lambda s, p, o: {}, calc_weights=False\n    )\n    for key, value in one_to_many.items():\n        nx_graph.add_edges_from(\n            [\n                (value[\"child_name\"], parent)\n                for parent in value[\"parent_node_names\"]\n            ]\n        )\n        if key in nx_graph.nodes:\n            nx_graph.remove_node(key)\n    return nx_graph\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.OntologyAdapter._get_all_ancestors","title":"<code>_get_all_ancestors(renamed, root_label, switch_label_and_id, rename_nodes=True)</code>","text":"<p>Get all ancestors of the root node in the networkx graph.</p> <p>Parameters:</p> Name Type Description Default <code>renamed</code> <code>DiGraph</code> <p>The renamed networkx graph</p> required <code>root_label</code> <code>str</code> <p>The label of the root node in the ontology</p> required <code>switch_label_and_id</code> <code>bool</code> <p>If True, id and label are switched</p> required <code>rename_nodes</code> <code>bool</code> <p>If True, the nodes are renamed</p> <code>True</code> <p>Returns:</p> Type Description <code>DiGraph</code> <p>nx.DiGraph: The filtered networkx graph</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def _get_all_ancestors(\n    self,\n    renamed: nx.DiGraph,\n    root_label: str,\n    switch_label_and_id: bool,\n    rename_nodes: bool = True,\n) -&gt; nx.DiGraph:\n    \"\"\"Get all ancestors of the root node in the networkx graph.\n\n    Args:\n        renamed (nx.DiGraph): The renamed networkx graph\n        root_label (str): The label of the root node in the ontology\n        switch_label_and_id (bool): If True, id and label are switched\n        rename_nodes (bool): If True, the nodes are renamed\n\n    Returns:\n        nx.DiGraph: The filtered networkx graph\n    \"\"\"\n    root = self._get_nx_id_and_label(\n        self._find_root_label(self._rdf_graph, root_label),\n        switch_label_and_id,\n        rename_nodes,\n    )[0]\n    ancestors = nx.ancestors(renamed, root)\n    ancestors.add(root)\n    filtered_graph = renamed.subgraph(ancestors)\n    return filtered_graph\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.OntologyAdapter._get_format","title":"<code>_get_format(ontology_file)</code>","text":"<p>Get the format of the ontology file.</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def _get_format(self, ontology_file):\n    \"\"\"\n    Get the format of the ontology file.\n    \"\"\"\n    if self._format:\n        if self._format == \"owl\":\n            return \"application/rdf+xml\"\n        elif self._format == \"obo\":\n            raise NotImplementedError(\"OBO format not yet supported\")\n        elif self._format == \"rdf\":\n            return \"application/rdf+xml\"\n        elif self._format == \"ttl\":\n            return self._format\n        else:\n            raise ValueError(\n                f\"Could not determine format of ontology file {ontology_file}\"\n            )\n\n    if ontology_file.endswith(\".owl\"):\n        return \"application/rdf+xml\"\n    elif ontology_file.endswith(\".obo\"):\n        raise NotImplementedError(\"OBO format not yet supported\")\n    elif ontology_file.endswith(\".rdf\"):\n        return \"application/rdf+xml\"\n    elif ontology_file.endswith(\".ttl\"):\n        return \"ttl\"\n    else:\n        raise ValueError(\n            f\"Could not determine format of ontology file {ontology_file}\"\n        )\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.OntologyAdapter._get_multiple_inheritance_dict","title":"<code>_get_multiple_inheritance_dict(g)</code>","text":"<p>Get the multiple inheritance dictionary from the RDF graph.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Graph</code> <p>The RDF graph</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The multiple inheritance dictionary</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def _get_multiple_inheritance_dict(self, g: rdflib.Graph) -&gt; dict:\n    \"\"\"Get the multiple inheritance dictionary from the RDF graph.\n\n    Args:\n        g (rdflib.Graph): The RDF graph\n\n    Returns:\n        dict: The multiple inheritance dictionary\n    \"\"\"\n    multiple_inheritance = g.triples(\n        (None, rdflib.OWL.intersectionOf, None)\n    )\n    intersection = {}\n    for (\n        node,\n        has_multiple_parents,\n        first_node_of_intersection_list,\n    ) in multiple_inheritance:\n        parents = self._retrieve_rdf_linked_list(\n            first_node_of_intersection_list\n        )\n        child_name = None\n        for s_, _, _ in g.triples((None, rdflib.RDFS.subClassOf, node)):\n            child_name = s_\n\n        # Handle Snomed CT post coordinated expressions\n        if not child_name:\n            for s_, _, _ in g.triples(\n                (None, rdflib.OWL.equivalentClass, node)\n            ):\n                child_name = s_\n\n        if child_name:\n            intersection[node] = {\n                \"child_name\": child_name,\n                \"parent_node_names\": parents,\n            }\n    return intersection\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.OntologyAdapter._get_nx_id_and_label","title":"<code>_get_nx_id_and_label(node, switch_id_and_label, rename_nodes=True)</code>","text":"<p>Rename node id and label for nx graph.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>str</code> <p>The node to rename</p> required <code>switch_id_and_label</code> <code>bool</code> <p>If True, switch id and label</p> required <p>Returns:</p> Type Description <code>tuple[str, str]</code> <p>tuple[str, str]: The renamed node id and label</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def _get_nx_id_and_label(\n    self, node, switch_id_and_label: bool, rename_nodes: bool = True\n) -&gt; tuple[str, str]:\n    \"\"\"Rename node id and label for nx graph.\n\n    Args:\n        node (str): The node to rename\n        switch_id_and_label (bool): If True, switch id and label\n\n    Returns:\n        tuple[str, str]: The renamed node id and label\n    \"\"\"\n    node_id_str = self._remove_prefix(str(node))\n    node_label_str = str(self._rdf_graph.value(node, rdflib.RDFS.label))\n    if rename_nodes:\n        node_label_str = node_label_str.replace(\"_\", \" \")\n        node_label_str = to_lower_sentence_case(node_label_str)\n    nx_id = node_label_str if switch_id_and_label else node_id_str\n    nx_label = node_id_str if switch_id_and_label else node_label_str\n    return nx_id, nx_label\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.OntologyAdapter._get_one_to_one_inheritance_triples","title":"<code>_get_one_to_one_inheritance_triples(g)</code>","text":"<p>Get the one to one inheritance triples from the RDF graph.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Graph</code> <p>The RDF graph</p> required <p>Returns:</p> Type Description <code>Graph</code> <p>rdflib.Graph: The one to one inheritance graph</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def _get_one_to_one_inheritance_triples(\n    self, g: rdflib.Graph\n) -&gt; rdflib.Graph:\n    \"\"\"Get the one to one inheritance triples from the RDF graph.\n\n    Args:\n        g (rdflib.Graph): The RDF graph\n\n    Returns:\n        rdflib.Graph: The one to one inheritance graph\n    \"\"\"\n    one_to_one_inheritance_graph = Graph()\n    for s, p, o in g.triples((None, rdflib.RDFS.subClassOf, None)):\n        if self.has_label(s, g):\n            one_to_one_inheritance_graph.add((s, p, o))\n    return one_to_one_inheritance_graph\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.OntologyAdapter._load_rdf_graph","title":"<code>_load_rdf_graph(ontology_file)</code>","text":"<p>Load the ontology into an RDFlib graph. The ontology file can be in OWL, OBO, or RDF/XML format.</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def _load_rdf_graph(self, ontology_file):\n    \"\"\"\n    Load the ontology into an RDFlib graph. The ontology file can be in\n    OWL, OBO, or RDF/XML format.\n    \"\"\"\n    g = rdflib.Graph()\n    g.parse(ontology_file, format=self._get_format(ontology_file))\n    return g\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.OntologyAdapter._remove_prefix","title":"<code>_remove_prefix(uri)</code>","text":"<p>Remove the prefix of a URI. URIs can contain either \"#\" or \"/\" as a separator between the prefix and the local name. The prefix is everything before the last separator.</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def _remove_prefix(self, uri: str) -&gt; str:\n    \"\"\"\n    Remove the prefix of a URI. URIs can contain either \"#\" or \"/\" as a\n    separator between the prefix and the local name. The prefix is\n    everything before the last separator.\n    \"\"\"\n    if self._remove_prefixes:\n        return uri.rsplit(\"#\", 1)[-1].rsplit(\"/\", 1)[-1]\n    else:\n        return uri\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.OntologyAdapter._retrieve_rdf_linked_list","title":"<code>_retrieve_rdf_linked_list(subject)</code>","text":"<p>Recursively retrieves a linked list from RDF. Example RDF list with the items [item1, item2]: list_node - first -&gt; item1 list_node - rest -&gt; list_node2 list_node2 - first -&gt; item2 list_node2 - rest -&gt; nil Args:     subject (rdflib.URIRef): One list_node of the RDF list Returns:     list: The items of the RDF list</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def _retrieve_rdf_linked_list(self, subject: rdflib.URIRef) -&gt; list:\n    \"\"\"Recursively retrieves a linked list from RDF.\n    Example RDF list with the items [item1, item2]:\n    list_node - first -&gt; item1\n    list_node - rest -&gt; list_node2\n    list_node2 - first -&gt; item2\n    list_node2 - rest -&gt; nil\n    Args:\n        subject (rdflib.URIRef): One list_node of the RDF list\n    Returns:\n        list: The items of the RDF list\n    \"\"\"\n    g = self._rdf_graph\n    rdf_list = []\n    for s, p, o in g.triples((subject, rdflib.RDF.first, None)):\n        rdf_list.append(o)\n    for s, p, o in g.triples((subject, rdflib.RDF.rest, None)):\n        if o != rdflib.RDF.nil:\n            rdf_list.extend(self._retrieve_rdf_linked_list(o))\n    return rdf_list\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.OntologyAdapter.get_ancestors","title":"<code>get_ancestors(node_label)</code>","text":"<p>Get the ancestors of a node in the ontology.</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def get_ancestors(self, node_label):\n    \"\"\"\n    Get the ancestors of a node in the ontology.\n    \"\"\"\n    return nx.dfs_preorder_nodes(self._nx_graph, node_label)\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.OntologyAdapter.get_head_join_node","title":"<code>get_head_join_node()</code>","text":"<p>Get the head join node of the ontology.</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def get_head_join_node(self):\n    \"\"\"\n    Get the head join node of the ontology.\n    \"\"\"\n    return self._head_join_node\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.OntologyAdapter.get_nx_graph","title":"<code>get_nx_graph()</code>","text":"<p>Get the networkx graph representing the ontology.</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def get_nx_graph(self):\n    \"\"\"\n    Get the networkx graph representing the ontology.\n    \"\"\"\n    return self._nx_graph\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.OntologyAdapter.get_rdf_graph","title":"<code>get_rdf_graph()</code>","text":"<p>Get the RDFlib graph representing the ontology.</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def get_rdf_graph(self):\n    \"\"\"\n    Get the RDFlib graph representing the ontology.\n    \"\"\"\n    return self._rdf_graph\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.OntologyAdapter.get_root_node","title":"<code>get_root_node()</code>","text":"<p>Get root node in the ontology.</p> <p>Returns:</p> Name Type Description <code>root_node</code> <p>If _switch_label_and_id is True, the root node label is returned, otherwise the root node id is returned.</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def get_root_node(self):\n    \"\"\"\n    Get root node in the ontology.\n\n    Returns:\n        root_node: If _switch_label_and_id is True, the root node label is returned,\n            otherwise the root node id is returned.\n    \"\"\"\n\n    root_node = None\n    root_label = self._root_label.replace(\"_\", \" \")\n\n    if self._switch_label_and_id:\n        root_node = to_lower_sentence_case(root_label)\n    elif not self._switch_label_and_id:\n        for node, data in self.get_nx_graph().nodes(data=True):\n            if \"label\" in data and data[\"label\"] == to_lower_sentence_case(\n                root_label\n            ):\n                root_node = node\n                break\n\n    return root_node\n</code></pre>"},{"location":"reference/source/#biocypher._ontology.OntologyAdapter.has_label","title":"<code>has_label(node, g)</code>","text":"<p>Does the node have a label in g?</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>URIRef</code> <p>The node to check</p> required <code>g</code> <code>Graph</code> <p>The graph to check in</p> required <p>Returns:     bool: True if the node has a label, False otherwise</p> Source code in <code>biocypher/_ontology.py</code> <pre><code>def has_label(self, node: rdflib.URIRef, g: rdflib.Graph) -&gt; bool:\n    \"\"\"Does the node have a label in g?\n\n    Args:\n        node (rdflib.URIRef): The node to check\n        g (rdflib.Graph): The graph to check in\n    Returns:\n        bool: True if the node has a label, False otherwise\n    \"\"\"\n    return (node, rdflib.RDFS.label, None) in g\n</code></pre>"},{"location":"reference/source/#_translatepy","title":"_translate.py","text":"<p>BioCypher 'translation' module. Responsible for translating between the raw input data and the BioCypherNode and BioCypherEdge objects.</p>"},{"location":"reference/source/#biocypher._translate.Translator","title":"<code>Translator</code>","text":"<p>Class responsible for exacting the translation process that is configured in the schema_config.yaml file. Creates a mapping dictionary from that file, and, given nodes and edges, translates them into BioCypherNodes and BioCypherEdges. During this process, can also filter the properties of the entities if the schema_config.yaml file specifies a property whitelist or blacklist.</p> <p>Provides utility functions for translating between input and output labels and cypher queries.</p> Source code in <code>biocypher/_translate.py</code> <pre><code>class Translator:\n    \"\"\"\n    Class responsible for exacting the translation process that is configured in\n    the schema_config.yaml file. Creates a mapping dictionary from that file,\n    and, given nodes and edges, translates them into BioCypherNodes and\n    BioCypherEdges. During this process, can also filter the properties of the\n    entities if the schema_config.yaml file specifies a property whitelist or\n    blacklist.\n\n    Provides utility functions for translating between input and output labels\n    and cypher queries.\n    \"\"\"\n\n    def __init__(self, ontology: \"Ontology\", strict_mode: bool = False):\n        \"\"\"\n        Args:\n            leaves:\n                Dictionary detailing the leaves of the hierarchy\n                tree representing the structure of the graph; the leaves are\n                the entities that will be direct components of the graph,\n                while the intermediary nodes are additional labels for\n                filtering purposes.\n            strict_mode:\n                If True, the translator will raise an error if input data do not\n                carry source, licence, and version information.\n        \"\"\"\n\n        self.ontology = ontology\n        self.strict_mode = strict_mode\n\n        # record nodes without biolink type configured in schema_config.yaml\n        self.notype = {}\n\n        # mapping functionality for translating terms and queries\n        self.mappings = {}\n        self.reverse_mappings = {}\n\n        self._update_ontology_types()\n\n    def translate_nodes(\n        self,\n        node_tuples: Iterable,\n    ) -&gt; Generator[BioCypherNode, None, None]:\n        \"\"\"\n        Translates input node representation to a representation that\n        conforms to the schema of the given BioCypher graph. For now\n        requires explicit statement of node type on pass.\n\n        Args:\n            node_tuples (list of tuples): collection of tuples\n                representing individual nodes by their unique id and a type\n                that is translated from the original database notation to\n                the corresponding BioCypher notation.\n\n        \"\"\"\n\n        self._log_begin_translate(node_tuples, \"nodes\")\n\n        for _id, _type, _props in node_tuples:\n            # check for strict mode requirements\n            required_props = [\"source\", \"licence\", \"version\"]\n\n            if self.strict_mode:\n                # rename 'license' to 'licence' in _props\n                if _props.get(\"license\"):\n                    _props[\"licence\"] = _props.pop(\"license\")\n\n                for prop in required_props:\n                    if prop not in _props:\n                        raise ValueError(\n                            f\"Property `{prop}` missing from node {_id}. \"\n                            \"Strict mode is enabled, so this is not allowed.\"\n                        )\n\n            # find the node in leaves that represents ontology node type\n            _ontology_class = self._get_ontology_mapping(_type)\n\n            if _ontology_class:\n                # filter properties for those specified in schema_config if any\n                _filtered_props = self._filter_props(_ontology_class, _props)\n\n                # preferred id\n                _preferred_id = self._get_preferred_id(_ontology_class)\n\n                yield BioCypherNode(\n                    node_id=_id,\n                    node_label=_ontology_class,\n                    preferred_id=_preferred_id,\n                    properties=_filtered_props,\n                )\n\n            else:\n                self._record_no_type(_type, _id)\n\n        self._log_finish_translate(\"nodes\")\n\n    def _get_preferred_id(self, _bl_type: str) -&gt; str:\n        \"\"\"\n        Returns the preferred id for the given Biolink type.\n        \"\"\"\n\n        return (\n            self.ontology.mapping.extended_schema[_bl_type][\"preferred_id\"]\n            if \"preferred_id\"\n            in self.ontology.mapping.extended_schema.get(_bl_type, {})\n            else \"id\"\n        )\n\n    def _filter_props(self, bl_type: str, props: dict) -&gt; dict:\n        \"\"\"\n        Filters properties for those specified in schema_config if any.\n        \"\"\"\n\n        filter_props = self.ontology.mapping.extended_schema[bl_type].get(\n            \"properties\", {}\n        )\n\n        # strict mode: add required properties (only if there is a whitelist)\n        if self.strict_mode and filter_props:\n            filter_props.update(\n                {\"source\": \"str\", \"licence\": \"str\", \"version\": \"str\"},\n            )\n\n        exclude_props = self.ontology.mapping.extended_schema[bl_type].get(\n            \"exclude_properties\", []\n        )\n\n        if isinstance(exclude_props, str):\n            exclude_props = [exclude_props]\n\n        if filter_props and exclude_props:\n            filtered_props = {\n                k: v\n                for k, v in props.items()\n                if (k in filter_props.keys() and k not in exclude_props)\n            }\n\n        elif filter_props:\n            filtered_props = {\n                k: v for k, v in props.items() if k in filter_props.keys()\n            }\n\n        elif exclude_props:\n            filtered_props = {\n                k: v for k, v in props.items() if k not in exclude_props\n            }\n\n        else:\n            return props\n\n        missing_props = [\n            k for k in filter_props.keys() if k not in filtered_props.keys()\n        ]\n        # add missing properties with default values\n        for k in missing_props:\n            filtered_props[k] = None\n\n        return filtered_props\n\n    def translate_edges(\n        self,\n        edge_tuples: Iterable,\n    ) -&gt; Generator[Union[BioCypherEdge, BioCypherRelAsNode], None, None]:\n        \"\"\"\n        Translates input edge representation to a representation that\n        conforms to the schema of the given BioCypher graph. For now\n        requires explicit statement of edge type on pass.\n\n        Args:\n\n            edge_tuples (list of tuples):\n\n                collection of tuples representing source and target of\n                an interaction via their unique ids as well as the type\n                of interaction in the original database notation, which\n                is translated to BioCypher notation using the `leaves`.\n                Can optionally possess its own ID.\n        \"\"\"\n\n        self._log_begin_translate(edge_tuples, \"edges\")\n\n        # legacy: deal with 4-tuples (no edge id)\n        # TODO remove for performance reasons once safe\n        edge_tuples = peekable(edge_tuples)\n        if len(edge_tuples.peek()) == 4:\n            edge_tuples = [\n                (None, src, tar, typ, props)\n                for src, tar, typ, props in edge_tuples\n            ]\n\n        for _id, _src, _tar, _type, _props in edge_tuples:\n            # check for strict mode requirements\n            if self.strict_mode:\n                if not \"source\" in _props:\n                    raise ValueError(\n                        f\"Edge {_id if _id else (_src, _tar)} does not have a `source` property.\",\n                        \" This is required in strict mode.\",\n                    )\n                if not \"licence\" in _props:\n                    raise ValueError(\n                        f\"Edge {_id if _id else (_src, _tar)} does not have a `licence` property.\",\n                        \" This is required in strict mode.\",\n                    )\n\n            # match the input label (_type) to\n            # a Biolink label from schema_config\n            bl_type = self._get_ontology_mapping(_type)\n\n            if bl_type:\n                # filter properties for those specified in schema_config if any\n                _filtered_props = self._filter_props(bl_type, _props)\n\n                rep = self.ontology.mapping.extended_schema[bl_type][\n                    \"represented_as\"\n                ]\n\n                if rep == \"node\":\n                    if _id:\n                        # if it brings its own ID, use it\n                        node_id = _id\n\n                    else:\n                        # source target concat\n                        node_id = (\n                            str(_src)\n                            + \"_\"\n                            + str(_tar)\n                            + \"_\"\n                            + \"_\".join(str(v) for v in _filtered_props.values())\n                        )\n\n                    n = BioCypherNode(\n                        node_id=node_id,\n                        node_label=bl_type,\n                        properties=_filtered_props,\n                    )\n\n                    # directionality check TODO generalise to account for\n                    # different descriptions of directionality or find a\n                    # more consistent solution for indicating directionality\n                    if _filtered_props.get(\"directed\") == True:\n                        l1 = \"IS_SOURCE_OF\"\n                        l2 = \"IS_TARGET_OF\"\n\n                    elif _filtered_props.get(\n                        \"src_role\",\n                    ) and _filtered_props.get(\"tar_role\"):\n                        l1 = _filtered_props.get(\"src_role\")\n                        l2 = _filtered_props.get(\"tar_role\")\n\n                    else:\n                        l1 = l2 = \"IS_PART_OF\"\n\n                    e_s = BioCypherEdge(\n                        source_id=_src,\n                        target_id=node_id,\n                        relationship_label=l1,\n                        # additional here\n                    )\n\n                    e_t = BioCypherEdge(\n                        source_id=_tar,\n                        target_id=node_id,\n                        relationship_label=l2,\n                        # additional here\n                    )\n\n                    yield BioCypherRelAsNode(n, e_s, e_t)\n\n                else:\n                    edge_label = self.ontology.mapping.extended_schema[\n                        bl_type\n                    ].get(\"label_as_edge\")\n\n                    if edge_label is None:\n                        edge_label = bl_type\n\n                    yield BioCypherEdge(\n                        relationship_id=_id,\n                        source_id=_src,\n                        target_id=_tar,\n                        relationship_label=edge_label,\n                        properties=_filtered_props,\n                    )\n\n            else:\n                self._record_no_type(_type, (_src, _tar))\n\n        self._log_finish_translate(\"edges\")\n\n    def _record_no_type(self, _type: Any, what: Any) -&gt; None:\n        \"\"\"\n        Records the type of a node or edge that is not represented in the\n        schema_config.\n        \"\"\"\n\n        logger.debug(f\"No ontology type defined for `{_type}`: {what}\")\n\n        if self.notype.get(_type, None):\n            self.notype[_type] += 1\n\n        else:\n            self.notype[_type] = 1\n\n    def get_missing_biolink_types(self) -&gt; dict:\n        \"\"\"\n        Returns a dictionary of types that were not represented in the\n        schema_config.\n        \"\"\"\n\n        return self.notype\n\n    @staticmethod\n    def _log_begin_translate(_input: Iterable, what: str):\n        n = f\"{len(_input)} \" if hasattr(_input, \"__len__\") else \"\"\n\n        logger.debug(f\"Translating {n}{what} to BioCypher\")\n\n    @staticmethod\n    def _log_finish_translate(what: str):\n        logger.debug(f\"Finished translating {what} to BioCypher.\")\n\n    def _update_ontology_types(self):\n        \"\"\"\n        Creates a dictionary to translate from input labels to ontology labels.\n\n        If multiple input labels, creates mapping for each.\n        \"\"\"\n\n        self._ontology_mapping = {}\n\n        for key, value in self.ontology.mapping.extended_schema.items():\n            labels = value.get(\"input_label\") or value.get(\"label_in_input\")\n\n            if isinstance(labels, str):\n                self._ontology_mapping[labels] = key\n\n            elif isinstance(labels, list):\n                for label in labels:\n                    self._ontology_mapping[label] = key\n\n            if value.get(\"label_as_edge\"):\n                self._add_translation_mappings(labels, value[\"label_as_edge\"])\n\n            else:\n                self._add_translation_mappings(labels, key)\n\n    def _get_ontology_mapping(self, label: str) -&gt; Optional[str]:\n        \"\"\"\n        For each given input type (\"input_label\" or \"label_in_input\"), find the\n        corresponding ontology class in the leaves dictionary (from the\n        `schema_config.yam`).\n\n        Args:\n            label:\n                The input type to find (`input_label` or `label_in_input` in\n                `schema_config.yaml`).\n        \"\"\"\n\n        # commented out until behaviour of _update_bl_types is fixed\n        return self._ontology_mapping.get(label, None)\n\n    def translate_term(self, term):\n        \"\"\"\n        Translate a single term.\n        \"\"\"\n\n        return self.mappings.get(term, None)\n\n    def reverse_translate_term(self, term):\n        \"\"\"\n        Reverse translate a single term.\n        \"\"\"\n\n        return self.reverse_mappings.get(term, None)\n\n    def translate(self, query):\n        \"\"\"\n        Translate a cypher query. Only translates labels as of now.\n        \"\"\"\n        for key in self.mappings:\n            query = query.replace(\":\" + key, \":\" + self.mappings[key])\n        return query\n\n    def reverse_translate(self, query):\n        \"\"\"\n        Reverse translate a cypher query. Only translates labels as of\n        now.\n        \"\"\"\n        for key in self.reverse_mappings:\n            a = \":\" + key + \")\"\n            b = \":\" + key + \"]\"\n            # TODO this conditional probably does not cover all cases\n            if a in query or b in query:\n                if isinstance(self.reverse_mappings[key], list):\n                    raise NotImplementedError(\n                        \"Reverse translation of multiple inputs not \"\n                        \"implemented yet. Many-to-one mappings are \"\n                        \"not reversible. \"\n                        f\"({key} -&gt; {self.reverse_mappings[key]})\",\n                    )\n                else:\n                    query = query.replace(\n                        a,\n                        \":\" + self.reverse_mappings[key] + \")\",\n                    ).replace(b, \":\" + self.reverse_mappings[key] + \"]\")\n        return query\n\n    def _add_translation_mappings(self, original_name, biocypher_name):\n        \"\"\"\n        Add translation mappings for a label and name. We use here the\n        PascalCase version of the BioCypher name, since sentence case is\n        not useful for Cypher queries.\n        \"\"\"\n        if isinstance(original_name, list):\n            for on in original_name:\n                self.mappings[on] = self.name_sentence_to_pascal(\n                    biocypher_name,\n                )\n        else:\n            self.mappings[original_name] = self.name_sentence_to_pascal(\n                biocypher_name,\n            )\n\n        if isinstance(biocypher_name, list):\n            for bn in biocypher_name:\n                self.reverse_mappings[\n                    self.name_sentence_to_pascal(\n                        bn,\n                    )\n                ] = original_name\n        else:\n            self.reverse_mappings[\n                self.name_sentence_to_pascal(\n                    biocypher_name,\n                )\n            ] = original_name\n\n    @staticmethod\n    def name_sentence_to_pascal(name: str) -&gt; str:\n        \"\"\"\n        Converts a name in sentence case to pascal case.\n        \"\"\"\n        # split on dots if dot is present\n        if \".\" in name:\n            return \".\".join(\n                [_misc.sentencecase_to_pascalcase(n) for n in name.split(\".\")],\n            )\n        else:\n            return _misc.sentencecase_to_pascalcase(name)\n</code></pre>"},{"location":"reference/source/#biocypher._translate.Translator.__init__","title":"<code>__init__(ontology, strict_mode=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>leaves</code> <p>Dictionary detailing the leaves of the hierarchy tree representing the structure of the graph; the leaves are the entities that will be direct components of the graph, while the intermediary nodes are additional labels for filtering purposes.</p> required <code>strict_mode</code> <code>bool</code> <p>If True, the translator will raise an error if input data do not carry source, licence, and version information.</p> <code>False</code> Source code in <code>biocypher/_translate.py</code> <pre><code>def __init__(self, ontology: \"Ontology\", strict_mode: bool = False):\n    \"\"\"\n    Args:\n        leaves:\n            Dictionary detailing the leaves of the hierarchy\n            tree representing the structure of the graph; the leaves are\n            the entities that will be direct components of the graph,\n            while the intermediary nodes are additional labels for\n            filtering purposes.\n        strict_mode:\n            If True, the translator will raise an error if input data do not\n            carry source, licence, and version information.\n    \"\"\"\n\n    self.ontology = ontology\n    self.strict_mode = strict_mode\n\n    # record nodes without biolink type configured in schema_config.yaml\n    self.notype = {}\n\n    # mapping functionality for translating terms and queries\n    self.mappings = {}\n    self.reverse_mappings = {}\n\n    self._update_ontology_types()\n</code></pre>"},{"location":"reference/source/#biocypher._translate.Translator._add_translation_mappings","title":"<code>_add_translation_mappings(original_name, biocypher_name)</code>","text":"<p>Add translation mappings for a label and name. We use here the PascalCase version of the BioCypher name, since sentence case is not useful for Cypher queries.</p> Source code in <code>biocypher/_translate.py</code> <pre><code>def _add_translation_mappings(self, original_name, biocypher_name):\n    \"\"\"\n    Add translation mappings for a label and name. We use here the\n    PascalCase version of the BioCypher name, since sentence case is\n    not useful for Cypher queries.\n    \"\"\"\n    if isinstance(original_name, list):\n        for on in original_name:\n            self.mappings[on] = self.name_sentence_to_pascal(\n                biocypher_name,\n            )\n    else:\n        self.mappings[original_name] = self.name_sentence_to_pascal(\n            biocypher_name,\n        )\n\n    if isinstance(biocypher_name, list):\n        for bn in biocypher_name:\n            self.reverse_mappings[\n                self.name_sentence_to_pascal(\n                    bn,\n                )\n            ] = original_name\n    else:\n        self.reverse_mappings[\n            self.name_sentence_to_pascal(\n                biocypher_name,\n            )\n        ] = original_name\n</code></pre>"},{"location":"reference/source/#biocypher._translate.Translator._filter_props","title":"<code>_filter_props(bl_type, props)</code>","text":"<p>Filters properties for those specified in schema_config if any.</p> Source code in <code>biocypher/_translate.py</code> <pre><code>def _filter_props(self, bl_type: str, props: dict) -&gt; dict:\n    \"\"\"\n    Filters properties for those specified in schema_config if any.\n    \"\"\"\n\n    filter_props = self.ontology.mapping.extended_schema[bl_type].get(\n        \"properties\", {}\n    )\n\n    # strict mode: add required properties (only if there is a whitelist)\n    if self.strict_mode and filter_props:\n        filter_props.update(\n            {\"source\": \"str\", \"licence\": \"str\", \"version\": \"str\"},\n        )\n\n    exclude_props = self.ontology.mapping.extended_schema[bl_type].get(\n        \"exclude_properties\", []\n    )\n\n    if isinstance(exclude_props, str):\n        exclude_props = [exclude_props]\n\n    if filter_props and exclude_props:\n        filtered_props = {\n            k: v\n            for k, v in props.items()\n            if (k in filter_props.keys() and k not in exclude_props)\n        }\n\n    elif filter_props:\n        filtered_props = {\n            k: v for k, v in props.items() if k in filter_props.keys()\n        }\n\n    elif exclude_props:\n        filtered_props = {\n            k: v for k, v in props.items() if k not in exclude_props\n        }\n\n    else:\n        return props\n\n    missing_props = [\n        k for k in filter_props.keys() if k not in filtered_props.keys()\n    ]\n    # add missing properties with default values\n    for k in missing_props:\n        filtered_props[k] = None\n\n    return filtered_props\n</code></pre>"},{"location":"reference/source/#biocypher._translate.Translator._get_ontology_mapping","title":"<code>_get_ontology_mapping(label)</code>","text":"<p>For each given input type (\"input_label\" or \"label_in_input\"), find the corresponding ontology class in the leaves dictionary (from the <code>schema_config.yam</code>).</p> <p>Parameters:</p> Name Type Description Default <code>label</code> <code>str</code> <p>The input type to find (<code>input_label</code> or <code>label_in_input</code> in <code>schema_config.yaml</code>).</p> required Source code in <code>biocypher/_translate.py</code> <pre><code>def _get_ontology_mapping(self, label: str) -&gt; Optional[str]:\n    \"\"\"\n    For each given input type (\"input_label\" or \"label_in_input\"), find the\n    corresponding ontology class in the leaves dictionary (from the\n    `schema_config.yam`).\n\n    Args:\n        label:\n            The input type to find (`input_label` or `label_in_input` in\n            `schema_config.yaml`).\n    \"\"\"\n\n    # commented out until behaviour of _update_bl_types is fixed\n    return self._ontology_mapping.get(label, None)\n</code></pre>"},{"location":"reference/source/#biocypher._translate.Translator._get_preferred_id","title":"<code>_get_preferred_id(_bl_type)</code>","text":"<p>Returns the preferred id for the given Biolink type.</p> Source code in <code>biocypher/_translate.py</code> <pre><code>def _get_preferred_id(self, _bl_type: str) -&gt; str:\n    \"\"\"\n    Returns the preferred id for the given Biolink type.\n    \"\"\"\n\n    return (\n        self.ontology.mapping.extended_schema[_bl_type][\"preferred_id\"]\n        if \"preferred_id\"\n        in self.ontology.mapping.extended_schema.get(_bl_type, {})\n        else \"id\"\n    )\n</code></pre>"},{"location":"reference/source/#biocypher._translate.Translator._record_no_type","title":"<code>_record_no_type(_type, what)</code>","text":"<p>Records the type of a node or edge that is not represented in the schema_config.</p> Source code in <code>biocypher/_translate.py</code> <pre><code>def _record_no_type(self, _type: Any, what: Any) -&gt; None:\n    \"\"\"\n    Records the type of a node or edge that is not represented in the\n    schema_config.\n    \"\"\"\n\n    logger.debug(f\"No ontology type defined for `{_type}`: {what}\")\n\n    if self.notype.get(_type, None):\n        self.notype[_type] += 1\n\n    else:\n        self.notype[_type] = 1\n</code></pre>"},{"location":"reference/source/#biocypher._translate.Translator._update_ontology_types","title":"<code>_update_ontology_types()</code>","text":"<p>Creates a dictionary to translate from input labels to ontology labels.</p> <p>If multiple input labels, creates mapping for each.</p> Source code in <code>biocypher/_translate.py</code> <pre><code>def _update_ontology_types(self):\n    \"\"\"\n    Creates a dictionary to translate from input labels to ontology labels.\n\n    If multiple input labels, creates mapping for each.\n    \"\"\"\n\n    self._ontology_mapping = {}\n\n    for key, value in self.ontology.mapping.extended_schema.items():\n        labels = value.get(\"input_label\") or value.get(\"label_in_input\")\n\n        if isinstance(labels, str):\n            self._ontology_mapping[labels] = key\n\n        elif isinstance(labels, list):\n            for label in labels:\n                self._ontology_mapping[label] = key\n\n        if value.get(\"label_as_edge\"):\n            self._add_translation_mappings(labels, value[\"label_as_edge\"])\n\n        else:\n            self._add_translation_mappings(labels, key)\n</code></pre>"},{"location":"reference/source/#biocypher._translate.Translator.get_missing_biolink_types","title":"<code>get_missing_biolink_types()</code>","text":"<p>Returns a dictionary of types that were not represented in the schema_config.</p> Source code in <code>biocypher/_translate.py</code> <pre><code>def get_missing_biolink_types(self) -&gt; dict:\n    \"\"\"\n    Returns a dictionary of types that were not represented in the\n    schema_config.\n    \"\"\"\n\n    return self.notype\n</code></pre>"},{"location":"reference/source/#biocypher._translate.Translator.name_sentence_to_pascal","title":"<code>name_sentence_to_pascal(name)</code>  <code>staticmethod</code>","text":"<p>Converts a name in sentence case to pascal case.</p> Source code in <code>biocypher/_translate.py</code> <pre><code>@staticmethod\ndef name_sentence_to_pascal(name: str) -&gt; str:\n    \"\"\"\n    Converts a name in sentence case to pascal case.\n    \"\"\"\n    # split on dots if dot is present\n    if \".\" in name:\n        return \".\".join(\n            [_misc.sentencecase_to_pascalcase(n) for n in name.split(\".\")],\n        )\n    else:\n        return _misc.sentencecase_to_pascalcase(name)\n</code></pre>"},{"location":"reference/source/#biocypher._translate.Translator.reverse_translate","title":"<code>reverse_translate(query)</code>","text":"<p>Reverse translate a cypher query. Only translates labels as of now.</p> Source code in <code>biocypher/_translate.py</code> <pre><code>def reverse_translate(self, query):\n    \"\"\"\n    Reverse translate a cypher query. Only translates labels as of\n    now.\n    \"\"\"\n    for key in self.reverse_mappings:\n        a = \":\" + key + \")\"\n        b = \":\" + key + \"]\"\n        # TODO this conditional probably does not cover all cases\n        if a in query or b in query:\n            if isinstance(self.reverse_mappings[key], list):\n                raise NotImplementedError(\n                    \"Reverse translation of multiple inputs not \"\n                    \"implemented yet. Many-to-one mappings are \"\n                    \"not reversible. \"\n                    f\"({key} -&gt; {self.reverse_mappings[key]})\",\n                )\n            else:\n                query = query.replace(\n                    a,\n                    \":\" + self.reverse_mappings[key] + \")\",\n                ).replace(b, \":\" + self.reverse_mappings[key] + \"]\")\n    return query\n</code></pre>"},{"location":"reference/source/#biocypher._translate.Translator.reverse_translate_term","title":"<code>reverse_translate_term(term)</code>","text":"<p>Reverse translate a single term.</p> Source code in <code>biocypher/_translate.py</code> <pre><code>def reverse_translate_term(self, term):\n    \"\"\"\n    Reverse translate a single term.\n    \"\"\"\n\n    return self.reverse_mappings.get(term, None)\n</code></pre>"},{"location":"reference/source/#biocypher._translate.Translator.translate","title":"<code>translate(query)</code>","text":"<p>Translate a cypher query. Only translates labels as of now.</p> Source code in <code>biocypher/_translate.py</code> <pre><code>def translate(self, query):\n    \"\"\"\n    Translate a cypher query. Only translates labels as of now.\n    \"\"\"\n    for key in self.mappings:\n        query = query.replace(\":\" + key, \":\" + self.mappings[key])\n    return query\n</code></pre>"},{"location":"reference/source/#biocypher._translate.Translator.translate_edges","title":"<code>translate_edges(edge_tuples)</code>","text":"<p>Translates input edge representation to a representation that conforms to the schema of the given BioCypher graph. For now requires explicit statement of edge type on pass.</p> <p>Args:</p> <pre><code>edge_tuples (list of tuples):\n\n    collection of tuples representing source and target of\n    an interaction via their unique ids as well as the type\n    of interaction in the original database notation, which\n    is translated to BioCypher notation using the `leaves`.\n    Can optionally possess its own ID.\n</code></pre> Source code in <code>biocypher/_translate.py</code> <pre><code>def translate_edges(\n    self,\n    edge_tuples: Iterable,\n) -&gt; Generator[Union[BioCypherEdge, BioCypherRelAsNode], None, None]:\n    \"\"\"\n    Translates input edge representation to a representation that\n    conforms to the schema of the given BioCypher graph. For now\n    requires explicit statement of edge type on pass.\n\n    Args:\n\n        edge_tuples (list of tuples):\n\n            collection of tuples representing source and target of\n            an interaction via their unique ids as well as the type\n            of interaction in the original database notation, which\n            is translated to BioCypher notation using the `leaves`.\n            Can optionally possess its own ID.\n    \"\"\"\n\n    self._log_begin_translate(edge_tuples, \"edges\")\n\n    # legacy: deal with 4-tuples (no edge id)\n    # TODO remove for performance reasons once safe\n    edge_tuples = peekable(edge_tuples)\n    if len(edge_tuples.peek()) == 4:\n        edge_tuples = [\n            (None, src, tar, typ, props)\n            for src, tar, typ, props in edge_tuples\n        ]\n\n    for _id, _src, _tar, _type, _props in edge_tuples:\n        # check for strict mode requirements\n        if self.strict_mode:\n            if not \"source\" in _props:\n                raise ValueError(\n                    f\"Edge {_id if _id else (_src, _tar)} does not have a `source` property.\",\n                    \" This is required in strict mode.\",\n                )\n            if not \"licence\" in _props:\n                raise ValueError(\n                    f\"Edge {_id if _id else (_src, _tar)} does not have a `licence` property.\",\n                    \" This is required in strict mode.\",\n                )\n\n        # match the input label (_type) to\n        # a Biolink label from schema_config\n        bl_type = self._get_ontology_mapping(_type)\n\n        if bl_type:\n            # filter properties for those specified in schema_config if any\n            _filtered_props = self._filter_props(bl_type, _props)\n\n            rep = self.ontology.mapping.extended_schema[bl_type][\n                \"represented_as\"\n            ]\n\n            if rep == \"node\":\n                if _id:\n                    # if it brings its own ID, use it\n                    node_id = _id\n\n                else:\n                    # source target concat\n                    node_id = (\n                        str(_src)\n                        + \"_\"\n                        + str(_tar)\n                        + \"_\"\n                        + \"_\".join(str(v) for v in _filtered_props.values())\n                    )\n\n                n = BioCypherNode(\n                    node_id=node_id,\n                    node_label=bl_type,\n                    properties=_filtered_props,\n                )\n\n                # directionality check TODO generalise to account for\n                # different descriptions of directionality or find a\n                # more consistent solution for indicating directionality\n                if _filtered_props.get(\"directed\") == True:\n                    l1 = \"IS_SOURCE_OF\"\n                    l2 = \"IS_TARGET_OF\"\n\n                elif _filtered_props.get(\n                    \"src_role\",\n                ) and _filtered_props.get(\"tar_role\"):\n                    l1 = _filtered_props.get(\"src_role\")\n                    l2 = _filtered_props.get(\"tar_role\")\n\n                else:\n                    l1 = l2 = \"IS_PART_OF\"\n\n                e_s = BioCypherEdge(\n                    source_id=_src,\n                    target_id=node_id,\n                    relationship_label=l1,\n                    # additional here\n                )\n\n                e_t = BioCypherEdge(\n                    source_id=_tar,\n                    target_id=node_id,\n                    relationship_label=l2,\n                    # additional here\n                )\n\n                yield BioCypherRelAsNode(n, e_s, e_t)\n\n            else:\n                edge_label = self.ontology.mapping.extended_schema[\n                    bl_type\n                ].get(\"label_as_edge\")\n\n                if edge_label is None:\n                    edge_label = bl_type\n\n                yield BioCypherEdge(\n                    relationship_id=_id,\n                    source_id=_src,\n                    target_id=_tar,\n                    relationship_label=edge_label,\n                    properties=_filtered_props,\n                )\n\n        else:\n            self._record_no_type(_type, (_src, _tar))\n\n    self._log_finish_translate(\"edges\")\n</code></pre>"},{"location":"reference/source/#biocypher._translate.Translator.translate_nodes","title":"<code>translate_nodes(node_tuples)</code>","text":"<p>Translates input node representation to a representation that conforms to the schema of the given BioCypher graph. For now requires explicit statement of node type on pass.</p> <p>Parameters:</p> Name Type Description Default <code>node_tuples</code> <code>list of tuples</code> <p>collection of tuples representing individual nodes by their unique id and a type that is translated from the original database notation to the corresponding BioCypher notation.</p> required Source code in <code>biocypher/_translate.py</code> <pre><code>def translate_nodes(\n    self,\n    node_tuples: Iterable,\n) -&gt; Generator[BioCypherNode, None, None]:\n    \"\"\"\n    Translates input node representation to a representation that\n    conforms to the schema of the given BioCypher graph. For now\n    requires explicit statement of node type on pass.\n\n    Args:\n        node_tuples (list of tuples): collection of tuples\n            representing individual nodes by their unique id and a type\n            that is translated from the original database notation to\n            the corresponding BioCypher notation.\n\n    \"\"\"\n\n    self._log_begin_translate(node_tuples, \"nodes\")\n\n    for _id, _type, _props in node_tuples:\n        # check for strict mode requirements\n        required_props = [\"source\", \"licence\", \"version\"]\n\n        if self.strict_mode:\n            # rename 'license' to 'licence' in _props\n            if _props.get(\"license\"):\n                _props[\"licence\"] = _props.pop(\"license\")\n\n            for prop in required_props:\n                if prop not in _props:\n                    raise ValueError(\n                        f\"Property `{prop}` missing from node {_id}. \"\n                        \"Strict mode is enabled, so this is not allowed.\"\n                    )\n\n        # find the node in leaves that represents ontology node type\n        _ontology_class = self._get_ontology_mapping(_type)\n\n        if _ontology_class:\n            # filter properties for those specified in schema_config if any\n            _filtered_props = self._filter_props(_ontology_class, _props)\n\n            # preferred id\n            _preferred_id = self._get_preferred_id(_ontology_class)\n\n            yield BioCypherNode(\n                node_id=_id,\n                node_label=_ontology_class,\n                preferred_id=_preferred_id,\n                properties=_filtered_props,\n            )\n\n        else:\n            self._record_no_type(_type, _id)\n\n    self._log_finish_translate(\"nodes\")\n</code></pre>"},{"location":"reference/source/#biocypher._translate.Translator.translate_term","title":"<code>translate_term(term)</code>","text":"<p>Translate a single term.</p> Source code in <code>biocypher/_translate.py</code> <pre><code>def translate_term(self, term):\n    \"\"\"\n    Translate a single term.\n    \"\"\"\n\n    return self.mappings.get(term, None)\n</code></pre>"},{"location":"reference/source/#classes","title":"Classes","text":""},{"location":"reference/source/#functions","title":"Functions","text":""},{"location":"reference/source/#other-members","title":"Other Members","text":""},{"location":"tutorials/","title":"Tutorials","text":"<p>The BioCypher tutorials are written as Jupyter notebooks and run directly in Google Colab\u2014a hosted notebook environment that requires no setup. At the top of each tutorial, you'll see a Run in Google Colab button. Click the button to open the notebook and run the code yourself. </p>"},{"location":"tutorials/#list-of-tutorials-current-status","title":"List of Tutorials (current status)","text":"<ol> <li>Getting started</li> <li>Example Notebook: BioCypher and Pandas</li> <li>Tutorial - Basics</li> <li>Tutorial - Handling Ontologies</li> <li>Tutorial - Adapters</li> </ol>"},{"location":"tutorials/#new-structure-future-proposal","title":"New structure (future proposal)","text":""},{"location":"tutorials/#for-beginners","title":"For beginners","text":"<ol> <li>Quickstart</li> <li>Build a BioCypher pipeline from scratch</li> <li>Create a NetworkX graph with a BioCypher pipeline.</li> </ol>"},{"location":"tutorials/#for-advanced-users","title":"For advanced users","text":""},{"location":"tutorials/#biological-activities","title":"Biological Activities","text":"<ul> <li>Build a BioCypher pipeline with CollecTRI dataset</li> </ul>"},{"location":"tutorials/#optimization","title":"Optimization","text":"<ul> <li>Optimizing a BioCypher graph with the Corneto framework</li> </ul>"},{"location":"tutorials/#machine-learning","title":"Machine Learning","text":"<ul> <li>Machine Learning over graphs (DECIDER project)</li> </ul>"},{"location":"tutorials/pandas_tutorial/","title":"Example Notebook: BioCypher and Pandas","text":"Tip: Run the tutorial interactively in      Google Colab.  <p>While BioCypher was designed as a graph-focused framework, due to commonalities in bioinformatics workflows, BioCypher also supports Pandas DataFrames. This allows integration with methods that use tabular data, such as machine learning and statistical analysis, for instance in the scVerse framework.</p> <p>To run this tutorial interactively, you will first need to install perform some setup steps specific to running on Google Colab. You can collapse this section and run the setup steps with one click, as they are not required for the explanation of BioCyper's functionality. You can of course also run the steps one by one, if you want to see what is happening. The real tutorial starts with section 1, \"Adding data\" (do not follow this link on colab, as you will be taken back to the website; please scroll down instead).</p> In\u00a0[\u00a0]: Copied! <pre>!pip install biocypher\n</pre> !pip install biocypher In\u00a0[\u00a0]: Copied! <pre>import yaml\nimport requests\nimport subprocess\n\nschema_path = \"https://raw.githubusercontent.com/biocypher/biocypher/main/tutorial/\"\n</pre> import yaml import requests import subprocess  schema_path = \"https://raw.githubusercontent.com/biocypher/biocypher/main/tutorial/\" In\u00a0[\u00a0]: Copied! <pre>!wget -O data_generator.py \"https://github.com/biocypher/biocypher/raw/main/tutorial/data_generator.py\"\n</pre> !wget -O data_generator.py \"https://github.com/biocypher/biocypher/raw/main/tutorial/data_generator.py\" In\u00a0[\u00a0]: Copied! <pre>owner = \"biocypher\"\nrepo = \"biocypher\"\npath = \"tutorial\"  # The path within the repository (optional, leave empty for the root directory)\ngithub_url = \"https://api.github.com/repos/{owner}/{repo}/contents/{path}\"\n\napi_url = github_url.format(owner=owner, repo=repo, path=path)\nresponse = requests.get(api_url)\n\n# Get list of yaml files from the repo\nfiles = response.json()\nyamls = []\nfor file in files:\n    if file[\"type\"] == \"file\":\n        if file[\"name\"].endswith(\".yaml\"):\n            yamls.append(file[\"name\"])\n\n# wget all yaml files\nfor yaml in yamls:\n    url_path = schema_path + yaml\n    subprocess.run([\"wget\", url_path])\n</pre> owner = \"biocypher\" repo = \"biocypher\" path = \"tutorial\"  # The path within the repository (optional, leave empty for the root directory) github_url = \"https://api.github.com/repos/{owner}/{repo}/contents/{path}\"  api_url = github_url.format(owner=owner, repo=repo, path=path) response = requests.get(api_url)  # Get list of yaml files from the repo files = response.json() yamls = [] for file in files:     if file[\"type\"] == \"file\":         if file[\"name\"].endswith(\".yaml\"):             yamls.append(file[\"name\"])  # wget all yaml files for yaml in yamls:     url_path = schema_path + yaml     subprocess.run([\"wget\", url_path]) <p>Let's also define functions with which we can visualize those</p> In\u00a0[\u00a0]: Copied! <pre># helper function to print yaml files\nimport yaml\ndef print_yaml(file_path):\n    with open(file_path, 'r') as file:\n        yaml_data = yaml.safe_load(file)\n\n    print(\"--------------\")\n    print(yaml.dump(yaml_data, sort_keys=False, indent=4))\n    print(\"--------------\")\n</pre> # helper function to print yaml files import yaml def print_yaml(file_path):     with open(file_path, 'r') as file:         yaml_data = yaml.safe_load(file)      print(\"--------------\")     print(yaml.dump(yaml_data, sort_keys=False, indent=4))     print(\"--------------\") In\u00a0[\u00a0]: Copied! <pre># create a list of proteins to be imported\nfrom data_generator import Protein\nn_proteins = 3\nproteins = [Protein() for _ in range(n_proteins)]\n</pre> # create a list of proteins to be imported from data_generator import Protein n_proteins = 3 proteins = [Protein() for _ in range(n_proteins)] <p>Each protein in our simulated data has a UniProt ID, a label (\"uniprot_protein\"), and a dictionary of properties describing it. This is - purely by coincidence - very close to the input BioCypher expects (for nodes):</p> <ul> <li>a unique identifier</li> <li>an input label (to allow mapping to the ontology, see the second step below)</li> <li>a dictionary of further properties (which can be empty)</li> </ul> <p>These should be presented to BioCypher in the form of a tuple. To achieve this representation, we can use a generator function that iterates through our simulated input data and, for each entity, forms the corresponding tuple. The use of a generator allows for efficient streaming of larger datasets where required.</p> In\u00a0[\u00a0]: Copied! <pre>def node_generator(proteins):\n    for protein in proteins:\n        yield (\n            protein.get_id(),\n            protein.get_label(),\n            protein.get_properties(),\n        )\nentities = node_generator(proteins)\n</pre> def node_generator(proteins):     for protein in proteins:         yield (             protein.get_id(),             protein.get_label(),             protein.get_properties(),         ) entities = node_generator(proteins) <p>The concept of an adapter can become arbitrarily complex and involve programmatic access to databases, API requests, asynchronous queries, context managers, and other complicating factors. However, it always boils down to providing the BioCypher driver with a collection of tuples, one for each entity in the input data. For more info, see the section on Adapters.</p> <p>As descibed above, nodes possess:</p> <ul> <li>a mandatory ID,</li> <li>a mandatory label, and</li> <li>a property dictionary,</li> </ul> <p>while edges possess:</p> <ul> <li>an (optional) ID,</li> <li>two mandatory IDs for source and target,</li> <li>a mandatory label, and</li> <li>a property dictionary.</li> </ul> <p>How these entities are mapped to the ontological hierarchy underlying a BioCypher graph is determined by their mandatory labels, which connect the input data stream to the schema configuration. This we will see in the following section.</p> In\u00a0[\u00a0]: Copied! <pre>print_yaml('01_schema_config.yaml')\n</pre> print_yaml('01_schema_config.yaml') <pre>--------------\nprotein:\n    represented_as: node\n    preferred_id: uniprot\n    input_label: uniprot_protein\n\n--------------\n</pre> <p>The first line (<code>protein</code>) identifies our entity and connects to the ontological backbone; here we define the first class to be represented in the graph. In the configuration YAML, we represent entities\u202f\u2014 similar to the internal representation of Biolink\u202f\u2014 in lower sentence case (e.g., \"small molecule\"). Conversely, for class names, in file names, and property graph labels, we use PascalCase instead (e.g., \"SmallMolecule\") to avoid issues with handling spaces. The transformation is done by BioCypher internally. BioCypher does not strictly enforce the entities allowed in this class definition; in fact, we provide several methods of extending the existing ontological backbone ad hoc by providing custom inheritance or hybridising ontologies. However, every entity should at some point be connected to the underlying ontology, otherwise the multiple hierarchical labels will not be populated. Following this first line are three indented values of the protein class.</p> <p>The second line (<code>represented_as</code>) tells BioCypher in which way each entity should be represented in the graph; the only options are <code>node</code> and <code>edge</code>. Representation as an edge is only possible when source and target IDs are provided in the input data stream. Conversely, relationships can be represented as both <code>node</code> or <code>edge</code>, depending on the desired output. When a relationship should be represented as a node, i.e., \"reified\", BioCypher takes care to create a set of two edges and a node in place of the relationship. This is useful when we want to connect the relationship to other entities in the graph, for example literature references.</p> <p>The third line (<code>preferred_id</code>) informs the uniqueness of represented entities by selecting an ontological namespace around which the definition of uniqueness should revolve. In our example, if a protein has its own uniprot ID, it is understood to be a unique entity. When there are multiple protein isoforms carrying the same uniprot ID, they are understood to be aggregated to result in only one unique entity in the graph. Decisions around uniqueness of graph constituents sometimes require some consideration in task-specific applications. Selection of a namespace also has effects in identifier mapping; in our case, for protein nodes that do not carry a uniprot ID, identifier mapping will attempt to find a uniprot ID given the other identifiers of that node. To account for the broadest possible range of identifier systems while also dealing with parsing of namespace prefixes and validation, we refer to the Bioregistry project namespaces, which should be preferred values for this field.</p> <p>Finally, the fourth line (<code>input_label</code>) connects the input data stream to the configuration; here we indicate which label to expect in the input tuple for each class in the graph. In our case, we expect \"uniprot_protein\" as the label for each protein in the input data stream; all other input entities that do not carry this label are ignored as long as they are not in the schema configuration.</p> In\u00a0[\u00a0]: Copied! <pre>from biocypher import BioCypher\nbc = BioCypher(\n    biocypher_config_path='01_biocypher_config.yaml',\n    schema_config_path='01_schema_config.yaml',\n)\n# Add the entities that we generated above to the graph\nbc.add(entities)\n</pre> from biocypher import BioCypher bc = BioCypher(     biocypher_config_path='01_biocypher_config.yaml',     schema_config_path='01_schema_config.yaml', ) # Add the entities that we generated above to the graph bc.add(entities) <pre>INFO -- Loading ontologies...\nINFO -- Instantiating OntologyAdapter class for https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl.\n</pre> In\u00a0[\u00a0]: Copied! <pre># Print the graph as a dictionary of pandas DataFrame(s) per node label\nbc.to_df()[\"protein\"]\n</pre> # Print the graph as a dictionary of pandas DataFrame(s) per node label bc.to_df()[\"protein\"] Out[\u00a0]: <pre>{'protein':   protein                                           sequence  \\\n 0  F7V4U2  RMFDDRFPVELRICTGSLVIINLGEFAEQHDKQDGSKPSHQPMFAT...   \n 1  K2Y8U3  HWPPSGVSCGVFPECWYRWRDEQWACFGPHIKYNKDNTWSWAQWMH...   \n 2  L1V6V9  QAEPKYKLAQENCRVQIKLPKIVGTCRPHWMTKTYHVLHTCVLWKS...   \n \n            description taxon      id preferred_id  \n 0  i f c m m q e o o s  9606  F7V4U2      uniprot  \n 1  e y p g j t j y r x  9606  K2Y8U3      uniprot  \n 2  a i b t l j e g n j  9606  L1V6V9      uniprot  }</pre> In\u00a0[\u00a0]: Copied! <pre>from data_generator import Protein, EntrezProtein\n</pre> from data_generator import Protein, EntrezProtein In\u00a0[\u00a0]: Copied! <pre>print_yaml('02_schema_config.yaml')\n</pre> print_yaml('02_schema_config.yaml') <pre>--------------\nprotein:\n    represented_as: node\n    preferred_id: uniprot\n    input_label:\n    - uniprot_protein\n    - entrez_protein\n\n--------------\n</pre> In\u00a0[\u00a0]: Copied! <pre># Create a list of proteins to be imported\nproteins = [\n    p for sublist in zip(\n        [Protein() for _ in range(n_proteins)],\n        [EntrezProtein() for _ in range(n_proteins)],\n    ) for p in sublist\n]\n# Create a new BioCypher instance\nbc = BioCypher(\n    biocypher_config_path='02_biocypher_config.yaml',\n    schema_config_path='02_schema_config.yaml',\n)\n# Run the import\nbc.add(node_generator(proteins))\n</pre> # Create a list of proteins to be imported proteins = [     p for sublist in zip(         [Protein() for _ in range(n_proteins)],         [EntrezProtein() for _ in range(n_proteins)],     ) for p in sublist ] # Create a new BioCypher instance bc = BioCypher(     biocypher_config_path='02_biocypher_config.yaml',     schema_config_path='02_schema_config.yaml', ) # Run the import bc.add(node_generator(proteins)) <pre>INFO -- Loading ontologies...\nINFO -- Instantiating OntologyAdapter class for https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl.\n</pre> In\u00a0[\u00a0]: Copied! <pre>bc.to_df()[\"protein\"]\n</pre> bc.to_df()[\"protein\"] Out[\u00a0]: <pre>{'protein':   protein                                           sequence  \\\n 0  K2W3K5  TVKISILFNPLPNQDMNTTTCQAESNYKAIYLYPWCSMDDVWNVEA...   \n 1  186009  FHYHGGMGPFMTYQNFLHWEQMQPMKLFNEPMQFHDWYGTHVNWPG...   \n 2  S6E6D1  CSVQIQIGMSQDSPDSSEGNMDCPPRNIGGYEIVCNVQGKRCYSTD...   \n 3  926766  HKEAELLVKGQIQTPKCLRHNHFYAKLTIVIELNYMVDRYGKDMAR...   \n 4  Z1F6R2  FMVWKDCLCIRMRHMAVPVPQYHCEYFEVILERWEVPCFSVLNRCK...   \n 5  362641  PISDEQEMGSEFCGHCNTGVYQVEMHFFECEDLNPKVQPKWIFTVT...   \n \n            description taxon      id preferred_id  \n 0  e e v h x f t f j l  9606  K2W3K5      uniprot  \n 1  b c q m l d a u u g  9606  186009      uniprot  \n 2  i z t s l x v g j l  9606  S6E6D1      uniprot  \n 3  t n a j d l j a t a  9606  926766      uniprot  \n 4  h d m k q n r e h r  9606  Z1F6R2      uniprot  \n 5  l m x k h m v g p y  9606  362641      uniprot  }</pre> <p>This again creates a single DataFrame, now for both protein types, but now including both input streams (you should note both uniprot &amp; entrez style IDs in the id column). However, we are generating our <code>entrez</code> proteins as having entrez IDs, which could result in problems in querying. Additionally, a strict import mode including regex pattern matching of identifiers will fail at this point due to the difference in pattern of UniProt vs. Entrez IDs. This issue could be resolved by mapping the Entrez IDs to UniProt IDs, but we will instead use the opportunity to demonstrate how to merge data from different sources into the same ontological class using ad hoc subclasses.</p> <p>In the previous section, we saw how to merge data from different sources into the same ontological class. However, we did not resolve the issue of the <code>entrez</code> proteins living in a different namespace than the <code>uniprot</code> proteins, which could result in problems in querying. In proteins, it would probably be more appropriate to solve this problem using identifier mapping, but in other categories, e.g., pathways, this may not be possible because of a lack of one-to-one mapping between different data sources. Thus, if we so desire, we can merge datasets into the same ontological class by creating ad hoc subclasses implicitly through BioCypher, by providing multiple preferred identifiers. In our case, we update our schema configuration as follows:</p> In\u00a0[\u00a0]: Copied! <pre>print_yaml('03_schema_config.yaml')\n</pre> print_yaml('03_schema_config.yaml') <pre>--------------\nprotein:\n    represented_as: node\n    preferred_id:\n    - uniprot\n    - entrez\n    input_label:\n    - uniprot_protein\n    - entrez_protein\n\n--------------\n</pre> <p>This will \"implicitly\" create two subclasses of the <code>protein</code> class, which will inherit the entire hierarchy of the <code>protein</code> class. The two subclasses will be named using a combination of their preferred namespace and the name of the parent class, separated by a dot, i.e., <code>uniprot.protein</code> and <code>entrez.protein</code>. In this manner, they can be identified as proteins regardless of their sources by any queries for the generic <code>protein</code> class, while still carrying information about their namespace and avoiding identifier conflicts.</p>  The only change affected upon the code from the previous section is the referral to the updated schema configuration file.   In the output, we now generate two separate files for the `protein` class, one for each subclass (with names in PascalCase).  <p>Let's create a DataFrame with the same nodes as above, but with a different schema configuration:</p> In\u00a0[\u00a0]: Copied! <pre>bc = BioCypher(\n    biocypher_config_path='03_biocypher_config.yaml',\n    schema_config_path='03_schema_config.yaml',\n)\nbc.add(node_generator(proteins))\nfor name, df in bc.to_df().items():\n    print(name)\n    display(df)\n</pre> bc = BioCypher(     biocypher_config_path='03_biocypher_config.yaml',     schema_config_path='03_schema_config.yaml', ) bc.add(node_generator(proteins)) for name, df in bc.to_df().items():     print(name)     display(df) <pre>INFO -- Loading ontologies...\nINFO -- Instantiating OntologyAdapter class for https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl.\n</pre> Out[\u00a0]: <pre>{'uniprot.protein':   uniprot.protein                                           sequence  \\\n 0          K2W3K5  TVKISILFNPLPNQDMNTTTCQAESNYKAIYLYPWCSMDDVWNVEA...   \n 1          S6E6D1  CSVQIQIGMSQDSPDSSEGNMDCPPRNIGGYEIVCNVQGKRCYSTD...   \n 2          Z1F6R2  FMVWKDCLCIRMRHMAVPVPQYHCEYFEVILERWEVPCFSVLNRCK...   \n \n            description taxon      id preferred_id  \n 0  e e v h x f t f j l  9606  K2W3K5      uniprot  \n 1  i z t s l x v g j l  9606  S6E6D1      uniprot  \n 2  h d m k q n r e h r  9606  Z1F6R2      uniprot  ,\n 'entrez.protein':   entrez.protein                                           sequence  \\\n 0         186009  FHYHGGMGPFMTYQNFLHWEQMQPMKLFNEPMQFHDWYGTHVNWPG...   \n 1         926766  HKEAELLVKGQIQTPKCLRHNHFYAKLTIVIELNYMVDRYGKDMAR...   \n 2         362641  PISDEQEMGSEFCGHCNTGVYQVEMHFFECEDLNPKVQPKWIFTVT...   \n \n            description taxon      id preferred_id  \n 0  b c q m l d a u u g  9606  186009       entrez  \n 1  t n a j d l j a t a  9606  926766       entrez  \n 2  l m x k h m v g p y  9606  362641       entrez  }</pre> <p>Now we see two separate DataFrames, one for each subclass of the <code>protein</code> class.</p> In\u00a0[\u00a0]: Copied! <pre>print_yaml('04_schema_config.yaml')\n</pre> print_yaml('04_schema_config.yaml') <pre>--------------\nprotein:\n    represented_as: node\n    preferred_id:\n    - uniprot\n    - entrez\n    input_label:\n    - uniprot_protein\n    - entrez_protein\n    properties:\n        sequence: str\n        description: str\n        taxon: str\n        mass: int\n\n--------------\n</pre> <p>This will add the <code>mass</code> property to all proteins (in addition to the three we had before); if not encountered, the column will be empty. Implicit subclasses will automatically inherit the property configuration; in this case, both <code>uniprot.protein</code> and <code>entrez.protein</code> will have the <code>mass</code> property, even though the <code>entrez</code> proteins do not have a <code>mass</code> value in the input data.</p>  If we wanted to ignore the mass value for all properties, we could simply remove the `mass` key from the `properties` dictionary.  In\u00a0[\u00a0]: Copied! <pre>from data_generator import EntrezProtein, RandomPropertyProtein\n</pre> from data_generator import EntrezProtein, RandomPropertyProtein In\u00a0[\u00a0]: Copied! <pre># Create a list of proteins to be imported (now with properties)\nproteins = [\n    p for sublist in zip(\n        [RandomPropertyProtein() for _ in range(n_proteins)],\n        [EntrezProtein() for _ in range(n_proteins)],\n    ) for p in sublist\n]\n# New instance, populated, and to DataFrame\nbc = BioCypher(\n    biocypher_config_path='04_biocypher_config.yaml',\n    schema_config_path='04_schema_config.yaml',\n)\nbc.add(node_generator(proteins))\nfor name, df in bc.to_df().items():\n    print(name)\n    display(df)\n</pre> # Create a list of proteins to be imported (now with properties) proteins = [     p for sublist in zip(         [RandomPropertyProtein() for _ in range(n_proteins)],         [EntrezProtein() for _ in range(n_proteins)],     ) for p in sublist ] # New instance, populated, and to DataFrame bc = BioCypher(     biocypher_config_path='04_biocypher_config.yaml',     schema_config_path='04_schema_config.yaml', ) bc.add(node_generator(proteins)) for name, df in bc.to_df().items():     print(name)     display(df) <pre>INFO -- Loading ontologies...\nINFO -- Instantiating OntologyAdapter class for https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl.\n</pre> Out[\u00a0]: <pre>{'uniprot.protein':   uniprot.protein                                           sequence  \\\n 0          S1Z9L5  RHLRGDVMQEDHHTSSERMVYNVLPQDYKVVSCEYWNTQVTALWVI...   \n 1          W9J5F1  IPFSQSAWAQQRIGPKGTKAHGVTQPAPMDIKNLCNLTDLTLILDF...   \n 2          T1J3U0  WFGCCHKQYVSHVIDRQDPQSPSDNPSLVSQLQFFMWGIQIQNGEI...   \n \n            description taxon  mass      id preferred_id  \n 0  u x e o k m a i o s  3899  None  S1Z9L5      uniprot  \n 1  i x k c r b p d d p  8873  None  W9J5F1      uniprot  \n 2  m a w r r u x c w o  1966  9364  T1J3U0      uniprot  ,\n 'entrez.protein':   entrez.protein                                           sequence  \\\n 0         405878  RMTDGFEWQLDFHAFIWCNQAAWQLPLEVHISQGNGGWRMGLYGNM...   \n 1         154167  CGMNYDNGYFSVAYQSYDLWYHQQLKTRGVKPAEKDSDKDLGIDVI...   \n 2         234189  GQWQECIQGFTPQQMCVDCCAETKLANKSYYHSWMTWRLSGLCFNM...   \n \n            description taxon  mass      id preferred_id  \n 0  y c s v s n e c h o  9606  None  405878       entrez  \n 1  i k n c e n r n c d  9606  None  154167       entrez  \n 2  o v w y g h y e v y  9606  None  234189       entrez  }</pre> In\u00a0[\u00a0]: Copied! <pre>from data_generator import RandomPropertyProteinIsoform\n</pre> from data_generator import RandomPropertyProteinIsoform In\u00a0[\u00a0]: Copied! <pre>print_yaml('05_schema_config.yaml')\n</pre> print_yaml('05_schema_config.yaml') <pre>--------------\nprotein:\n    represented_as: node\n    preferred_id:\n    - uniprot\n    - entrez\n    input_label:\n    - uniprot_protein\n    - entrez_protein\n    properties:\n        sequence: str\n        description: str\n        taxon: str\n        mass: int\nprotein isoform:\n    is_a: protein\n    inherit_properties: true\n    represented_as: node\n    preferred_id: uniprot\n    input_label: uniprot_isoform\n\n--------------\n</pre> <p>This allows maintenance of property lists for many classes at once. If the child class has properties already, they will be kept (if they are not present in the parent class) or replaced by the parent class properties (if they are present).</p> <p>Again, apart from adding the protein isoforms to the input stream, the code for this example is identical to the previous one except for the reference to the updated schema configuration.</p> <p>We now create three separate DataFrames, all of which are children of the <code>protein</code> class; two implicit children (<code>uniprot.protein</code> and <code>entrez.protein</code>) and one explicit child (<code>protein isoform</code>).</p> In\u00a0[\u00a0]: Copied! <pre># create a list of proteins to be imported\nproteins = [\n    p for sublist in zip(\n        [RandomPropertyProtein() for _ in range(n_proteins)],\n        [RandomPropertyProteinIsoform() for _ in range(n_proteins)],\n        [EntrezProtein() for _ in range(n_proteins)],\n    ) for p in sublist\n]\n\n# Create BioCypher driver\nbc = BioCypher(\n    biocypher_config_path='05_biocypher_config.yaml',\n    schema_config_path='05_schema_config.yaml',\n)\n# Run the import\nbc.add(node_generator(proteins))\n\nfor name, df in bc.to_df().items():\n    print(name)\n    display(df)\n</pre> # create a list of proteins to be imported proteins = [     p for sublist in zip(         [RandomPropertyProtein() for _ in range(n_proteins)],         [RandomPropertyProteinIsoform() for _ in range(n_proteins)],         [EntrezProtein() for _ in range(n_proteins)],     ) for p in sublist ]  # Create BioCypher driver bc = BioCypher(     biocypher_config_path='05_biocypher_config.yaml',     schema_config_path='05_schema_config.yaml', ) # Run the import bc.add(node_generator(proteins))  for name, df in bc.to_df().items():     print(name)     display(df) <pre>INFO -- Loading ontologies...\nINFO -- Instantiating OntologyAdapter class for https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl.\n</pre> <pre>uniprot.protein\n  uniprot.protein                                           sequence  \\\n0          A9L6G4  SWIVVGQPDSHNKRLVNYHWMRCEHPLRCWRPIYVVRVSFQSQCEQ...   \n1          E4N2H2  PGVMILDNMQHKCSKELSTRQIITNHWICNSAPISWSSGMDRSCLD...   \n2          V4F1T1  DQCHNLCPGSSFQCPENAFGNDWIDHMPQETGLMQYDDPQSGMWFT...   \n\n           description taxon  mass      id preferred_id  \n0  m o k j a f w v w r  4220  None  A9L6G4      uniprot  \n1  n v i r s f m f d w  6339  6481  E4N2H2      uniprot  \n2  w e v v a b o b b u  9176  6510  V4F1T1      uniprot  \nprotein isoform\n  protein isoform                                           sequence  \\\n0          F0N9A4  QDVVLVEGCGDEGWIHMPEKRPGQAYKWCERFRPIPDFTNSIKIAY...   \n1          B1W6O2  SQKHFRRWWTNDCFGQELMSIYYNVKFWDNLIEMTGGPASRVCLGQ...   \n2          G6V5R9  ASAITPFSYEKPHTVTLDATEVFPKMQDAQAIEREIHFSKSTLVYG...   \n\n           description taxon  mass      id preferred_id  \n0  r f e a v a a g w r  8061  None  F0N9A4      uniprot  \n1  a c a v v k v k c w  6786  None  B1W6O2      uniprot  \n2  c k g d a l f r t v  6868  1323  G6V5R9      uniprot  \nentrez.protein\n  entrez.protein                                           sequence  \\\n0          52329  DYRSMAPTFILMKIYPACDAITKRRWSVATVKDGEFIWWSAVKIFP...   \n1         581107  LLVFNMGQLAVAGYGNTMVSAMMCFCCDVKARMGMSWLPKITTMQW...   \n2         270569  MVCSHHELAVAFQTMCPIQGDAATAKANAHRTTDKQNWMVVKWFRT...   \n\n           description taxon  mass      id preferred_id  \n0  q k r b h g t q x x  9606  None   52329       entrez  \n1  h f g z j r b g m w  9606  None  581107       entrez  \n2  s b p v f u t y g v  9606  None  270569       entrez  \n</pre> In\u00a0[\u00a0]: Copied! <pre>print_yaml('06_schema_config_pandas.yaml')\n</pre> print_yaml('06_schema_config_pandas.yaml') <pre>--------------\nprotein:\n    represented_as: node\n    preferred_id:\n    - uniprot\n    - entrez\n    input_label:\n    - uniprot_protein\n    - entrez_protein\n    properties:\n        sequence: str\n        description: str\n        taxon: str\n        mass: int\nprotein isoform:\n    is_a: protein\n    inherit_properties: true\n    represented_as: node\n    preferred_id: uniprot\n    input_label: uniprot_isoform\nprotein protein interaction:\n    is_a: pairwise molecular interaction\n    represented_as: edge\n    preferred_id: intact\n    input_label: interacts_with\n    properties:\n        method: str\n        source: str\n\n--------------\n</pre> <p>Now that we have added <code>protein protein interaction</code> as an edge, we have to simulate some interactions:</p> In\u00a0[\u00a0]: Copied! <pre>from data_generator import InteractionGenerator\n\n# Simulate edges for proteins we defined above\nppi = InteractionGenerator(\n    interactors=[p.get_id() for p in proteins],\n    interaction_probability=0.05,\n).generate_interactions()\n</pre> from data_generator import InteractionGenerator  # Simulate edges for proteins we defined above ppi = InteractionGenerator(     interactors=[p.get_id() for p in proteins],     interaction_probability=0.05, ).generate_interactions() In\u00a0[\u00a0]: Copied! <pre># naturally interactions/edges contain information about the interacting source and target nodes\n# let's look at the first one in the list\ninteraction = ppi[0]\nf\"{interaction.get_source_id()} {interaction.label} {interaction.get_target_id()}\"\n</pre> # naturally interactions/edges contain information about the interacting source and target nodes # let's look at the first one in the list interaction = ppi[0] f\"{interaction.get_source_id()} {interaction.label} {interaction.get_target_id()}\" Out[\u00a0]: <pre>'A9L6G4 interacts_with V4F1T1'</pre> In\u00a0[\u00a0]: Copied! <pre># similarly to nodes, it also has a dictionary of properties\ninteraction.get_properties()\n</pre> # similarly to nodes, it also has a dictionary of properties interaction.get_properties() Out[\u00a0]: <pre>{'source': 'signor', 'method': 'u z c x m d c u g s'}</pre> <p>As with nodes, we add first createa a new BioCypher instance, and then populate it with nodes as well as edges:</p> In\u00a0[\u00a0]: Copied! <pre>bc = BioCypher(\n    biocypher_config_path='06_biocypher_config.yaml',\n    schema_config_path='06_schema_config_pandas.yaml',\n)\n</pre> bc = BioCypher(     biocypher_config_path='06_biocypher_config.yaml',     schema_config_path='06_schema_config_pandas.yaml', ) In\u00a0[\u00a0]: Copied! <pre># Extract id, source, target, label, and property dictionary\ndef edge_generator(ppi):\n    for interaction in ppi:\n        yield (\n            interaction.get_id(),\n            interaction.get_source_id(),\n            interaction.get_target_id(),\n            interaction.get_label(),\n            interaction.get_properties(),\n        )\n\nbc.add(node_generator(proteins))\nbc.add(edge_generator(ppi))\n</pre> # Extract id, source, target, label, and property dictionary def edge_generator(ppi):     for interaction in ppi:         yield (             interaction.get_id(),             interaction.get_source_id(),             interaction.get_target_id(),             interaction.get_label(),             interaction.get_properties(),         )  bc.add(node_generator(proteins)) bc.add(edge_generator(ppi))  <pre>INFO -- Loading ontologies...\nINFO -- Instantiating OntologyAdapter class for https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl.\n</pre> <p>Let's look at the interaction DataFrame:</p> In\u00a0[\u00a0]: Copied! <pre>bc.to_df()[\"protein protein interaction\"]\n</pre> bc.to_df()[\"protein protein interaction\"] Out[\u00a0]: protein protein interaction _from _to source method 0 intact703256 A9L6G4 V4F1T1 signor u z c x m d c u g s 1 None E4N2H2 F0N9A4 intact None <p>Finally, it is worth noting that BioCypher relies on ontologies, which are machine readable representations of domains of knowledge that we use to ground the contents of our knowledge graphs. While details about ontologies are out of scope for this tutorial, and are described in detail in the BioCypher documentation, we can still have a glimpse at the ontology that we used implicitly in this tutorial:</p> In\u00a0[\u00a0]: Copied! <pre>bc.show_ontology_structure()\n</pre> bc.show_ontology_structure() <pre>Showing ontology structure based on https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl\nentity\n\u251c\u2500\u2500 association\n\u2502   \u2514\u2500\u2500 gene to gene association\n\u2502       \u2514\u2500\u2500 pairwise gene to gene interaction\n\u2502           \u2514\u2500\u2500 pairwise molecular interaction\n\u2502               \u2514\u2500\u2500 protein protein interaction\n\u2514\u2500\u2500 named thing\n    \u2514\u2500\u2500 biological entity\n        \u2514\u2500\u2500 polypeptide\n            \u2514\u2500\u2500 protein\n                \u251c\u2500\u2500 entrez.protein\n                \u251c\u2500\u2500 protein isoform\n                \u2514\u2500\u2500 uniprot.protein\n</pre> Out[\u00a0]: <pre>&lt;treelib.tree.Tree at 0x7f7327b3a880&gt;</pre>"},{"location":"tutorials/pandas_tutorial/#example-notebook-biocypher-and-pandas","title":"Example Notebook: BioCypher and Pandas\u00b6","text":""},{"location":"tutorials/pandas_tutorial/#introduction","title":"Introduction\u00b6","text":"<p>The main purpose of BioCypher is to facilitate the pre-processing of biomedical data, and thus save development time in the maintenance of curated knowledge graphs, while allowing simple and efficient creation of task-specific lightweight knowledge graphs in a user-friendly and biology-centric fashion.</p> <p>We are going to use a toy example to familiarise the user with the basic functionality of BioCypher. One central task of BioCypher is the harmonisation of dissimilar datasets describing the same entities. Thus, in this example, the input data - which in the real-world use case could come from any type of interface - are represented by simulated data containing some examples of differently formatted biomedical entities such as proteins and their interactions.</p> <p>There are two other versions of this tutorial, which only differ in the output format. The first uses a CSV output format to write files suitable for Neo4j admin import, and the second creates an in-memory collection of Pandas dataframes. You can find the former in the tutorial directory of the BioCypher repository. This tutorial simply takes the latter, in-memory approach to a Jupyter notebook.</p>"},{"location":"tutorials/pandas_tutorial/#setup","title":"Setup\u00b6","text":""},{"location":"tutorials/pandas_tutorial/#tutorial-files","title":"Tutorial files\u00b6","text":"<p>In the <code>biocypher</code> root directory, you will find a <code>tutorial</code> directory with the files for this tutorial. The <code>data_generator.py</code> file contains the simulated data generation code, and the other files, specifically the <code>.yaml</code> files, are named according to the tutorial step they are used in.</p> <p>Let's download these:</p>"},{"location":"tutorials/pandas_tutorial/#configuration","title":"Configuration\u00b6","text":"<p>BioCypher is configured using a YAML file; it comes with a default (which you can see in the Configuration section). You can use it, for instance, to select an output format, the output directory, separators, logging level, and other options. For this tutorial, we will use a dedicated configuration file for each of the steps. The configuration files are located in the <code>tutorial</code> directory, and are called using the <code>biocypher_config_path</code> argument at instantiation of the BioCypher interface. For more information, see also the Quickstart Configuration section.</p>"},{"location":"tutorials/pandas_tutorial/#section-1-adding-data","title":"Section 1: Adding data\u00b6","text":""},{"location":"tutorials/pandas_tutorial/#input-data-stream-adapter","title":"Input data stream (\"adapter\")\u00b6","text":"<p>The basic operation of adding data to the knowledge graph requires two components: an input stream of data (which we call adapter) and a configuration for the resulting desired output (the schema configuration). The former will be simulated by calling the <code>Protein</code> class of our data generator 10 times.</p>"},{"location":"tutorials/pandas_tutorial/#schema-configuration","title":"Schema configuration\u00b6","text":"<p>How each BioCypher graph is structured is determined by the schema configuration YAML file that is given to the BioCypher interface. This also serves to ground the entities of the graph in the biomedical realm by using an ontological hierarchy. In this tutorial, we refer to the Biolink model as the general backbone of our ontological hierarchy. The basic premise of the schema configuration YAML file is that each component of the desired knowledge graph output should be configured here; if (and only if) an entity is represented in the schema configuration and is present in the input data stream, will it be part of our knowledge graph.</p> <p>In our case, since we only import proteins, we only require few lines of configuration:</p>"},{"location":"tutorials/pandas_tutorial/#creating-the-graph-using-the-biocypher-interface","title":"Creating the graph (using the BioCypher interface)\u00b6","text":"<p>All that remains to be done now is to instantiate the BioCypher interface (as the main means of communicating with BioCypher) and call the function to create the graph.</p>"},{"location":"tutorials/pandas_tutorial/#section-2-merging-data","title":"Section 2: Merging data\u00b6","text":""},{"location":"tutorials/pandas_tutorial/#plain-merge","title":"Plain merge\u00b6","text":"<p>Using the workflow described above with minor changes, we can merge data from different input streams. If we do not want to introduce additional ontological subcategories, we can simply add the new input stream to the existing one and add the new label to the schema configuration (the new label being <code>entrez_protein</code>). In this case, we would add the following to the schema configuration:</p>"},{"location":"tutorials/pandas_tutorial/#ad-hoc-subclassing","title":"Ad hoc subclassing\u00b6","text":""},{"location":"tutorials/pandas_tutorial/#section-3-handling-properties","title":"Section 3: Handling properties\u00b6","text":"<p>While ID and label are mandatory components of our knowledge graph, properties are optional and can include different types of information on the entities. In source data, properties are represented in arbitrary ways, and designations rarely overlap even for the most trivial of cases (spelling differences, formatting, etc). Additionally, some data sources contain a large wealth of information about entities, most of which may not be needed for the given task. Thus, it is often desirable to filter out properties that are not needed to save time, disk space, and memory.</p> <p>Maintaining consistent properties per entity type is particularly important when using the admin import feature of Neo4j, which requires consistency between the header and data files. Properties that are introduced into only some of the rows will lead to column misalignment and import failure. In \"online mode\", this is not an issue.</p> <p>We will take a look at how to handle property selection in BioCypher in a way that is flexible and easy to maintain.</p>"},{"location":"tutorials/pandas_tutorial/#designated-properties","title":"Designated properties\u00b6","text":"<p>The simplest and most straightforward way to ensure that properties are consistent for each entity type is to designate them explicitly in the schema configuration. This is done by adding a <code>properties</code> key to the entity type configuration. The value of this key is another dictionary, where in the standard case the keys are the names of the properties that the entity type should possess, and the values give the type of the property. Possible values are:</p> <ul> <li><p><code>str</code> (or <code>string</code>),</p> </li> <li><p><code>int</code> (or <code>integer</code>, <code>long</code>),</p> </li> <li><p><code>float</code> (or <code>double</code>, <code>dbl</code>),</p> </li> <li><p><code>bool</code> (or <code>boolean</code>),</p> </li> <li><p>arrays of any of these types (indicated by square brackets, e.g. <code>string[]</code>).</p> </li> </ul> <p>In the case of properties that are not present in (some of) the source data, BioCypher will add them to the output with a default value of <code>None</code>. Additional properties in the input that are not represented in these designated property names will be ignored. Let's imagine that some, but not all, of our protein nodes have a <code>mass</code> value. If we want to include the mass value on all proteins, we can add the following to our schema configuration:</p>"},{"location":"tutorials/pandas_tutorial/#inheriting-properties","title":"Inheriting properties\u00b6","text":"<p>Sometimes, explicit designation of properties requires a lot of maintenance work, particularly for classes with many properties. In these cases, it may be more convenient to inherit properties from a parent class. This is done by adding a <code>properties</code> key to a suitable parent class configuration, and then defining inheritance via the <code>is_a</code> key in the child class configuration and setting the <code>inherit_properties</code> key to <code>true</code>.</p> <p>Let's say we have an additional <code>protein isoform</code> class, which can reasonably inherit from <code>protein</code> and should carry the same properties as the parent. We can add the following to our schema configuration:</p>"},{"location":"tutorials/pandas_tutorial/#section-4-handling-relationships","title":"Section 4: Handling relationships\u00b6","text":"<p>Naturally, we do not only want nodes in our knowledge graph, but also edges. In BioCypher, the configuration of relationships is very similar to that of nodes, with some key differences. First the similarities: the top-level class configuration of edges is the same; class names refer to ontological classes or are an extension thereof. Similarly, the <code>is_a</code> key is used to define inheritance, and the <code>inherit_properties</code> key is used to inherit properties from a parent class. Relationships also possess a <code>preferred_id</code> key, an <code>input_label</code> key, and a <code>properties</code> key, which work in the same way as for nodes.</p> <p>Relationships also have a <code>represented_as</code> key, which in this case can be either <code>node</code> or <code>edge</code>. The <code>node</code> option is used to \"reify\" the relationship in order to be able to connect it to other nodes in the graph. In addition to the configuration of nodes, relationships also have fields for the <code>source</code> and <code>target</code> node types, which refer to the ontological classes of the respective nodes, and are currently optional.</p> <p>To add protein-protein interactions to our graph, we can modify the schema configuration above to the following:</p>"},{"location":"tutorials/pandas_tutorial_refactored/","title":"Example Notebook: BioCypher and Pandas","text":"Tip: Run the tutorial interactively in      Google Colab.  <p>While BioCypher was designed as a graph-focused framework, due to commonalities in bioinformatics workflows, BioCypher also supports Pandas DataFrames. This allows integration with methods that use tabular data, such as machine learning and statistical analysis, for instance in the scVerse framework.</p> <p>To run this tutorial interactively, you will first need to install perform some setup steps specific to running on Google Colab. You can collapse this section and run the setup steps with one click, as they are not required for the explanation of BioCyper's functionality. You can of course also run the steps one by one, if you want to see what is happening. The real tutorial starts with section 1, \"Adding data\" (do not follow this link on colab, as you will be taken back to the website; please scroll down instead).</p> In\u00a0[\u00a0]: Copied! <pre>!pip install biocypher\n</pre> !pip install biocypher In\u00a0[\u00a0]: Copied! <pre>import yaml\nimport requests\nimport subprocess\n\nschema_path = \"https://raw.githubusercontent.com/biocypher/biocypher/main/tutorial/\"\n</pre> import yaml import requests import subprocess  schema_path = \"https://raw.githubusercontent.com/biocypher/biocypher/main/tutorial/\" In\u00a0[\u00a0]: Copied! <pre>!wget -O data_generator.py \"https://github.com/biocypher/biocypher/raw/main/tutorial/data_generator.py\"\n</pre> !wget -O data_generator.py \"https://github.com/biocypher/biocypher/raw/main/tutorial/data_generator.py\" In\u00a0[\u00a0]: Copied! <pre>owner = \"biocypher\"\nrepo = \"biocypher\"\npath = \"tutorial\"  # The path within the repository (optional, leave empty for the root directory)\ngithub_url = \"https://api.github.com/repos/{owner}/{repo}/contents/{path}\"\n\napi_url = github_url.format(owner=owner, repo=repo, path=path)\nresponse = requests.get(api_url)\n\n# Get list of yaml files from the repo\nfiles = response.json()\nyamls = []\nfor file in files:\n    if file[\"type\"] == \"file\":\n        if file[\"name\"].endswith(\".yaml\"):\n            yamls.append(file[\"name\"])\n\n# wget all yaml files\nfor yaml in yamls:\n    url_path = schema_path + yaml\n    subprocess.run([\"wget\", url_path])\n</pre> owner = \"biocypher\" repo = \"biocypher\" path = \"tutorial\"  # The path within the repository (optional, leave empty for the root directory) github_url = \"https://api.github.com/repos/{owner}/{repo}/contents/{path}\"  api_url = github_url.format(owner=owner, repo=repo, path=path) response = requests.get(api_url)  # Get list of yaml files from the repo files = response.json() yamls = [] for file in files:     if file[\"type\"] == \"file\":         if file[\"name\"].endswith(\".yaml\"):             yamls.append(file[\"name\"])  # wget all yaml files for yaml in yamls:     url_path = schema_path + yaml     subprocess.run([\"wget\", url_path]) <p>Let's also define functions with which we can visualize those</p> In\u00a0[\u00a0]: Copied! <pre># helper function to print yaml files\nimport yaml\ndef print_yaml(file_path):\n    with open(file_path, 'r') as file:\n        yaml_data = yaml.safe_load(file)\n\n    print(\"--------------\")\n    print(yaml.dump(yaml_data, sort_keys=False, indent=4))\n    print(\"--------------\")\n</pre> # helper function to print yaml files import yaml def print_yaml(file_path):     with open(file_path, 'r') as file:         yaml_data = yaml.safe_load(file)      print(\"--------------\")     print(yaml.dump(yaml_data, sort_keys=False, indent=4))     print(\"--------------\") In\u00a0[\u00a0]: Copied! <pre># create a list of proteins to be imported\nfrom data_generator import Protein\nn_proteins = 3\nproteins = [Protein() for _ in range(n_proteins)]\n</pre> # create a list of proteins to be imported from data_generator import Protein n_proteins = 3 proteins = [Protein() for _ in range(n_proteins)] <p>Each protein in our simulated data has a UniProt ID, a label (\"uniprot_protein\"), and a dictionary of properties describing it. This is - purely by coincidence - very close to the input BioCypher expects (for nodes):</p> <ul> <li>a unique identifier</li> <li>an input label (to allow mapping to the ontology, see the second step below)</li> <li>a dictionary of further properties (which can be empty)</li> </ul> <p>These should be presented to BioCypher in the form of a tuple. To achieve this representation, we can use a generator function that iterates through our simulated input data and, for each entity, forms the corresponding tuple. The use of a generator allows for efficient streaming of larger datasets where required.</p> In\u00a0[\u00a0]: Copied! <pre>def node_generator(proteins):\n    for protein in proteins:\n        yield (\n            protein.get_id(),\n            protein.get_label(),\n            protein.get_properties(),\n        )\nentities = node_generator(proteins)\n</pre> def node_generator(proteins):     for protein in proteins:         yield (             protein.get_id(),             protein.get_label(),             protein.get_properties(),         ) entities = node_generator(proteins) <p>The concept of an adapter can become arbitrarily complex and involve programmatic access to databases, API requests, asynchronous queries, context managers, and other complicating factors. However, it always boils down to providing the BioCypher driver with a collection of tuples, one for each entity in the input data. For more info, see the section on Adapters.</p> <p>As descibed above, nodes possess:</p> <ul> <li>a mandatory ID,</li> <li>a mandatory label, and</li> <li>a property dictionary,</li> </ul> <p>while edges possess:</p> <ul> <li>an (optional) ID,</li> <li>two mandatory IDs for source and target,</li> <li>a mandatory label, and</li> <li>a property dictionary.</li> </ul> <p>How these entities are mapped to the ontological hierarchy underlying a BioCypher graph is determined by their mandatory labels, which connect the input data stream to the schema configuration. This we will see in the following section.</p> In\u00a0[\u00a0]: Copied! <pre>print_yaml('01_schema_config.yaml')\n</pre> print_yaml('01_schema_config.yaml') <pre>--------------\nprotein:\n    represented_as: node\n    preferred_id: uniprot\n    input_label: uniprot_protein\n\n--------------\n</pre> <p>The first line (<code>protein</code>) identifies our entity and connects to the ontological backbone; here we define the first class to be represented in the graph. In the configuration YAML, we represent entities\u202f\u2014 similar to the internal representation of Biolink\u202f\u2014 in lower sentence case (e.g., \"small molecule\"). Conversely, for class names, in file names, and property graph labels, we use PascalCase instead (e.g., \"SmallMolecule\") to avoid issues with handling spaces. The transformation is done by BioCypher internally. BioCypher does not strictly enforce the entities allowed in this class definition; in fact, we provide several methods of extending the existing ontological backbone ad hoc by providing custom inheritance or hybridising ontologies. However, every entity should at some point be connected to the underlying ontology, otherwise the multiple hierarchical labels will not be populated. Following this first line are three indented values of the protein class.</p> <p>The second line (<code>represented_as</code>) tells BioCypher in which way each entity should be represented in the graph; the only options are <code>node</code> and <code>edge</code>. Representation as an edge is only possible when source and target IDs are provided in the input data stream. Conversely, relationships can be represented as both <code>node</code> or <code>edge</code>, depending on the desired output. When a relationship should be represented as a node, i.e., \"reified\", BioCypher takes care to create a set of two edges and a node in place of the relationship. This is useful when we want to connect the relationship to other entities in the graph, for example literature references.</p> <p>The third line (<code>preferred_id</code>) informs the uniqueness of represented entities by selecting an ontological namespace around which the definition of uniqueness should revolve. In our example, if a protein has its own uniprot ID, it is understood to be a unique entity. When there are multiple protein isoforms carrying the same uniprot ID, they are understood to be aggregated to result in only one unique entity in the graph. Decisions around uniqueness of graph constituents sometimes require some consideration in task-specific applications. Selection of a namespace also has effects in identifier mapping; in our case, for protein nodes that do not carry a uniprot ID, identifier mapping will attempt to find a uniprot ID given the other identifiers of that node. To account for the broadest possible range of identifier systems while also dealing with parsing of namespace prefixes and validation, we refer to the Bioregistry project namespaces, which should be preferred values for this field.</p> <p>Finally, the fourth line (<code>input_label</code>) connects the input data stream to the configuration; here we indicate which label to expect in the input tuple for each class in the graph. In our case, we expect \"uniprot_protein\" as the label for each protein in the input data stream; all other input entities that do not carry this label are ignored as long as they are not in the schema configuration.</p> In\u00a0[\u00a0]: Copied! <pre>from biocypher import BioCypher\nbc = BioCypher(\n    biocypher_config_path='01_biocypher_config.yaml',\n    schema_config_path='01_schema_config.yaml',\n)\n# Add the entities that we generated above to the graph\nbc.add(entities)\n</pre> from biocypher import BioCypher bc = BioCypher(     biocypher_config_path='01_biocypher_config.yaml',     schema_config_path='01_schema_config.yaml', ) # Add the entities that we generated above to the graph bc.add(entities) <pre>INFO -- Loading ontologies...\nINFO -- Instantiating OntologyAdapter class for https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl.\n</pre> In\u00a0[\u00a0]: Copied! <pre># Print the graph as a dictionary of pandas DataFrame(s) per node label\nbc.to_df()[\"protein\"]\n</pre> # Print the graph as a dictionary of pandas DataFrame(s) per node label bc.to_df()[\"protein\"] Out[\u00a0]: <pre>{'protein':   protein                                           sequence  \\\n 0  F7V4U2  RMFDDRFPVELRICTGSLVIINLGEFAEQHDKQDGSKPSHQPMFAT...   \n 1  K2Y8U3  HWPPSGVSCGVFPECWYRWRDEQWACFGPHIKYNKDNTWSWAQWMH...   \n 2  L1V6V9  QAEPKYKLAQENCRVQIKLPKIVGTCRPHWMTKTYHVLHTCVLWKS...   \n \n            description taxon      id preferred_id  \n 0  i f c m m q e o o s  9606  F7V4U2      uniprot  \n 1  e y p g j t j y r x  9606  K2Y8U3      uniprot  \n 2  a i b t l j e g n j  9606  L1V6V9      uniprot  }</pre> In\u00a0[\u00a0]: Copied! <pre>from data_generator import Protein, EntrezProtein\n</pre> from data_generator import Protein, EntrezProtein In\u00a0[\u00a0]: Copied! <pre>print_yaml('02_schema_config.yaml')\n</pre> print_yaml('02_schema_config.yaml') <pre>--------------\nprotein:\n    represented_as: node\n    preferred_id: uniprot\n    input_label:\n    - uniprot_protein\n    - entrez_protein\n\n--------------\n</pre> In\u00a0[\u00a0]: Copied! <pre># Create a list of proteins to be imported\nproteins = [\n    p for sublist in zip(\n        [Protein() for _ in range(n_proteins)],\n        [EntrezProtein() for _ in range(n_proteins)],\n    ) for p in sublist\n]\n# Create a new BioCypher instance\nbc = BioCypher(\n    biocypher_config_path='02_biocypher_config.yaml',\n    schema_config_path='02_schema_config.yaml',\n)\n# Run the import\nbc.add(node_generator(proteins))\n</pre> # Create a list of proteins to be imported proteins = [     p for sublist in zip(         [Protein() for _ in range(n_proteins)],         [EntrezProtein() for _ in range(n_proteins)],     ) for p in sublist ] # Create a new BioCypher instance bc = BioCypher(     biocypher_config_path='02_biocypher_config.yaml',     schema_config_path='02_schema_config.yaml', ) # Run the import bc.add(node_generator(proteins)) <pre>INFO -- Loading ontologies...\nINFO -- Instantiating OntologyAdapter class for https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl.\n</pre> In\u00a0[\u00a0]: Copied! <pre>bc.to_df()[\"protein\"]\n</pre> bc.to_df()[\"protein\"] Out[\u00a0]: <pre>{'protein':   protein                                           sequence  \\\n 0  K2W3K5  TVKISILFNPLPNQDMNTTTCQAESNYKAIYLYPWCSMDDVWNVEA...   \n 1  186009  FHYHGGMGPFMTYQNFLHWEQMQPMKLFNEPMQFHDWYGTHVNWPG...   \n 2  S6E6D1  CSVQIQIGMSQDSPDSSEGNMDCPPRNIGGYEIVCNVQGKRCYSTD...   \n 3  926766  HKEAELLVKGQIQTPKCLRHNHFYAKLTIVIELNYMVDRYGKDMAR...   \n 4  Z1F6R2  FMVWKDCLCIRMRHMAVPVPQYHCEYFEVILERWEVPCFSVLNRCK...   \n 5  362641  PISDEQEMGSEFCGHCNTGVYQVEMHFFECEDLNPKVQPKWIFTVT...   \n \n            description taxon      id preferred_id  \n 0  e e v h x f t f j l  9606  K2W3K5      uniprot  \n 1  b c q m l d a u u g  9606  186009      uniprot  \n 2  i z t s l x v g j l  9606  S6E6D1      uniprot  \n 3  t n a j d l j a t a  9606  926766      uniprot  \n 4  h d m k q n r e h r  9606  Z1F6R2      uniprot  \n 5  l m x k h m v g p y  9606  362641      uniprot  }</pre> <p>This again creates a single DataFrame, now for both protein types, but now including both input streams (you should note both uniprot &amp; entrez style IDs in the id column). However, we are generating our <code>entrez</code> proteins as having entrez IDs, which could result in problems in querying. Additionally, a strict import mode including regex pattern matching of identifiers will fail at this point due to the difference in pattern of UniProt vs. Entrez IDs. This issue could be resolved by mapping the Entrez IDs to UniProt IDs, but we will instead use the opportunity to demonstrate how to merge data from different sources into the same ontological class using ad hoc subclasses.</p> <p>In the previous section, we saw how to merge data from different sources into the same ontological class. However, we did not resolve the issue of the <code>entrez</code> proteins living in a different namespace than the <code>uniprot</code> proteins, which could result in problems in querying. In proteins, it would probably be more appropriate to solve this problem using identifier mapping, but in other categories, e.g., pathways, this may not be possible because of a lack of one-to-one mapping between different data sources. Thus, if we so desire, we can merge datasets into the same ontological class by creating ad hoc subclasses implicitly through BioCypher, by providing multiple preferred identifiers. In our case, we update our schema configuration as follows:</p> In\u00a0[\u00a0]: Copied! <pre>print_yaml('03_schema_config.yaml')\n</pre> print_yaml('03_schema_config.yaml') <pre>--------------\nprotein:\n    represented_as: node\n    preferred_id:\n    - uniprot\n    - entrez\n    input_label:\n    - uniprot_protein\n    - entrez_protein\n\n--------------\n</pre> <p>This will \"implicitly\" create two subclasses of the <code>protein</code> class, which will inherit the entire hierarchy of the <code>protein</code> class. The two subclasses will be named using a combination of their preferred namespace and the name of the parent class, separated by a dot, i.e., <code>uniprot.protein</code> and <code>entrez.protein</code>. In this manner, they can be identified as proteins regardless of their sources by any queries for the generic <code>protein</code> class, while still carrying information about their namespace and avoiding identifier conflicts.</p>  The only change affected upon the code from the previous section is the referral to the updated schema configuration file.   In the output, we now generate two separate files for the `protein` class, one for each subclass (with names in PascalCase).  <p>Let's create a DataFrame with the same nodes as above, but with a different schema configuration:</p> In\u00a0[\u00a0]: Copied! <pre>bc = BioCypher(\n    biocypher_config_path='03_biocypher_config.yaml',\n    schema_config_path='03_schema_config.yaml',\n)\nbc.add(node_generator(proteins))\nfor name, df in bc.to_df().items():\n    print(name)\n    display(df)\n</pre> bc = BioCypher(     biocypher_config_path='03_biocypher_config.yaml',     schema_config_path='03_schema_config.yaml', ) bc.add(node_generator(proteins)) for name, df in bc.to_df().items():     print(name)     display(df) <pre>INFO -- Loading ontologies...\nINFO -- Instantiating OntologyAdapter class for https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl.\n</pre> Out[\u00a0]: <pre>{'uniprot.protein':   uniprot.protein                                           sequence  \\\n 0          K2W3K5  TVKISILFNPLPNQDMNTTTCQAESNYKAIYLYPWCSMDDVWNVEA...   \n 1          S6E6D1  CSVQIQIGMSQDSPDSSEGNMDCPPRNIGGYEIVCNVQGKRCYSTD...   \n 2          Z1F6R2  FMVWKDCLCIRMRHMAVPVPQYHCEYFEVILERWEVPCFSVLNRCK...   \n \n            description taxon      id preferred_id  \n 0  e e v h x f t f j l  9606  K2W3K5      uniprot  \n 1  i z t s l x v g j l  9606  S6E6D1      uniprot  \n 2  h d m k q n r e h r  9606  Z1F6R2      uniprot  ,\n 'entrez.protein':   entrez.protein                                           sequence  \\\n 0         186009  FHYHGGMGPFMTYQNFLHWEQMQPMKLFNEPMQFHDWYGTHVNWPG...   \n 1         926766  HKEAELLVKGQIQTPKCLRHNHFYAKLTIVIELNYMVDRYGKDMAR...   \n 2         362641  PISDEQEMGSEFCGHCNTGVYQVEMHFFECEDLNPKVQPKWIFTVT...   \n \n            description taxon      id preferred_id  \n 0  b c q m l d a u u g  9606  186009       entrez  \n 1  t n a j d l j a t a  9606  926766       entrez  \n 2  l m x k h m v g p y  9606  362641       entrez  }</pre> <p>Now we see two separate DataFrames, one for each subclass of the <code>protein</code> class.</p> In\u00a0[\u00a0]: Copied! <pre>print_yaml('04_schema_config.yaml')\n</pre> print_yaml('04_schema_config.yaml') <pre>--------------\nprotein:\n    represented_as: node\n    preferred_id:\n    - uniprot\n    - entrez\n    input_label:\n    - uniprot_protein\n    - entrez_protein\n    properties:\n        sequence: str\n        description: str\n        taxon: str\n        mass: int\n\n--------------\n</pre> <p>This will add the <code>mass</code> property to all proteins (in addition to the three we had before); if not encountered, the column will be empty. Implicit subclasses will automatically inherit the property configuration; in this case, both <code>uniprot.protein</code> and <code>entrez.protein</code> will have the <code>mass</code> property, even though the <code>entrez</code> proteins do not have a <code>mass</code> value in the input data.</p>  If we wanted to ignore the mass value for all properties, we could simply remove the `mass` key from the `properties` dictionary.  In\u00a0[\u00a0]: Copied! <pre>from data_generator import EntrezProtein, RandomPropertyProtein\n</pre> from data_generator import EntrezProtein, RandomPropertyProtein In\u00a0[\u00a0]: Copied! <pre># Create a list of proteins to be imported (now with properties)\nproteins = [\n    p for sublist in zip(\n        [RandomPropertyProtein() for _ in range(n_proteins)],\n        [EntrezProtein() for _ in range(n_proteins)],\n    ) for p in sublist\n]\n# New instance, populated, and to DataFrame\nbc = BioCypher(\n    biocypher_config_path='04_biocypher_config.yaml',\n    schema_config_path='04_schema_config.yaml',\n)\nbc.add(node_generator(proteins))\nfor name, df in bc.to_df().items():\n    print(name)\n    display(df)\n</pre> # Create a list of proteins to be imported (now with properties) proteins = [     p for sublist in zip(         [RandomPropertyProtein() for _ in range(n_proteins)],         [EntrezProtein() for _ in range(n_proteins)],     ) for p in sublist ] # New instance, populated, and to DataFrame bc = BioCypher(     biocypher_config_path='04_biocypher_config.yaml',     schema_config_path='04_schema_config.yaml', ) bc.add(node_generator(proteins)) for name, df in bc.to_df().items():     print(name)     display(df) <pre>INFO -- Loading ontologies...\nINFO -- Instantiating OntologyAdapter class for https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl.\n</pre> Out[\u00a0]: <pre>{'uniprot.protein':   uniprot.protein                                           sequence  \\\n 0          S1Z9L5  RHLRGDVMQEDHHTSSERMVYNVLPQDYKVVSCEYWNTQVTALWVI...   \n 1          W9J5F1  IPFSQSAWAQQRIGPKGTKAHGVTQPAPMDIKNLCNLTDLTLILDF...   \n 2          T1J3U0  WFGCCHKQYVSHVIDRQDPQSPSDNPSLVSQLQFFMWGIQIQNGEI...   \n \n            description taxon  mass      id preferred_id  \n 0  u x e o k m a i o s  3899  None  S1Z9L5      uniprot  \n 1  i x k c r b p d d p  8873  None  W9J5F1      uniprot  \n 2  m a w r r u x c w o  1966  9364  T1J3U0      uniprot  ,\n 'entrez.protein':   entrez.protein                                           sequence  \\\n 0         405878  RMTDGFEWQLDFHAFIWCNQAAWQLPLEVHISQGNGGWRMGLYGNM...   \n 1         154167  CGMNYDNGYFSVAYQSYDLWYHQQLKTRGVKPAEKDSDKDLGIDVI...   \n 2         234189  GQWQECIQGFTPQQMCVDCCAETKLANKSYYHSWMTWRLSGLCFNM...   \n \n            description taxon  mass      id preferred_id  \n 0  y c s v s n e c h o  9606  None  405878       entrez  \n 1  i k n c e n r n c d  9606  None  154167       entrez  \n 2  o v w y g h y e v y  9606  None  234189       entrez  }</pre> In\u00a0[\u00a0]: Copied! <pre>from data_generator import RandomPropertyProteinIsoform\n</pre> from data_generator import RandomPropertyProteinIsoform In\u00a0[\u00a0]: Copied! <pre>print_yaml('05_schema_config.yaml')\n</pre> print_yaml('05_schema_config.yaml') <pre>--------------\nprotein:\n    represented_as: node\n    preferred_id:\n    - uniprot\n    - entrez\n    input_label:\n    - uniprot_protein\n    - entrez_protein\n    properties:\n        sequence: str\n        description: str\n        taxon: str\n        mass: int\nprotein isoform:\n    is_a: protein\n    inherit_properties: true\n    represented_as: node\n    preferred_id: uniprot\n    input_label: uniprot_isoform\n\n--------------\n</pre> <p>This allows maintenance of property lists for many classes at once. If the child class has properties already, they will be kept (if they are not present in the parent class) or replaced by the parent class properties (if they are present).</p> <p>Again, apart from adding the protein isoforms to the input stream, the code for this example is identical to the previous one except for the reference to the updated schema configuration.</p> <p>We now create three separate DataFrames, all of which are children of the <code>protein</code> class; two implicit children (<code>uniprot.protein</code> and <code>entrez.protein</code>) and one explicit child (<code>protein isoform</code>).</p> In\u00a0[\u00a0]: Copied! <pre># create a list of proteins to be imported\nproteins = [\n    p for sublist in zip(\n        [RandomPropertyProtein() for _ in range(n_proteins)],\n        [RandomPropertyProteinIsoform() for _ in range(n_proteins)],\n        [EntrezProtein() for _ in range(n_proteins)],\n    ) for p in sublist\n]\n\n# Create BioCypher driver\nbc = BioCypher(\n    biocypher_config_path='05_biocypher_config.yaml',\n    schema_config_path='05_schema_config.yaml',\n)\n# Run the import\nbc.add(node_generator(proteins))\n\nfor name, df in bc.to_df().items():\n    print(name)\n    display(df)\n</pre> # create a list of proteins to be imported proteins = [     p for sublist in zip(         [RandomPropertyProtein() for _ in range(n_proteins)],         [RandomPropertyProteinIsoform() for _ in range(n_proteins)],         [EntrezProtein() for _ in range(n_proteins)],     ) for p in sublist ]  # Create BioCypher driver bc = BioCypher(     biocypher_config_path='05_biocypher_config.yaml',     schema_config_path='05_schema_config.yaml', ) # Run the import bc.add(node_generator(proteins))  for name, df in bc.to_df().items():     print(name)     display(df) <pre>INFO -- Loading ontologies...\nINFO -- Instantiating OntologyAdapter class for https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl.\n</pre> <pre>uniprot.protein\n  uniprot.protein                                           sequence  \\\n0          A9L6G4  SWIVVGQPDSHNKRLVNYHWMRCEHPLRCWRPIYVVRVSFQSQCEQ...   \n1          E4N2H2  PGVMILDNMQHKCSKELSTRQIITNHWICNSAPISWSSGMDRSCLD...   \n2          V4F1T1  DQCHNLCPGSSFQCPENAFGNDWIDHMPQETGLMQYDDPQSGMWFT...   \n\n           description taxon  mass      id preferred_id  \n0  m o k j a f w v w r  4220  None  A9L6G4      uniprot  \n1  n v i r s f m f d w  6339  6481  E4N2H2      uniprot  \n2  w e v v a b o b b u  9176  6510  V4F1T1      uniprot  \nprotein isoform\n  protein isoform                                           sequence  \\\n0          F0N9A4  QDVVLVEGCGDEGWIHMPEKRPGQAYKWCERFRPIPDFTNSIKIAY...   \n1          B1W6O2  SQKHFRRWWTNDCFGQELMSIYYNVKFWDNLIEMTGGPASRVCLGQ...   \n2          G6V5R9  ASAITPFSYEKPHTVTLDATEVFPKMQDAQAIEREIHFSKSTLVYG...   \n\n           description taxon  mass      id preferred_id  \n0  r f e a v a a g w r  8061  None  F0N9A4      uniprot  \n1  a c a v v k v k c w  6786  None  B1W6O2      uniprot  \n2  c k g d a l f r t v  6868  1323  G6V5R9      uniprot  \nentrez.protein\n  entrez.protein                                           sequence  \\\n0          52329  DYRSMAPTFILMKIYPACDAITKRRWSVATVKDGEFIWWSAVKIFP...   \n1         581107  LLVFNMGQLAVAGYGNTMVSAMMCFCCDVKARMGMSWLPKITTMQW...   \n2         270569  MVCSHHELAVAFQTMCPIQGDAATAKANAHRTTDKQNWMVVKWFRT...   \n\n           description taxon  mass      id preferred_id  \n0  q k r b h g t q x x  9606  None   52329       entrez  \n1  h f g z j r b g m w  9606  None  581107       entrez  \n2  s b p v f u t y g v  9606  None  270569       entrez  \n</pre> In\u00a0[\u00a0]: Copied! <pre>print_yaml('06_schema_config_pandas.yaml')\n</pre> print_yaml('06_schema_config_pandas.yaml') <pre>--------------\nprotein:\n    represented_as: node\n    preferred_id:\n    - uniprot\n    - entrez\n    input_label:\n    - uniprot_protein\n    - entrez_protein\n    properties:\n        sequence: str\n        description: str\n        taxon: str\n        mass: int\nprotein isoform:\n    is_a: protein\n    inherit_properties: true\n    represented_as: node\n    preferred_id: uniprot\n    input_label: uniprot_isoform\nprotein protein interaction:\n    is_a: pairwise molecular interaction\n    represented_as: edge\n    preferred_id: intact\n    input_label: interacts_with\n    properties:\n        method: str\n        source: str\n\n--------------\n</pre> <p>Now that we have added <code>protein protein interaction</code> as an edge, we have to simulate some interactions:</p> In\u00a0[\u00a0]: Copied! <pre>from data_generator import InteractionGenerator\n\n# Simulate edges for proteins we defined above\nppi = InteractionGenerator(\n    interactors=[p.get_id() for p in proteins],\n    interaction_probability=0.05,\n).generate_interactions()\n</pre> from data_generator import InteractionGenerator  # Simulate edges for proteins we defined above ppi = InteractionGenerator(     interactors=[p.get_id() for p in proteins],     interaction_probability=0.05, ).generate_interactions() In\u00a0[\u00a0]: Copied! <pre># naturally interactions/edges contain information about the interacting source and target nodes\n# let's look at the first one in the list\ninteraction = ppi[0]\nf\"{interaction.get_source_id()} {interaction.label} {interaction.get_target_id()}\"\n</pre> # naturally interactions/edges contain information about the interacting source and target nodes # let's look at the first one in the list interaction = ppi[0] f\"{interaction.get_source_id()} {interaction.label} {interaction.get_target_id()}\" Out[\u00a0]: <pre>'A9L6G4 interacts_with V4F1T1'</pre> In\u00a0[\u00a0]: Copied! <pre># similarly to nodes, it also has a dictionary of properties\ninteraction.get_properties()\n</pre> # similarly to nodes, it also has a dictionary of properties interaction.get_properties() Out[\u00a0]: <pre>{'source': 'signor', 'method': 'u z c x m d c u g s'}</pre> <p>As with nodes, we add first createa a new BioCypher instance, and then populate it with nodes as well as edges:</p> In\u00a0[\u00a0]: Copied! <pre>bc = BioCypher(\n    biocypher_config_path='06_biocypher_config.yaml',\n    schema_config_path='06_schema_config_pandas.yaml',\n)\n</pre> bc = BioCypher(     biocypher_config_path='06_biocypher_config.yaml',     schema_config_path='06_schema_config_pandas.yaml', ) In\u00a0[\u00a0]: Copied! <pre># Extract id, source, target, label, and property dictionary\ndef edge_generator(ppi):\n    for interaction in ppi:\n        yield (\n            interaction.get_id(),\n            interaction.get_source_id(),\n            interaction.get_target_id(),\n            interaction.get_label(),\n            interaction.get_properties(),\n        )\n\nbc.add(node_generator(proteins))\nbc.add(edge_generator(ppi))\n</pre> # Extract id, source, target, label, and property dictionary def edge_generator(ppi):     for interaction in ppi:         yield (             interaction.get_id(),             interaction.get_source_id(),             interaction.get_target_id(),             interaction.get_label(),             interaction.get_properties(),         )  bc.add(node_generator(proteins)) bc.add(edge_generator(ppi))  <pre>INFO -- Loading ontologies...\nINFO -- Instantiating OntologyAdapter class for https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl.\n</pre> <p>Let's look at the interaction DataFrame:</p> In\u00a0[\u00a0]: Copied! <pre>bc.to_df()[\"protein protein interaction\"]\n</pre> bc.to_df()[\"protein protein interaction\"] Out[\u00a0]: protein protein interaction _from _to source method 0 intact703256 A9L6G4 V4F1T1 signor u z c x m d c u g s 1 None E4N2H2 F0N9A4 intact None <p>Finally, it is worth noting that BioCypher relies on ontologies, which are machine readable representations of domains of knowledge that we use to ground the contents of our knowledge graphs. While details about ontologies are out of scope for this tutorial, and are described in detail in the BioCypher documentation, we can still have a glimpse at the ontology that we used implicitly in this tutorial:</p> In\u00a0[\u00a0]: Copied! <pre>bc.show_ontology_structure()\n</pre> bc.show_ontology_structure() <pre>Showing ontology structure based on https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl\nentity\n\u251c\u2500\u2500 association\n\u2502   \u2514\u2500\u2500 gene to gene association\n\u2502       \u2514\u2500\u2500 pairwise gene to gene interaction\n\u2502           \u2514\u2500\u2500 pairwise molecular interaction\n\u2502               \u2514\u2500\u2500 protein protein interaction\n\u2514\u2500\u2500 named thing\n    \u2514\u2500\u2500 biological entity\n        \u2514\u2500\u2500 polypeptide\n            \u2514\u2500\u2500 protein\n                \u251c\u2500\u2500 entrez.protein\n                \u251c\u2500\u2500 protein isoform\n                \u2514\u2500\u2500 uniprot.protein\n</pre> Out[\u00a0]: <pre>&lt;treelib.tree.Tree at 0x7f7327b3a880&gt;</pre>"},{"location":"tutorials/pandas_tutorial_refactored/#example-notebook-biocypher-and-pandas","title":"Example Notebook: BioCypher and Pandas\u00b6","text":""},{"location":"tutorials/pandas_tutorial_refactored/#introduction","title":"Introduction\u00b6","text":"<p>The main purpose of BioCypher is to facilitate the pre-processing of biomedical data, and thus save development time in the maintenance of curated knowledge graphs, while allowing simple and efficient creation of task-specific lightweight knowledge graphs in a user-friendly and biology-centric fashion.</p> <p>We are going to use a toy example to familiarise the user with the basic functionality of BioCypher. One central task of BioCypher is the harmonisation of dissimilar datasets describing the same entities. Thus, in this example, the input data - which in the real-world use case could come from any type of interface - are represented by simulated data containing some examples of differently formatted biomedical entities such as proteins and their interactions.</p> <p>There are two other versions of this tutorial, which only differ in the output format. The first uses a CSV output format to write files suitable for Neo4j admin import, and the second creates an in-memory collection of Pandas dataframes. You can find the former in the tutorial directory of the BioCypher repository. This tutorial simply takes the latter, in-memory approach to a Jupyter notebook.</p>"},{"location":"tutorials/pandas_tutorial_refactored/#setup","title":"Setup\u00b6","text":""},{"location":"tutorials/pandas_tutorial_refactored/#tutorial-files","title":"Tutorial files\u00b6","text":"<p>In the <code>biocypher</code> root directory, you will find a <code>tutorial</code> directory with the files for this tutorial. The <code>data_generator.py</code> file contains the simulated data generation code, and the other files, specifically the <code>.yaml</code> files, are named according to the tutorial step they are used in.</p> <p>Let's download these:</p>"},{"location":"tutorials/pandas_tutorial_refactored/#configuration","title":"Configuration\u00b6","text":"<p>BioCypher is configured using a YAML file; it comes with a default (which you can see in the Configuration section). You can use it, for instance, to select an output format, the output directory, separators, logging level, and other options. For this tutorial, we will use a dedicated configuration file for each of the steps. The configuration files are located in the <code>tutorial</code> directory, and are called using the <code>biocypher_config_path</code> argument at instantiation of the BioCypher interface. For more information, see also the Quickstart Configuration section.</p>"},{"location":"tutorials/pandas_tutorial_refactored/#section-1-adding-data","title":"Section 1: Adding data\u00b6","text":""},{"location":"tutorials/pandas_tutorial_refactored/#input-data-stream-adapter","title":"Input data stream (\"adapter\")\u00b6","text":"<p>The basic operation of adding data to the knowledge graph requires two components: an input stream of data (which we call adapter) and a configuration for the resulting desired output (the schema configuration). The former will be simulated by calling the <code>Protein</code> class of our data generator 10 times.</p>"},{"location":"tutorials/pandas_tutorial_refactored/#schema-configuration","title":"Schema configuration\u00b6","text":"<p>How each BioCypher graph is structured is determined by the schema configuration YAML file that is given to the BioCypher interface. This also serves to ground the entities of the graph in the biomedical realm by using an ontological hierarchy. In this tutorial, we refer to the Biolink model as the general backbone of our ontological hierarchy. The basic premise of the schema configuration YAML file is that each component of the desired knowledge graph output should be configured here; if (and only if) an entity is represented in the schema configuration and is present in the input data stream, will it be part of our knowledge graph.</p> <p>In our case, since we only import proteins, we only require few lines of configuration:</p>"},{"location":"tutorials/pandas_tutorial_refactored/#creating-the-graph-using-the-biocypher-interface","title":"Creating the graph (using the BioCypher interface)\u00b6","text":"<p>All that remains to be done now is to instantiate the BioCypher interface (as the main means of communicating with BioCypher) and call the function to create the graph.</p>"},{"location":"tutorials/pandas_tutorial_refactored/#section-2-merging-data","title":"Section 2: Merging data\u00b6","text":""},{"location":"tutorials/pandas_tutorial_refactored/#plain-merge","title":"Plain merge\u00b6","text":"<p>Using the workflow described above with minor changes, we can merge data from different input streams. If we do not want to introduce additional ontological subcategories, we can simply add the new input stream to the existing one and add the new label to the schema configuration (the new label being <code>entrez_protein</code>). In this case, we would add the following to the schema configuration:</p>"},{"location":"tutorials/pandas_tutorial_refactored/#ad-hoc-subclassing","title":"Ad hoc subclassing\u00b6","text":""},{"location":"tutorials/pandas_tutorial_refactored/#section-3-handling-properties","title":"Section 3: Handling properties\u00b6","text":"<p>While ID and label are mandatory components of our knowledge graph, properties are optional and can include different types of information on the entities. In source data, properties are represented in arbitrary ways, and designations rarely overlap even for the most trivial of cases (spelling differences, formatting, etc). Additionally, some data sources contain a large wealth of information about entities, most of which may not be needed for the given task. Thus, it is often desirable to filter out properties that are not needed to save time, disk space, and memory.</p> <p>Maintaining consistent properties per entity type is particularly important when using the admin import feature of Neo4j, which requires consistency between the header and data files. Properties that are introduced into only some of the rows will lead to column misalignment and import failure. In \"online mode\", this is not an issue.</p> <p>We will take a look at how to handle property selection in BioCypher in a way that is flexible and easy to maintain.</p>"},{"location":"tutorials/pandas_tutorial_refactored/#designated-properties","title":"Designated properties\u00b6","text":"<p>The simplest and most straightforward way to ensure that properties are consistent for each entity type is to designate them explicitly in the schema configuration. This is done by adding a <code>properties</code> key to the entity type configuration. The value of this key is another dictionary, where in the standard case the keys are the names of the properties that the entity type should possess, and the values give the type of the property. Possible values are:</p> <ul> <li><p><code>str</code> (or <code>string</code>),</p> </li> <li><p><code>int</code> (or <code>integer</code>, <code>long</code>),</p> </li> <li><p><code>float</code> (or <code>double</code>, <code>dbl</code>),</p> </li> <li><p><code>bool</code> (or <code>boolean</code>),</p> </li> <li><p>arrays of any of these types (indicated by square brackets, e.g. <code>string[]</code>).</p> </li> </ul> <p>In the case of properties that are not present in (some of) the source data, BioCypher will add them to the output with a default value of <code>None</code>. Additional properties in the input that are not represented in these designated property names will be ignored. Let's imagine that some, but not all, of our protein nodes have a <code>mass</code> value. If we want to include the mass value on all proteins, we can add the following to our schema configuration:</p>"},{"location":"tutorials/pandas_tutorial_refactored/#inheriting-properties","title":"Inheriting properties\u00b6","text":"<p>Sometimes, explicit designation of properties requires a lot of maintenance work, particularly for classes with many properties. In these cases, it may be more convenient to inherit properties from a parent class. This is done by adding a <code>properties</code> key to a suitable parent class configuration, and then defining inheritance via the <code>is_a</code> key in the child class configuration and setting the <code>inherit_properties</code> key to <code>true</code>.</p> <p>Let's say we have an additional <code>protein isoform</code> class, which can reasonably inherit from <code>protein</code> and should carry the same properties as the parent. We can add the following to our schema configuration:</p>"},{"location":"tutorials/pandas_tutorial_refactored/#section-4-handling-relationships","title":"Section 4: Handling relationships\u00b6","text":"<p>Naturally, we do not only want nodes in our knowledge graph, but also edges. In BioCypher, the configuration of relationships is very similar to that of nodes, with some key differences. First the similarities: the top-level class configuration of edges is the same; class names refer to ontological classes or are an extension thereof. Similarly, the <code>is_a</code> key is used to define inheritance, and the <code>inherit_properties</code> key is used to inherit properties from a parent class. Relationships also possess a <code>preferred_id</code> key, an <code>input_label</code> key, and a <code>properties</code> key, which work in the same way as for nodes.</p> <p>Relationships also have a <code>represented_as</code> key, which in this case can be either <code>node</code> or <code>edge</code>. The <code>node</code> option is used to \"reify\" the relationship in order to be able to connect it to other nodes in the graph. In addition to the configuration of nodes, relationships also have fields for the <code>source</code> and <code>target</code> node types, which refer to the ontological classes of the respective nodes, and are currently optional.</p> <p>To add protein-protein interactions to our graph, we can modify the schema configuration above to the following:</p>"},{"location":"tutorials/tutorial001_basics/","title":"Tutorial - Basics","text":"<p>The main purpose of BioCypher is to facilitate the pre-processing of biomedical data to save development time in the maintenance of curated knowledge graphs and to allow the simple and efficient creation of task-specific lightweight knowledge graphs in a user-friendly and biology-centric fashion.</p> <p>We are going to use a toy example to familiarise the user with the basic functionality of BioCypher. One central task of BioCypher is the harmonisation of dissimilar datasets describing the same entities. Thus, in this example, the input data - which in the real-world use case could come from any type of interface - are represented by simulated data containing some examples of differently formatted biomedical entities such as proteins and their interactions.</p> <p>There are two versions of this tutorial, which only differ in the output format. The first uses a CSV output format to write files suitable for Neo4j admin import, and the second creates an in-memory collection of Pandas dataframes. You can find both in the <code>tutorial</code> directory of the BioCypher repository; the Pandas version of each tutorial step is suffixed with <code>_pandas</code>.</p> <p>Warning: Neo4j</p> <p>While you can use the files generated to create an actual Neo4j database, it is not required for this tutorial. For checking the output, you can simply open the CSV files in a text editor or your IDE; by default, they will be written to the <code>biocypher-out</code> directory. If you simply want to run the tutorial to see how it works, you can also run the Pandas version.</p>"},{"location":"tutorials/tutorial001_basics/#setup","title":"Setup","text":"<p>To run this tutorial, you will need to have cloned and installed the BioCypher repository on your machine. We recommend using Poetry:</p> <pre><code>git clone https://github.com/biocypher/biocypher.git\ncd biocypher\npoetry install\n</code></pre> <p>Note: Poetry environment</p> <p>In order to run the tutorial code, you will need to activate the Poetry environment. This can be done by running <code>poetry shell</code> in the <code>biocypher</code> directory. Alternatively, you can run the code from within the Poetry environment by prepending <code>poetry run</code> to the command. For example, to run the tutorial code, you can run <code>poetry run python tutorial/01__basic_import.py</code>.</p> <p>In the <code>biocypher</code> root directory, you will find a <code>tutorial</code> directory with the files for this tutorial. The <code>data_generator.py</code> file contains the simulated data generation code, and the other files are named according to the tutorial step they are used in. The <code>biocypher-out</code> directory will be created automatically when you run the tutorial code.</p>"},{"location":"tutorials/tutorial001_basics/#configuration","title":"Configuration","text":"<p>BioCypher is configured using a YAML file; it comes with a default (which you can see in the Configuration section). You can use it, for instance, to select an output format, the output directory, separators, logging level, and other options. For this tutorial, we will use a dedicated configuration file for each of the steps. The configuration files are located in the <code>tutorial</code> directory, and are called using the <code>biocypher_config_path</code> argument at instantiation of the BioCypher interface. For more information, see also the Quickstart Configuration section.</p>"},{"location":"tutorials/tutorial001_basics/#section-1-adding-data","title":"Section 1: Adding data","text":"<p>Note: Poetry environment</p> <p>The code for this tutorial can be found at <code>tutorial/01__basic_import.py</code>. The schema is at <code>tutorial/01_schema_config.yaml</code>, configuration in <code>tutorial/01_biocypher_config.yaml</code>. Data generation happens in <code>tutorial/data_generator.py</code>.</p>"},{"location":"tutorials/tutorial001_basics/#input-data-stream-adapter","title":"Input data stream (\"adapter\")","text":"<p>The basic operation of adding data to the knowledge graph requires two components: an input stream of data (which we call adapter) and a configuration for the resulting desired output (the schema configuration). The former will be simulated by calling the <code>Protein</code> class of our data generator 10 times.</p> <pre><code>from tutorial.data_generator import Protein\nproteins = [Protein() for _ in range(10)]\n</code></pre> <p>Each protein in our simulated data has a UniProt ID, a label (\"uniprot_protein\"), and a dictionary of properties describing it. This is purely by coincidence - very close to the input BioCypher expects (for nodes): - a unique identifier - an input label (to allow mapping to the ontology, see the second step below) - a dictionary of further properties (which can be empty)</p> <p>These should be presented to BioCypher in the form of a tuple. To achieve this representation, we can use a generator function that iterates through our simulated input data and, for each entity, forms the corresponding tuple. The use of a generator allows for efficient streaming of larger datasets where required.</p> <pre><code>def node_generator():\n    for protein in proteins:\n        yield (\n            protein.get_id(),\n            protein.get_label(),\n            protein.get_properties()\n        )\n</code></pre> <p>The concept of an adapter can become arbitrarily complex and involve programmatic access to databases, API requests, asynchronous queries, context managers, and other complicating factors. However, it always boils down to providing the BioCypher driver with a collection of tuples, one for each entity in the input data. For more info, see the section on Adapters.</p> <p>As descibed above, nodes possess:</p> <ul> <li>a mandatory ID,</li> <li>a mandatory label, and</li> <li>a property dictionary,</li> </ul> <p>while edges possess:</p> <ul> <li>an (optional) ID,</li> <li>two mandatory IDs for source and target,</li> <li>a mandatory label, and</li> <li>a property dictionary.</li> </ul> <p>How these entities are mapped to the ontological hierarchy underlying a BioCypher graph is determined by their mandatory labels, which connect the input data stream to the schema configuration. This we will see in the following section.</p>"},{"location":"tutorials/tutorial001_basics/#schema-configuration","title":"Schema configuration","text":"<p>How each BioCypher graph is structured is determined by the schema configuration YAML file that is given to the BioCypher interface. This also serves to ground the entities of the graph in the biomedical realm by using an ontological hierarchy. In this tutorial, we refer to the Biolink model as the general backbone of our ontological hierarchy. The basic premise of the schema configuration YAML file is that each component of the desired knowledge graph output should be configured here; if (and only if) an entity is represented in the schema configuration and is present in the input data stream, will it be part of our knowledge graph.</p> <p>In our case, since we only import proteins, we only require few lines of configuration:</p> <pre><code>protein:                            # mapping\n    represented_as: node            # schema configuration\n    preferred_id: uniprot           # uniqueness\n    input_label: uniprot_protein    # connection to input stream\n</code></pre> <p>The first line (<code>protein</code>) identifies our entity and connects to the ontological backbone; here we define the first class to be represented in the graph. In the configuration YAML, we represent entities\u202f\u2014 similar to the internal representation of Biolink\u202f\u2014 in lower sentence case (e.g., \"small molecule\"). Conversely, for class names, in file names, and property graph labels, we use PascalCase instead (e.g., \"SmallMolecule\") to avoid issues with handling spaces. The transformation is done by BioCypher internally. BioCypher does not strictly enforce the entities allowed in this class definition; in fact, we provide several methods of extending the existing ontological backbone ad hoc by providing custom inheritance or hybridising ontologies. However, every entity should at some point be connected to the underlying ontology, otherwise the multiple hierarchical labels will not be populated. Following this first line are three indented values of the protein class.</p> <p>The second line (<code>represented_as</code>) tells BioCypher in which way each entity should be represented in the graph; the only options are <code>node</code> and <code>edge</code>. Representation as an edge is only possible when source and target IDs are provided in the input data stream. Conversely, relationships can be represented as both <code>node</code> or <code>edge</code>, depending on the desired output. When a relationship should be represented as a node, i.e., \"reified\", BioCypher takes care to create a set of two edges and a node in place of the relationship. This is useful when we want to connect the relationship to other entities in the graph, for example literature references.</p> <p>The third line (<code>preferred_id</code>) informs the uniqueness of represented entities by selecting an ontological namespace around which the definition of uniqueness should revolve. In our example, if a protein has its own uniprot ID, it is understood to be a unique entity. When there are multiple protein isoforms carrying the same uniprot ID, they are understood to be aggregated to result in only one unique entity in the graph. Decisions around uniqueness of graph constituents sometimes require some consideration in task-specific applications. Selection of a namespace also has effects in identifier mapping; in our case, for protein nodes that do not carry a uniprot ID, identifier mapping will attempt to find a uniprot ID given the other identifiers of that node. To account for the broadest possible range of identifier systems while also dealing with parsing of namespace prefixes and validation, we refer to the Bioregistry project namespaces, which should be preferred values for this field.</p> <p>Finally, the fourth line (<code>input_label</code>) connects the input data stream to the configuration; here we indicate which label to expect in the input tuple for each class in the graph. In our case, we expect \"uniprot_protein\" as the label for each protein in the input data stream; all other input entities that do not carry this label are ignored as long as they are not in the schema configuration.</p>"},{"location":"tutorials/tutorial001_basics/#creating-the-graph-using-the-biocypher-interface","title":"Creating the graph (using the BioCypher interface)","text":"<p>All that remains to be done now is to instantiate the BioCypher interface (as the main means of communicating with BioCypher) and call the function to create the graph. While this can be done \"online\", i.e., by connecting to a running DBMS instance, we will in this example use the offline mode of BioCypher, which does not require setting up a graph database instance. The following code will use the data stream and configuration set up above to write the files for knowledge graph creation:</p> <pre><code>import os\nos.chdir('../')\n</code></pre> <pre><code>from biocypher import BioCypher\n\nbc = BioCypher(\n    biocypher_config_path=\"tutorial/01_biocypher_config.yaml\",\n    schema_config_path=\"tutorial/01_schema_config.yaml\",\n)\n\nbc.write_nodes(node_generator())\n</code></pre> <p>We pass our configuration files at instantiation of the interface, and we pass the data stream to the <code>write_nodes</code> function. BioCypher will then create the graph and write it to the output directory, which is set to <code>biocypher-out/</code> by default, creating a subfolder with the current datetime for each driver instance.</p> <p>Note</p> <p>The <code>biocypher_config_path</code> parameter at instantiation of the <code>BioCypher</code> class  should in most cases not be needed; we are using it here to increase convenience of the tutorial and to showcase its use. We are overriding the default value of only two settings: the offline mode (<code>offline</code> in <code>biocypher</code>) and the database name (<code>database_name</code> in <code>neo4j</code>).</p> <p>By default, BioCypher will look for a file named <code>biocypher_config.yaml</code> in the current working directory and in its subfolder <code>config</code>, as well as in various user directories. For more information, see the section on configuration.</p>"},{"location":"tutorials/tutorial001_basics/#importing-data-into-neo4j","title":"Importing data into Neo4j","text":"<p>If you want to build an actual Neo4j graph from the tutorial output files, please follow the Neo4j import tutorial.</p>"},{"location":"tutorials/tutorial001_basics/#quality-control-and-convenience-functions","title":"Quality control and convenience functions","text":"<p>BioCypher provides a number of convenience functions for quality control and data exploration. In addition to writing the import call for Neo4j, we can print a log of ontological classes that were present in the input data but are not accounted for in the schema configuration, as well as a log of duplicates in the input data (for the level of granularity that was used for the import). We can also print the ontological hierarchy derived from the underlying model(s) according to the classes that were given in the schema configuration:</p> <pre><code>bc.log_missing_input_labels()   # show input unaccounted for in the schema\nbc.log_duplicates()             # show duplicates in the input data\nbc.show_ontology_structure()    # show ontological hierarchy\n</code></pre>"},{"location":"tutorials/tutorial001_basics/#section-2-merging-data","title":"Section 2: Merging data","text":""},{"location":"tutorials/tutorial001_basics/#plain-merge","title":"Plain merge","text":"<p>Tutorial files</p> <p>The code for this tutorial can be found at <code>tutorial/02__merge.py</code>.  Schema files are at <code>tutorial/02_schema_config.yaml</code>, configuration in <code>tutorial/02_biocypher_config.yaml</code>. Data generation happens in <code>tutorial/data_generator.py</code>.</p> <p>Using the workflow described above with minor changes, we can merge data from different input streams. If we do not want to introduce additional ontological subcategories, we can simply add the new input stream to the existing one and add the new label to the schema configuration (the new label being <code>entrez_protein</code>). In this case, we would add the following to the schema configuration:</p> <pre><code>protein:\n    represented_as: node\n    preferred_id: uniprot\n    input_label: [uniprot_protein, entrez_protein]\n</code></pre> <p>This again creates a single output file, now for both protein types, including both input streams, and the graph can be created as before using the command line call created by BioCypher. However, we are generating our <code>entrez</code> proteins as having entrez IDs, which could result in problems in querying. Additionally, a strict import mode including regex pattern matching of identifiers will fail at this point due to the difference in pattern of UniProt vs. Entrez IDs. This issue could be resolved by mapping the Entrez IDs to UniProt IDs, but we will instead use the opportunity to demonstrate how to merge data from different sources into the same ontological class using ad hoc subclasses.</p>"},{"location":"tutorials/tutorial001_basics/#ad-hoc-subclassing","title":"Ad hoc subclassing","text":"<p>Tutorial files</p> <p>The code for this tutorial can be found at <code>tutorial/03__implicit_subclass.py</code>. Schema files are at <code>tutorial/03_schema_config.yaml</code>, configuration in <code>tutorial/03_biocypher_config.yaml</code>.  Data generation happens in <code>tutorial/data_generator.py</code>.</p> <p>In the previous section, we saw how to merge data from different sources into the same ontological class. However, we did not resolve the issue of the <code>entrez</code> proteins living in a different namespace than the <code>uniprot</code> proteins, which could result in problems in querying. In proteins, it would probably be more appropriate to solve this problem using identifier mapping, but in other categories, e.g., pathways, this may not be possible because of a lack of one-to-one mapping between different data sources. Thus, if we so desire, we can merge datasets into the same ontological class by creating ad hoc subclasses implicitly through BioCypher, by providing multiple preferred identifiers. In our case, we update our schema configuration as follows:</p> <pre><code>protein:\n    represented_as: node\n    preferred_id: [uniprot, entrez]\n    input_label: [uniprot_protein, entrez_protein]\n</code></pre> <p>This will \"implicitly\" create two subclasses of the <code>protein</code> class, which will inherit the entire hierarchy of the <code>protein</code> class. The two subclasses will be named using a combination of their preferred namespace and the name of the parent class, separated by a dot, i.e., <code>uniprot.protein</code> and <code>entrez.protein</code>. In this manner, they can be identified as proteins regardless of their sources by any queries for the generic <code>protein</code> class, while still carrying information about their namespace and avoiding identifier conflicts.</p> <p>Note</p> <p>The only change affected upon the code from the previous section is the referral to the updated schema configuration file.</p> <p>Hint</p> <p>In the output, we now generate two separate files for the <code>protein</code> class, one for each subclass (with names in PascalCase).</p>"},{"location":"tutorials/tutorial001_basics/#section-3-handling-properties","title":"Section 3: Handling properties","text":"<p>While ID and label are mandatory components of our knowledge graph, properties are optional and can include different types of information on the entities. In source data, properties are represented in arbitrary ways, and designations rarely overlap even for the most trivial of cases (spelling differences, formatting, etc). Additionally, some data sources contain a large wealth of information about entities, most of which may not be needed for the given task. Thus, it is often desirable to filter out properties that are not needed to save time, disk space, and memory.</p> <p>Note</p> <p>Maintaining consistent properties per entity type is particularly important when using the admin import feature of Neo4j, which requires consistency between the header and data files. Properties that are introduced into only some of the rows will lead to column misalignment and import failure. In \"online mode\", this is not an issue.</p> <p>We will take a look at how to handle property selection in BioCypher in a way that is flexible and easy to maintain.</p>"},{"location":"tutorials/tutorial001_basics/#designated-properties","title":"Designated properties","text":"<p>Tutorial files</p> <p>The code for this tutorial can be found at <code>tutorial/04__properties.py</code>. Schema files are at <code>tutorial/04_schema_config.yaml</code>, configuration in <code>tutorial/04_biocypher_config.yaml</code>. Data generation happens in <code>tutorial/data_generator.py</code>.</p> <p>The simplest and most straightforward way to ensure that properties are consistent for each entity type is to designate them explicitly in the schema configuration. This is done by adding a <code>properties</code> key to the entity type configuration. The value of this key is another dictionary, where in the standard case the keys are the names of the properties that the entity type should possess, and the values give the type of the property. Possible values are:</p> <ul> <li> <p><code>str</code> (or <code>string</code>),</p> </li> <li> <p><code>int</code> (or <code>integer</code>, <code>long</code>),</p> </li> <li> <p><code>float</code> (or <code>double</code>, <code>dbl</code>),</p> </li> <li> <p><code>bool</code> (or <code>boolean</code>),</p> </li> <li> <p>arrays of any of these types (indicated by square brackets, e.g. <code>string[]</code>).</p> </li> </ul> <p>In the case of properties that are not present in (some of) the source data, BioCypher will add them to the output with a default value of <code>None</code>. Additional properties in the input that are not represented in these designated property names will be ignored. Let's imagine that some, but not all, of our protein nodes have a <code>mass</code> value. If we want to include the mass value on all proteins, we can add the following to our schema configuration:</p> <pre><code>protein:\n    represented_as: node\n    preferred_id: [uniprot, entrez]\n    input_label: [uniprot_protein, entrez_protein]\n    properties:\n        sequence: str\n        description: str\n        taxon: str\n        mass: dbl\n</code></pre> <p>This will add the <code>mass</code> property to all proteins (in addition to the three we had before); if not encountered, the column will be empty. Implicit subclasses will automatically inherit the property configuration; in this case, both <code>uniprot.protein</code> and <code>entrez.protein</code> will have the <code>mass</code> property, even though the <code>entrez</code> proteins do not have a <code>mass</code> value in the input data.</p> <p>Note</p> <p>If we wanted to ignore the mass value for all properties, we could simply remove the <code>mass</code> key from the <code>properties</code> dictionary.</p> <p>Tip</p> <p>BioCypher provides feedback about property conflicts; try running the code for this example (<code>04__properties.py</code>) with the schema configuration of the previous section (<code>03_schema_config.yaml</code>) and see what happens.</p>"},{"location":"tutorials/tutorial001_basics/#inheriting-properties","title":"Inheriting properties","text":"<p>Tutorial files</p> <p>The code for this tutorial can be found at <code>tutorial/05__property_inheritance.py</code>. Schema files are at <code>tutorial/05_schema_config.yaml</code>, configuration in <code>tutorial/05_biocypher_config.yaml</code>. Data generation happens in  <code>tutorial/data_generator.py</code>.</p> <p>Sometimes, explicit designation of properties requires a lot of maintenance work, particularly for classes with many properties. In these cases, it may be more convenient to inherit properties from a parent class. This is done by adding a <code>properties</code> key to a suitable parent class configuration, and then defining inheritance via the <code>is_a</code> key in the child class configuration and setting the <code>inherit_properties</code> key to <code>true</code>.</p> <p>Let's say we have an additional <code>protein isoform</code> class, which can reasonably inherit from <code>protein</code> and should carry the same properties as the parent. We can add the following to our schema configuration:</p> <pre><code>protein isoform:\n    is_a: protein\n    inherit_properties: true\n    represented_as: node\n    preferred_id: uniprot\n    input_label: uniprot_isoform\n</code></pre> <p>This allows maintenance of property lists for many classes at once. If the child class has properties already, they will be kept (if they are not present in the parent class) or replaced by the parent class properties (if they are present).</p> <p>Note</p> <p>Again, apart from adding the protein isoforms to the input stream, the code for this example is identical to the previous one except for the reference to the updated schema configuration.    </p> <p>Hint</p> <p>We now create three separate data files, all of which are children of the <code>protein</code> class; two implicit children (<code>uniprot.protein</code> and <code>entrez.protein</code>) and one explicit child (<code>protein isoform</code>).    </p>"},{"location":"tutorials/tutorial001_basics/#section-4-handling-relationships","title":"Section 4: Handling relationships","text":"<p>Tutorial Files</p> <p>The code for this tutorial can be found at <code>tutorial/06__relationships.py</code>. Schema files are at <code>tutorial/06_schema_config.yaml</code>, configuration in <code>tutorial/06_biocypher_config.yaml</code>. Data generation happens in <code>tutorial/data_generator.py</code>.    </p> <p>Naturally, we do not only want nodes in our knowledge graph, but also edges. In BioCypher, the configuration of relationships is very similar to that of nodes, with some key differences. First the similarities: the top-level class configuration of edges is the same; class names refer to ontological classes or are an extension thereof. Similarly, the <code>is_a</code> key is used to define inheritance, and the <code>inherit_properties</code> key is used to inherit properties from a parent class. Relationships also possess a <code>preferred_id</code> key, an <code>input_label</code> key, and a <code>properties</code> key, which work in the same way as for nodes.</p> <p>Relationships also have a <code>represented_as</code> key, which in this case can be either <code>node</code> or <code>edge</code>. The <code>node</code> option is used to \"reify\" the relationship in order to be able to connect it to other nodes in the graph. In addition to the configuration of nodes, relationships also have fields for the <code>source</code> and <code>target</code> node types, which refer to the ontological classes of the respective nodes, and are currently optional.</p> <p>To add protein-protein interactions to our graph, we can add the following to the schema configuration above:</p> <pre><code>protein protein interaction:\n    is_a: pairwise molecular interaction\n    represented_as: node\n    preferred_id: intact\n    input_label: interacts_with\n    properties:\n        method: str\n        source: str\n</code></pre> <p>Here, we use explicit subclassing to define the protein-protein interaction, which is not represented in the basic Biolink model, as a direct child of the Biolink \"pairwise molecular interaction\" class. We also reify this relationship by representing it as a node. This allows us to connect it to other nodes in the graph, for example to evidences for each interaction. If we do not want to reify the relationship, we can set <code>represented_as</code> to <code>edge</code> instead.</p>"},{"location":"tutorials/tutorial001_basics/#relationship-identifiers","title":"Relationship identifiers","text":"<p>In biomedical data, relationships often do not have curated unique identifiers. Nevertheless, we may want to be able to refer to them in the graph. Thus, edges possess an ID field similar to nodes, which can be supplied in the input data as an optional first element in the edge tuple. Generating this ID from the properties of the edge (source and target identifiers, and additionally any properties that the edge possesses) can be done, for instance, by using the MD5 hash of the concatenation of these values. Edge IDs are active by default, but can be deactivated by setting the <code>use_id</code> field to <code>false</code> in the <code>schema_config.yaml</code> file.</p> schema_config.yaml<pre><code>protein protein interaction:\n    is_a: pairwise molecular interaction\n    represented_as: edge\n    use_id: false\n    # ...\n</code></pre>"},{"location":"tutorials/tutorial002_handling_ontologies/","title":"Tutorial - Handling Ontologies","text":"<p>BioCypher relies on ontologies to ground the knowledge graph contents in biology. This has the advantages of providing machine readability and therefore automation capabilities as well as making working with BioCypher accessible to biologically oriented researchers. However, it also means that BioCypher requires a certain amount of knowledge about ontologies and how to use them. We try to make dealing with ontologies as easy as possible, but some basic understanding is required. In the following we will cover the basics of ontologies and how to use them in BioCypher.</p>"},{"location":"tutorials/tutorial002_handling_ontologies/#what-is-an-ontology","title":"What is an ontology?","text":"<p>An ontology is a formal representation of a domain of knowledge. It is a hierarchical structure of concepts and relations. The concepts are organized into a hierarchy, where each concept is a subclass of a more general concept. For instance, a wardrobe is a subclass of a piece of furniture. Individual wardrobes, such as yours or mine, are instances of the concept wardrobe, and as such would be represented as Wardrobe nodes in a knowledge graph. In BioCypher, these nodes would additionally inherit the PieceOfFurniture label from the ontological hierarchy of things.</p> <p>Note</p> <p>Why is the class called piece of furniture but the label is PieceOfFurniture?</p> <p>The Biolink model uses two different case notations for its labels: the \"internal\" designation of classes is in lower sentence case (\"protein\", \"pairwise molecular interaction\"), while the \"external\" designation is in PascalCase (\"Protein\", \"PairwiseMolecularInteraction\"). BioCypher uses the same paradigm: in most cases (input, schema configuration, internally), the lower sentence case is used, while in the output (Neo4j labels, file system names) the PascalCase is more suitable; Neo4j labels and system file names don't deal well with spaces and special characters. Therefore, we check the output file names for their compliance with the Neo4j naming rules. All non compliant characters are removed from the file name (e.g. if the ontology class is called \"desk (piece of furniture)\", the brackets would be removed and the file name will be \"DeskPieceOfFurniture\"). We also remove the \"biolink:\" CURIE prefix for use in file names and Neo4j labels.</p> <p>The relations between concepts can also be organized into a hierarchy. In the specific case of a Neo4j graph, however, relationships cannot possess multiple labels; therefore, if concept inheritance is desired for relationships, they need to be \"reified\", i.e., turned into nodes. BioCypher provides a simple way of converting edges to nodes and vice versa (using the <code>represented_as</code> field). For a more in-depth explanation of ontologies, we recommend this introduction.</p>"},{"location":"tutorials/tutorial002_handling_ontologies/#how-biocypher-uses-ontologies","title":"How BioCypher uses ontologies","text":"<p>BioCypher is agnostic to the choice of ontology. Practically, we have built our initial projects around the Biolink model, because it provides a large but shallow collection of concepts that are relevant to the biomedical domain. Other examples of generalist ontologies are the Experimental Factor Ontology and the Basic Formal Ontology. To account for the specific requirements of expert systems, it is possible to use multiple ontologies in the same project. For instance, one might want to extend the rather basic classes relating to molecular interactions in Biolink (the most specific being <code>pairwise molecular interaction</code>) with more specific classes from a more domain-specific ontology, such as the EBI molecular interactions ontology (PSI-MI). A different project may need to define very specific genetics concepts, and thus extend the Biolink model at the terminal node <code>sequence variant</code> with the corresponding subtree of the Sequence Ontology. The OBO Foundry and the BioPortal collect many such specialised ontologies.</p> <p>The default format for ingesting ontology definitions into BioCypher is the Web Ontology Language (OWL); BioCypher can read <code>.owl</code>, <code>.rdf</code>, and <code>.ttl</code> files. The preferred way to specify the ontology or ontologies to be used in a project is to specify them in the biocypher configuration file (<code>biocypher_config.yaml</code>). This file is used to specify the location of the ontology files, as well as the root node of the main (\"head\") ontology and join nodes as fusion points for all \"tail\" ontologies. For more info, see the section on hybridising ontologies.</p>"},{"location":"tutorials/tutorial002_handling_ontologies/#visualising-ontologies","title":"Visualising ontologies","text":"<p>BioCypher provides a simple way of visualising the ontology hierarchy. This is useful for debugging and for getting a quick overview of the ontology and which parts are actually used in the knowledge graph to be created. Depending on your use case you can either visualise the parts of the ontology used in the knowledge graph (sufficient for most use cases) or the full ontology. If the used ontology is more complex and contains multiple inheritance please refer to the section on visualising complex ontologies.</p>"},{"location":"tutorials/tutorial002_handling_ontologies/#visualise-only-the-parts-of-the-ontology-used-in-the-knowledge-graph","title":"Visualise only the parts of the ontology used in the knowledge graph","text":"<p>To get an overview of the structure of our project, we can run the following command via the interface:</p> Visualising the ontology hierarchy<pre><code>from biocypher import BioCypher\nbc = BioCypher(\n    offline=True,  # no need to connect or to load data\n    schema_config_path=\"tutorial/06_schema_config.yaml\",\n)\nbc.show_ontology_structure()\n</code></pre> <p>This will build the ontology scaffold and print a tree visualisation of its hierarchy to the console using the treelib library. You can see this in action in tutorial part 6 (<code>tutorial/06_relationships.py</code>). The output will look something like this:</p> <pre><code>Showing ontology structure, based on Biolink 3.0.3:\nentity\n\u251c\u2500\u2500 association\n\u2502   \u2514\u2500\u2500 gene to gene association\n\u2502       \u2514\u2500\u2500 pairwise gene to gene interaction\n\u2502           \u2514\u2500\u2500 pairwise molecular interaction\n\u2502               \u2514\u2500\u2500 protein protein interaction\n\u251c\u2500\u2500 mixin\n\u2514\u2500\u2500 named thing\n    \u2514\u2500\u2500 biological entity\n        \u2514\u2500\u2500 polypeptide\n            \u2514\u2500\u2500 protein\n                \u251c\u2500\u2500 entrez.protein\n                \u251c\u2500\u2500 protein isoform\n                \u2514\u2500\u2500 uniprot.protein\n</code></pre> <p>Note</p> <p>BioCypher will only show the parts of the ontology that are actually used in the knowledge graph with the exception of intermediary nodes that are needed to build a complete tree. For instance, the <code>protein</code> class is linked to the root class <code>entity</code> via <code>polypeptide</code>, <code>biological entity</code>, and <code>named thing</code>, all of which are not part of the input data.</p>"},{"location":"tutorials/tutorial002_handling_ontologies/#visualise-the-full-ontology","title":"Visualise the full ontology","text":"<p>If you want to see the complete ontology tree, you can call <code>show_ontology_structure</code> with the parameter <code>full=True</code>.</p> Visualising the full ontology hierarchy<pre><code>from biocypher import BioCypher\nbc = BioCypher(\n    offline=True,  # no need to connect or to load data\n    schema_config_path=\"tutorial/06_schema_config.yaml\",\n)\nbc.show_ontology_structure(full=True)\n</code></pre>"},{"location":"tutorials/tutorial002_handling_ontologies/#visualise-complex-ontologies","title":"Visualise complex ontologies","text":"<p>Not all ontologies can be easily visualised as a tree, such as ontologies with multiple inheritance, where classes in the ontology can have multiple parent classes. This violates the definition of a tree, where each node can only have one parent node. Consequently, ontologies with multiple inheritance cannot be visualised as a tree.</p> <p>BioCypher can still handle these ontologies, and you can call <code>show_ontology_structure()</code> to get a visualisation of the ontology. However, each ontology class will only be added to the hierarchy tree once (a class with multiple parent classes is only placed under one parent in the hierarchy tree). Since this will occur the first time the class is seen, the ontology class might not be placed where you would expect it. This only applies to the visualisation; the underlying ontology is still correct and contains all ontology classes and their relationships.</p> <p>Note</p> <p>When calling <code>show_ontology_structure()</code>, BioCypher automatically checks if the ontology contains multiple inheritance and logs a warning message if so.</p> <p>If you need to get a visualisation of the ontology with multiple inheritance, you can call <code>show_ontology_structure()</code> with the parameter <code>to_disk=/some/path/where_to_store_the_file</code>. This creates a <code>GraphML</code> file and stores it at the specified location.</p>"},{"location":"tutorials/tutorial002_handling_ontologies/#using-ontologies-plain-biolink","title":"Using ontologies: plain Biolink","text":"<p>BioCypher maps any input data to the underlying ontology; in the basic case, the Biolink model. This mapping is defined in the schema configuration (<code>schema_config.yaml</code>, see also here). In the simplest case, the representation of a concept in the knowledge graph to be built and the Biolink model class representing this concept are synonymous. For instance, the concept protein is represented by the Biolink class protein. To introduce proteins into the knowledge graph, one would simply define a node constituent with the class label protein. This is the mechanism we implicitly used for proteins in the basic tutorial (part 1); to reiterate:</p> schema_config.yaml<pre><code>protein:\n  represented_as: node\n  # ...\n</code></pre>"},{"location":"tutorials/tutorial002_handling_ontologies/#model-extensions","title":"Model extensions","text":"<p>There are multiple reasons why a user might want to modify the basic model of the ontology or ontologies used. A class that is relevant to the user's task might be missing (Explicit inheritance). A class might not be granular enough, and the user would like to split it into subclasses based on distinct inputs (Implicit inheritance). For some very common use cases, we recommend going one step further and, maybe after some testing using the above \"soft\" model extensions, proposing the introduction of a new class to the model itself. For instance, Biolink is an open source community project, and new classes can be requested by opening an issue or filing a pull request directly on the Biolink model GitHub repository. Similar mechanisms apply for OBO Foundry ontologies.</p> <p>BioCypher provides further methods for ontology manipulation. The name of a class of the model may be too unwieldy for the use inside the desired knowledge graph, and the user would like to introduce a synonym/alias (Synonyms). Finally, the user might want to extend the basic model with another, more specialised ontology (Hybridising ontologies).</p>"},{"location":"tutorials/tutorial002_handling_ontologies/#explicit-inheritance","title":"Explicit inheritance","text":"<p>Explicit inheritance is the most straightforward way of extending the basic model. It is also the most common use case. For instance, the Biolink model does not contain a class for <code>protein isoform</code>, and neither does it contain a relationship class for <code>protein protein interaction</code>, both of which we have already used in the basic tutorial. Since protein isoforms are specific types of protein, it makes sense to extend the existing Biolink model class <code>protein</code> with the concept of protein isoforms. To do this, we simply add a new class <code>protein isoform</code> to the schema configuration, and specify that it is a subclass of <code>protein</code> using the (optional) <code>is_a</code> field:</p> schema_config.yaml<pre><code>protein isoform:\n  is_a: protein\n  represented_as: node\n  # ...\n</code></pre> <p>Explicit inheritance can also be used to introduce new relationship classes. However, if the output is a Neo4j graph, these relationships must be represented as nodes to provide full functionality, since edges do not allow multiple labels. This does not mean that explicit inheritance cannot be used in edges; it is even recommended to do so to situate all components of the knowledge graph in the ontological hierarchy. However, to have the ancestry represented in the resulting Neo4j graph DB, multiple labels are required. For instance, we have already used the <code>protein protein interaction</code> relationship in the basic tutorial (part 6), making it a child of the Biolink model class <code>pairwise molecular interaction</code>. To reiterate:</p> schema_config.yaml<pre><code>protein protein interaction:\n  is_a: pairwise molecular interaction\n  represented_as: node\n  # ...\n</code></pre> <p>The <code>is_a</code> field can be used to specify multiple inheritance, i.e., multiple ancestor classes and their direct parent-child relationships can be created by specifying multiple classes (as a list) in the <code>is_a</code> field. For instance, if we wanted to further extend the protein-protein interaction with a more specific <code>enzymatic interaction</code> class, we could do so as follows:</p> schema_config.yaml<pre><code>enzymatic interaction:\n  is_a: [protein protein interaction, pairwise molecular interaction]\n  represented_as: node\n  # ...\n</code></pre> <p>Note</p> <p>To create this multiple inheritance chain, we do not require the creation of a <code>protein protein interaction</code> class as shown above; all intermediary classes are automatically created by BioCypher and inserted into the ontological hierarchy. To obtain a continuous ontology tree, the target class (i.e., the last in the list) must be a real Biolink model class.</p>"},{"location":"tutorials/tutorial002_handling_ontologies/#implicit-inheritance","title":"Implicit inheritance","text":"<p>The base model (in the standard case, Biolink) can also be extended without specifying an explicit <code>is_a</code> field. This \"implicit\" inheritance happens when a class has multiple input labels that each refer to a distinct preferred identifier. In other words, if both the <code>input_label</code> and the <code>preferred_id</code> fields of a schema configuration class are lists, BioCypher will automatically create a subclass for each of the preferred identifiers. This is demonstrated in part 3 of the basic tutorial.</p> <p>Caution</p> <p>If only the <code>input_label</code> field - but not the <code>preferred_id</code> field - is a list, BioCypher will merge the inputs instead. This is useful for cases where different input streams should be unified under the same class label. See part 2 of the basic tutorial for more information.</p> <p>To make this more concrete, let's consider the example of <code>pathway</code> annotations. There are multiple projects that provide pathway annotations, such as Reactome and Wikipathways, and, in contrast to proteins, pathways are not easily mapped one-to-one. For classes where mapping is difficult or even impossible, we can use implicit subclassing instead. The Biolink model contains a <code>pathway</code> class, which we can use as a parent class of the Reactome and Wikipathways classes; we simply need to provide the pathways as two separate inputs with their own labels (e.g., \"react\" and \"wiki\"), and specify a corresponding list of preferred identifiers in the <code>preferred_id</code> field:</p> schema_config.yaml<pre><code>pathway:\n  represented_as: node\n  preferred_id: [reactome, wikipathways]\n  input_label: [react, wiki]\n  # ...\n</code></pre> <p>This will prompt BioCypher to create two subclasses of <code>pathway</code>, one for each input, and to map the input data to these subclasses. In the resulting knowledge graph, the Reactome and Wikipathways pathways will be represented as distinct classes by prepending the preferred identifier to the class label: <code>Reactome.Pathway</code> and <code>Wikipathways.Pathway</code>. By virtue of BioCypher's multiple labelling paradigm, those nodes will also inherit the <code>Pathway</code> class label as well as all parent labels and mixins of <code>Pathway</code> (<code>BiologicalProcess</code>, etc.). This allows us to query the graph for all <code>Pathway</code> nodes as well as for specific datasets depending on the desired granularity.</p> <p>Note</p> <p>This also works for relationships, but in this case, not the preferred identifiers but the sources (defined in the <code>source</code> field) are used to create the subclasses.</p>"},{"location":"tutorials/tutorial002_handling_ontologies/#synonyms","title":"Synonyms","text":"<p>Note: Tutorial Files</p> <p>The code for this tutorial can be found at <code>tutorial/07__synonyms.py</code>. Schema files are at <code>tutorial/07_schema_config.yaml</code>, configuration in <code>tutorial/07_biocypher_config.yaml</code>. Data generation happens in <code>tutorial/data_generator.py</code>.</p> <p>In some cases, an ontology may contain a biological concept, but the name of the concept does for some reason not agree with the users desired knowledge graph structure. For instance, the user may not want to represent protein complexes in the graph as <code>macromolecular complex</code> nodes due to ease of use and/or readability criteria and rather call these nodes <code>complex</code>. In such cases, the user can introduce a synonym for the ontology class. This is done by selecting another, more desirable name for the respective class(es) and specifying the <code>synonym_for</code> field in their schema configuration. In this case, as we would like to represent protein complexes as <code>complex</code> nodes, we can do so as follows:</p> schema_config.yaml<pre><code>complex:\n  synonym_for: macromolecular complex\n  represented_as: node\n  # ...\n</code></pre> <p>Importantly, BioCypher preserves these mappings to enable compatibility between different structural instantiations of the ontology (or combination of ontologies). All entities that are mapped to ontology classes in any way can be harmonised even between different types of concrete representations.</p> <p>Note</p> <p>It is essential that the desired class name is used as the main class key in the schema configuration, and the ontology class name is given in the <code>synonym_for</code> field. The name given in the <code>synonym_for</code> field must be an existing class name (in this example, a real Biolink class).</p> <p>We can visualise the structure of the ontology as we have before. Instead of using <code>bc.show_ontology_structure()</code> however, we can use the <code>bc.summary()</code> method to show the structure and simultaneously check for duplicates and missing labels. This is useful for debugging purposes, and we can see that the import was completed without encountering duplicates, and all labels in the input are accounted for in the schema configuration. We also observe in the tree that the <code>complex</code> class is now a synonym for the <code>macromolecular complex</code> class (their being synonyms indicated as an equals sign):</p> <pre><code>Showing ontology structure based on https://raw.githubusercontent.com/biolink/biolink-model/v3.2.1/biolink-model.owl.ttl\nentity\n\u251c\u2500\u2500 association\n\u2502   \u2514\u2500\u2500 gene to gene association\n\u2502       \u2514\u2500\u2500 pairwise gene to gene interaction\n\u2502           \u2514\u2500\u2500 pairwise molecular interaction\n\u2502               \u2514\u2500\u2500 protein protein interaction\n\u2514\u2500\u2500 named thing\n    \u2514\u2500\u2500 biological entity\n        \u251c\u2500\u2500 complex = macromolecular complex\n        \u2514\u2500\u2500 polypeptide\n            \u2514\u2500\u2500 protein\n                \u251c\u2500\u2500 entrez.protein\n                \u251c\u2500\u2500 protein isoform\n                \u2514\u2500\u2500 uniprot.protein\n</code></pre>"},{"location":"tutorials/tutorial002_handling_ontologies/#hybridising-ontologies","title":"Hybridising ontologies","text":"<p>A broad, general ontology is a useful tool for knowledge representation, but often the task at hand requires more specific and granular concepts. In such cases, it is possible to hybridise the general ontology with a more specific one. For instance, there are many different types of sequence variants in biology, but Biolink only provides a generic \"sequence variant\" class (and it clearly exceeds the scope of Biolink to provide granular classes for all thinkable cases). However, there are many specialist ontologies, such as the Sequence Ontology (SO), which provides a more granular representation of sequence variants, and MONDO, which provides a more granular representation of diseases.</p> <p>To hybridise the Biolink model with the SO and MONDO, we can use the generic ontology adapter class of BioCypher by providing \"tail ontologies\" as dictionaries consisting of an OWL format ontology file and a set of nodes, one in the head ontology (which by default is Biolink), and one in the tail ontology. Each of the tail ontologies will then be joined to the head ontology to form the hybridised ontology at the specified nodes. It is up to the user to make sure that the concept at which the ontologies shall be joined makes sense as a point of contact between the ontologies; ideally, it is the exact same concept.</p> <p>Hint</p> <p>If the concept does not exist in the head ontology, but is a feasible child class of an existing concept, you can set the <code>merge_nodes</code> option to <code>False</code> to prevent the merging of head and tail join nodes, but instead adding the tail join node as a child of the head join node you have specified. For instance, in the example below, we merge <code>sequence variant</code> from Biolink and <code>sequence_variant</code> from Sequence Ontology into a single node, but we add the MONDO subtree of <code>human disease</code> as a child of <code>disease</code> in Biolink.</p> <p><code>merge_nodes</code> is set to <code>True</code> by default, so there is no need to specify it in the configuration file if you want to merge the nodes.</p> <p>The ontology adapter also accepts any arbitrary \"head ontology\" as a base ontology, but if none is provided, the Biolink model is used as the default head ontology. However, it is strongly recommended to explicitly specify your desired ontology version here. These options can be provided to the BioCypher interface as parameters, or as options in the BioCypher configuration file, which is the preferred method for transparency reasons:</p> Using biocypher_config.yaml<pre><code># ...\n\nbiocypher:  # biocypher settings\n\n  # Ontology configuration\n  head_ontology:\n    url: https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl\n    root_node: entity\n\n  tail_ontologies:\n\n    so:\n      url: data/so.owl\n      head_join_node: sequence variant\n      tail_join_node: sequence_variant\n\n    mondo:\n      url: http://purl.obolibrary.org/obo/mondo.owl\n      head_join_node: disease\n      tail_join_node: human disease\n      merge_nodes: false\n\n# ...\n</code></pre> <p>Note</p> <p>The <code>url</code> parameter can be either a local path or a URL to a remote resource.   </p> <p>If you need to pass the ontology configuration programmatically, you can do so as follows at BioCypher interface instantiation:</p> Programmatic usage<pre><code>bc = BioCypher(\n    # ...\n\n    head_ontology={\n      'url': 'https://github.com/biolink/biolink-model/raw/v3.2.1/biolink-model.owl.ttl',\n      'root_node': 'entity',\n    },\n\n    tail_ontologies={\n        'so':\n            {\n                'url': 'test/ontologies/so.owl',\n                'head_join_node': 'sequence variant',\n                'tail_join_node': 'sequence_variant',\n            },\n        'mondo':\n            {\n                'url': 'test/ontologies/mondo.owl',\n                'head_join_node': 'disease',\n                'tail_join_node': 'human disease',\n                'merge_nodes': False,\n            }\n    },\n\n    # ...\n)\n</code></pre>"},{"location":"tutorials/tutorial003_adapters/","title":"Tutorial - Adapters","text":"<p>Note</p> <p>For a list of existing and planned adapters, please see here. You can also get an overview of pipelines and the adapters they use in our meta graph.</p> <p></p> <p>Note</p> <p>To facilitate the creation of a BioCypher pipeline, we have created a template repository that can be used as a starting point for your own adapter. It contains a basic structure for an adapter, as well as a script that can be used as a blueprint for a build pipeline. The repository can be found here.  </p> <p>A \"BioCypher adapter\" is a python program responsible for connecting to the BioCypher core and providing it with the data from its associated resource. In doing so, it should adhere to several design principles to ensure simple interoperability between the core and multiple adapters. In essence, an adapter should conform to an interface that is defined by the core to give information about the nodes and edges the adapter provides to enable automatic harmonisation of the contents. An adapter can be \"primary\", i.e., responsible for a single \"atomic\" resource (e.g. UniProt, Reactome, etc.), or \"secondary\", i.e., connecting to a resource that is itself a combination of multiple primary resources (e.g. OmniPath, Open Targets, etc.). Due to extensive prior harmonisation, the latter is often easier to implement and thus is a good starting point that can be subsequently extended to and replaced by primary adapters.</p> <p>Warning</p> <p>The adapter interface is still under development and may change rapidly.</p>"},{"location":"tutorials/tutorial003_adapters/#adapter-philosophy","title":"Adapter philosophy","text":"<p>There are currently two 'flavours' of adapters. The first is simpler and used in workflows that are similar to harmonisation scripts, where the BioCypher interface is instantiated in the same script as the adapter(s). In the second, the BioCypher interface is contained in the adapter class, which makes for a more complex architecture, but allows for more involved workflows. In pseudo-code, the two approaches look like this:</p> Simple adapter<pre><code>from biocypher import BioCypher\nfrom adapter import Adapter\n\nbc = BioCypher()\nadapter = Adapter()\n\nbc.write_nodes(adapter.get_nodes())\n</code></pre> <p>Here, the script file is the central point of control, orchestrating the entire interaction between the BioCypher core and the adapter(s). Examples of this simpler format are the Open Targets KG and the CROssBAR v2.</p> <p>On the other hand, the more involved approach looks like this:</p> Adapter base class<pre><code>from biocypher import BioCypher\n\nclass Adapter:\n    __bc = BioCypher()\n\n    def __init__(self):\n        # setup\n\n    @classmethod\n    def get_biocypher(cls):\n        return Adapter.__bc\n\n    def get_nodes(self):\n        # ...\n        return nodes\n\n    def write_nodes(self):\n        Adapter.get_biocypher.write_nodes(self.get_nodes())\n</code></pre> <p>Here, the adapter class (and adapters inheriting from it) contains a singleton instance of the BioCypher interface. Thus, the adapter needs to provide BioCypher functionality to the outside via dedicated methods. This allows for more complex workflows, for instance, reducing clutter when executing multiple adapters in a single for-loop, or writing from a stream of data, e.g. in a Neo4j transaction (which happens inside the adapter).</p> Main script<pre><code>from adapters import AdapterChild1, AdapterChild2\n\nadapters = [AdapterChild1(), AdapterChild2()]\n\nfor adapter in adapters:\n    adapter.write_nodes()\n</code></pre> <p>Examples of this approach are the IGVF Knowledge Graph and the Clinical Knowledge Graph migration.</p> <p>Note</p> <p>While there are differences in implementation details, both approaches are largely functionally equivalent. At the current time, there is no clear preference for one over the other; both are used. As the ecosystem matures and more high-level functionality is added (e.g. the pipeline), advantages of one approach over the other may become more apparent.   </p>"},{"location":"tutorials/tutorial003_adapters/#adapter-functions","title":"Adapter functions","text":"<p>In general, a single adapter fulfils the following tasks:</p> <ol> <li> <p>Loading the data from the primary resource, for instance by using pypath download / caching functions (as in the UniProt example adapter), by using columnar distributed data formats such as Parquet (as in the Open Targets example adapter), by using a running database instance (as in the CKG example adapter), or by simply reading a file from disk (as in the Dependency Map example adapter). Generally, any method that allows the efficient transfer of the data from adapter to BioCypher core is acceptable.</p> </li> <li> <p>Passing the data to BioCypher as a stream or list to be written to the used DBMS (or application) via a Python driver (\"online\") or via batch import (e.g. from CSV files).  The latter has the advantage of high throughput and a low memory footprint, while the former allows for a more interactive workflow but is often much slower, thus making it better suited for small incremental updates.</p> </li> <li> <p>Providing or connecting to additional functionality that is useful for the creation of knowledge graphs, such as identifier translation (e.g. via pypath.mapping as in the UniProt example adapter), or identifier and prefix standardisation and validation (e.g. via Bioregistry as in the UniProt example adapter and others).</p> </li> </ol> <p>Note</p> <p>For developers: We follow a design philosophy of \"separation of concerns\" in BioCypher. This means that the core should not be concerned with the details of how data is loaded, but only with the data itself. This is why the core does not contain any code for loading data from a resource, but only for writing it to the database. The adapter is responsible for loading the data and passing it to the core, which allows for a more modular design and makes it easier to maintain, extend, and reuse the code.</p> <p>For introduction of new features, we recommend to first implement them in the adapter, and to move them to the core only if they have shown to be useful for multiple adapters.</p>"},{"location":"tutorials/tutorial003_adapters/#1-loading-the-data","title":"1. Loading the Data","text":"<p>Depending on the data source, it is up to the developer of the adapter to find and define a suitable representation to be piped into BioCypher; for instance, in out <code>pypath</code> adapter, we load the entire <code>pypath</code> object into memory to be passed to BioCypher using a generator that evaluates each <code>pypath</code> object and transforms it to the tuple representation described below. This is made possible by the \"pre-harmonised\" form in which the data is represented within <code>pypath</code>. For more heterogeneous data representations, additional transformations may be necessary before piping into BioCypher.</p> <p>For larger datasets, it can be beneficial to adopt a streaming approach or batch processing, as demonstrated in the Open Targets adapter and the CKG adapter. BioCypher can handle input streams of arbitrary length via Python generators.</p>"},{"location":"tutorials/tutorial003_adapters/#2-passing-the-data","title":"2. Passing the Data","text":"<p>We currently pass data into BioCypher as a collection of tuples. Nodes are represented as 3-tuples, containing: - the node ID (unique in the space of the knowledge graph, ideally a CURIE with   a prefix registered in the Bioregistry) - the node type, i.e., its label (this is the string that is mapped to an   ontological class via the <code>input_label</code> field in the schema configuration) - a dictionary of node attributes</p> <p>While edges are represented as 5-tuples, containing: - the (optional) relationship ID (unique in the space of the KG) - the source node ID (referring to a unique node ID in the KG) - the target node ID (referring to a unique node ID in the KG) - the relationship type, i.e., its label (this is the string that is mapped to   an ontological class via the <code>input_label</code> field in the schema configuration) - a dictionary of relationship attributes</p> <p>Note</p> <p>This representation will probably be subject to change soon and yield to a more standardised interface for nodes and edges, derived from a BioCypher core class. We refer to this development in an issue.</p>"},{"location":"tutorials/tutorial003_adapters/#strict-mode","title":"Strict mode","text":"<p>We can activate BioCypher strict mode with the <code>strict_mode</code> option in the configuration. In strict mode, the driver will raise an error if it encounters a node or edge without data source, version, and licence. These currently need to be provided as part of the node and edge attribute dictionaries, with the reserved keywords <code>source</code>, <code>version</code>, and <code>licence</code> (or <code>license</code>). This may change to a more rigorous implementation in the future.</p>"}]}